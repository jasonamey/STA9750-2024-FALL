[
  {
    "objectID": "mp01.html",
    "href": "mp01.html",
    "title": "Jason Amey Mini Project 01",
    "section": "",
    "text": "Public transit in the United States serves a critical role in urban mobility. Serving millions of commuters while reducing congestion, pollution, and reliance on personal vehicles, transit is a critical institution in the success of the United States.\nHowever there exists a wide variation in the fiscal efficiency of these systems. Understanding these financial dimensions is essential for evaluating both the sustainability and performance of transit services.\nThis report explores data from major U.S. public transit systems, with analysis focused on factors such as: fare revenue per mile, vehicle revenue miles (VRM), unlinked passenger trips (UPT), and the ratio of expenses to fare-box recovery.\nThe data thus provides insights into important components of tranist analysis including: which systems operate most efficiently, which modes of transport generate the most revenue, and how these metrics differ throughout the United States.\nUsing tools from the R programming language, we explore these trends over time along with the influence of population density, geography, and mode-type on a transit system’s financial outcomes. Through this exploration, we hope to better understand the complex relationship among transit usage, financial sustainability, and regional transit characteristics.\n\n\nif(!require(\"tidyverse\")) install.packages(\"tidyverse\")\nlibrary(tidyverse)\n\nif(!require(\"DT\")) install.packages(\"DT\")\nlibrary(DT)\n\nif(!require(\"stringr\")) install.packages(\"stringr\")\nlibrary(stringr)\n\nif(!require(\"lubridate\")) install.packages(\"lubridate\")\nlibrary(lubridate)\n\nFARES &lt;- readxl::read_xlsx(\"data/mp-01/2022_fare_revenue.xlsx\") |&gt;\n  select(-`State/Parent NTD ID`,\n         -`Reporter Type`,\n         -`Reporting Module`,\n         -`TOS`,\n         -`Passenger Paid Fares`,\n         -`Organization Paid Fares`) |&gt;\n  filter(`Expense Type` == \"Funds Earned During Period\") |&gt;\n  select(-`Expense Type`)\n\nEXPENSES &lt;- readr::read_csv(\"data/mp-01/2022_expenses.csv\") |&gt;\n  select(`NTD ID`,\n         `Agency`,\n         `Total`,\n         `Mode`) |&gt;\n  mutate(`NTD ID` = as.integer(`NTD ID`)) |&gt;\n  rename(Expenses = Total) |&gt;\n  group_by(`NTD ID`, `Mode`) |&gt;\n  summarize(Expenses = sum(Expenses)) |&gt;\n  ungroup()\n\nTRIPS &lt;- readxl::read_xlsx(\"data/mp-01/2022_ridership.xlsx\", sheet=\"UPT\") |&gt;\n  filter(`Mode/Type of Service Status` == \"Active\") |&gt;\n  select(-`Legacy NTD ID`,\n         -`Reporter Type`,\n         -`Mode/Type of Service Status`,\n         -`UACE CD`,\n         -`TOS`) |&gt;\n  pivot_longer(-c(`NTD ID`:`3 Mode`),\n               names_to=\"month\",\n               values_to=\"UPT\") |&gt;\n  drop_na() |&gt;\n  mutate(month=my(month)) # Parse _m_onth _y_ear date specs\n\nMILES &lt;- readxl::read_xlsx(\"data/mp-01/2022_ridership.xlsx\", sheet=\"VRM\") |&gt;\n  filter(`Mode/Type of Service Status` == \"Active\") |&gt;\n  select(-`Legacy NTD ID`,\n         -`Reporter Type`,\n         -`Mode/Type of Service Status`,\n         -`UACE CD`,\n         -`TOS`) |&gt;\n  pivot_longer(-c(`NTD ID`:`3 Mode`),\n               names_to=\"month\",\n               values_to=\"VRM\") |&gt;\n  drop_na() |&gt;\n  group_by(`NTD ID`, `Agency`, `UZA Name`,\n           `Mode`, `3 Mode`, month) |&gt;\n  summarize(VRM = sum(VRM)) |&gt;\n  ungroup() |&gt;\n  mutate(month=my(month)) # Parse _m_onth _y_ear date specs\n\nUSAGE &lt;- inner_join(TRIPS, MILES) |&gt;\n  mutate(`NTD ID` = as.integer(`NTD ID`))\n\nFINANCIALS &lt;- inner_join(FARES, EXPENSES, join_by(`NTD ID`, `Mode`))\n\nFINANCIALS &lt;- FINANCIALS |&gt;\n  rename(\n         \"mode\" = \"Mode\"\n  )\n\nFINANCIALS &lt;- FINANCIALS |&gt;\n  mutate(mode=case_when(\n    mode == \"HR\" ~ \"Heavy Rail\",\n    mode == \"DR\" ~ \"Demand Response\",\n    mode == \"FB\" ~ \"Ferry Boat\",\n    mode == \"MB\" ~ \"Motor Bus\",\n    mode == \"SR\" ~ \"Streetcar\",\n    mode == \"TB\" ~ \"Trolleybus\",\n    mode == \"VP\" ~ \"Vanpool\",\n    mode == \"CB\" ~ \"Commuter Bus\",\n    mode == \"RB\" ~ \"Bus Rapid Transit\",\n    mode == \"LR\" ~ \"Light Rail\",\n    mode == \"YR\" ~ \"Hybrid Rail\",\n    mode == \"MG\" ~ \"Guided Transit (Monorail)\",\n    mode == \"CR\" ~ \"Commuter Rail\",\n    mode == \"AR\" ~ \"Alaska Railroad\",\n    mode == \"TR\" ~ \"Tramway\",\n    mode == \"HR\" ~ \"Heavy Rail\",\n    mode == \"IP\" ~ \"Inclined Plane\",\n    mode == \"PB\" ~ \"Publico\",\n    mode == \"CC\" ~ \"Cable Car\",\n    TRUE ~ \"Unknown\"))"
  },
  {
    "objectID": "mp01.html#fiscal-characteristics-of-major-us-public-transit-systems",
    "href": "mp01.html#fiscal-characteristics-of-major-us-public-transit-systems",
    "title": "Jason Amey Mini Project 01",
    "section": "",
    "text": "Public transit in the United States serves a critical role in urban mobility. Serving millions of commuters while reducing congestion, pollution, and reliance on personal vehicles, transit is a critical institution in the success of the United States.\nHowever there exists a wide variation in the fiscal efficiency of these systems. Understanding these financial dimensions is essential for evaluating both the sustainability and performance of transit services.\nThis report explores data from major U.S. public transit systems, with analysis focused on factors such as: fare revenue per mile, vehicle revenue miles (VRM), unlinked passenger trips (UPT), and the ratio of expenses to fare-box recovery.\nThe data thus provides insights into important components of tranist analysis including: which systems operate most efficiently, which modes of transport generate the most revenue, and how these metrics differ throughout the United States.\nUsing tools from the R programming language, we explore these trends over time along with the influence of population density, geography, and mode-type on a transit system’s financial outcomes. Through this exploration, we hope to better understand the complex relationship among transit usage, financial sustainability, and regional transit characteristics.\n\n\nif(!require(\"tidyverse\")) install.packages(\"tidyverse\")\nlibrary(tidyverse)\n\nif(!require(\"DT\")) install.packages(\"DT\")\nlibrary(DT)\n\nif(!require(\"stringr\")) install.packages(\"stringr\")\nlibrary(stringr)\n\nif(!require(\"lubridate\")) install.packages(\"lubridate\")\nlibrary(lubridate)\n\nFARES &lt;- readxl::read_xlsx(\"data/mp-01/2022_fare_revenue.xlsx\") |&gt;\n  select(-`State/Parent NTD ID`,\n         -`Reporter Type`,\n         -`Reporting Module`,\n         -`TOS`,\n         -`Passenger Paid Fares`,\n         -`Organization Paid Fares`) |&gt;\n  filter(`Expense Type` == \"Funds Earned During Period\") |&gt;\n  select(-`Expense Type`)\n\nEXPENSES &lt;- readr::read_csv(\"data/mp-01/2022_expenses.csv\") |&gt;\n  select(`NTD ID`,\n         `Agency`,\n         `Total`,\n         `Mode`) |&gt;\n  mutate(`NTD ID` = as.integer(`NTD ID`)) |&gt;\n  rename(Expenses = Total) |&gt;\n  group_by(`NTD ID`, `Mode`) |&gt;\n  summarize(Expenses = sum(Expenses)) |&gt;\n  ungroup()\n\nTRIPS &lt;- readxl::read_xlsx(\"data/mp-01/2022_ridership.xlsx\", sheet=\"UPT\") |&gt;\n  filter(`Mode/Type of Service Status` == \"Active\") |&gt;\n  select(-`Legacy NTD ID`,\n         -`Reporter Type`,\n         -`Mode/Type of Service Status`,\n         -`UACE CD`,\n         -`TOS`) |&gt;\n  pivot_longer(-c(`NTD ID`:`3 Mode`),\n               names_to=\"month\",\n               values_to=\"UPT\") |&gt;\n  drop_na() |&gt;\n  mutate(month=my(month)) # Parse _m_onth _y_ear date specs\n\nMILES &lt;- readxl::read_xlsx(\"data/mp-01/2022_ridership.xlsx\", sheet=\"VRM\") |&gt;\n  filter(`Mode/Type of Service Status` == \"Active\") |&gt;\n  select(-`Legacy NTD ID`,\n         -`Reporter Type`,\n         -`Mode/Type of Service Status`,\n         -`UACE CD`,\n         -`TOS`) |&gt;\n  pivot_longer(-c(`NTD ID`:`3 Mode`),\n               names_to=\"month\",\n               values_to=\"VRM\") |&gt;\n  drop_na() |&gt;\n  group_by(`NTD ID`, `Agency`, `UZA Name`,\n           `Mode`, `3 Mode`, month) |&gt;\n  summarize(VRM = sum(VRM)) |&gt;\n  ungroup() |&gt;\n  mutate(month=my(month)) # Parse _m_onth _y_ear date specs\n\nUSAGE &lt;- inner_join(TRIPS, MILES) |&gt;\n  mutate(`NTD ID` = as.integer(`NTD ID`))\n\nFINANCIALS &lt;- inner_join(FARES, EXPENSES, join_by(`NTD ID`, `Mode`))\n\nFINANCIALS &lt;- FINANCIALS |&gt;\n  rename(\n         \"mode\" = \"Mode\"\n  )\n\nFINANCIALS &lt;- FINANCIALS |&gt;\n  mutate(mode=case_when(\n    mode == \"HR\" ~ \"Heavy Rail\",\n    mode == \"DR\" ~ \"Demand Response\",\n    mode == \"FB\" ~ \"Ferry Boat\",\n    mode == \"MB\" ~ \"Motor Bus\",\n    mode == \"SR\" ~ \"Streetcar\",\n    mode == \"TB\" ~ \"Trolleybus\",\n    mode == \"VP\" ~ \"Vanpool\",\n    mode == \"CB\" ~ \"Commuter Bus\",\n    mode == \"RB\" ~ \"Bus Rapid Transit\",\n    mode == \"LR\" ~ \"Light Rail\",\n    mode == \"YR\" ~ \"Hybrid Rail\",\n    mode == \"MG\" ~ \"Guided Transit (Monorail)\",\n    mode == \"CR\" ~ \"Commuter Rail\",\n    mode == \"AR\" ~ \"Alaska Railroad\",\n    mode == \"TR\" ~ \"Tramway\",\n    mode == \"HR\" ~ \"Heavy Rail\",\n    mode == \"IP\" ~ \"Inclined Plane\",\n    mode == \"PB\" ~ \"Publico\",\n    mode == \"CC\" ~ \"Cable Car\",\n    TRUE ~ \"Unknown\"))"
  },
  {
    "objectID": "miniprojects/mp01.html",
    "href": "miniprojects/mp01.html",
    "title": "Jason Amey Mini Project 01",
    "section": "",
    "text": "Public transit in the United States serves a critical role in urban mobility. Serving millions of commuters while reducing congestion, pollution, and reliance on personal vehicles, transit is a critical institution in the success of the United States.\nHowever there exists a wide variation in the fiscal efficiency of these systems. Understanding these financial dimensions is essential for evaluating both the sustainability and performance of transit services.\nThis report explores data from major U.S. public transit systems, with analysis focused on factors such as: fare revenue per mile, vehicle revenue miles (VRM), unlinked passenger trips (UPT), and the ratio of expenses to fare-box recovery.\nThe data thus provides insights into important components of tranist analysis including: which systems operate most efficiently, which modes of transport generate the most revenue, and how these metrics differ throughout the United States.\nUsing tools from the R programming language, we explore these trends over time along with the influence of population density, geography, and mode-type on a transit system’s financial outcomes. Through this exploration, we hope to better understand the complex relationship among transit usage, financial sustainability, and regional transit characteristics.\n\n\nif(!require(\"tidyverse\")) install.packages(\"tidyverse\")\nlibrary(tidyverse)\n\nif(!require(\"DT\")) install.packages(\"DT\")\nlibrary(DT)\n\nif(!require(\"stringr\")) install.packages(\"stringr\")\nlibrary(stringr)\n\nif(!require(\"lubridate\")) install.packages(\"lubridate\")\nlibrary(lubridate)\n\nFARES &lt;- readxl::read_xlsx(\"data/mp-01/2022_fare_revenue.xlsx\") |&gt;\n  select(-`State/Parent NTD ID`,\n         -`Reporter Type`,\n         -`Reporting Module`,\n         -`TOS`,\n         -`Passenger Paid Fares`,\n         -`Organization Paid Fares`) |&gt;\n  filter(`Expense Type` == \"Funds Earned During Period\") |&gt;\n  select(-`Expense Type`)\n\nEXPENSES &lt;- readr::read_csv(\"data/mp-01/2022_expenses.csv\") |&gt;\n  select(`NTD ID`,\n         `Agency`,\n         `Total`,\n         `Mode`) |&gt;\n  mutate(`NTD ID` = as.integer(`NTD ID`)) |&gt;\n  rename(Expenses = Total) |&gt;\n  group_by(`NTD ID`, `Mode`) |&gt;\n  summarize(Expenses = sum(Expenses)) |&gt;\n  ungroup()\n\nTRIPS &lt;- readxl::read_xlsx(\"data/mp-01/2022_ridership.xlsx\", sheet=\"UPT\") |&gt;\n  filter(`Mode/Type of Service Status` == \"Active\") |&gt;\n  select(-`Legacy NTD ID`,\n         -`Reporter Type`,\n         -`Mode/Type of Service Status`,\n         -`UACE CD`,\n         -`TOS`) |&gt;\n  pivot_longer(-c(`NTD ID`:`3 Mode`),\n               names_to=\"month\",\n               values_to=\"UPT\") |&gt;\n  drop_na() |&gt;\n  mutate(month=my(month)) # Parse _m_onth _y_ear date specs\n\nMILES &lt;- readxl::read_xlsx(\"data/mp-01/2022_ridership.xlsx\", sheet=\"VRM\") |&gt;\n  filter(`Mode/Type of Service Status` == \"Active\") |&gt;\n  select(-`Legacy NTD ID`,\n         -`Reporter Type`,\n         -`Mode/Type of Service Status`,\n         -`UACE CD`,\n         -`TOS`) |&gt;\n  pivot_longer(-c(`NTD ID`:`3 Mode`),\n               names_to=\"month\",\n               values_to=\"VRM\") |&gt;\n  drop_na() |&gt;\n  group_by(`NTD ID`, `Agency`, `UZA Name`,\n           `Mode`, `3 Mode`, month) |&gt;\n  summarize(VRM = sum(VRM)) |&gt;\n  ungroup() |&gt;\n  mutate(month=my(month)) # Parse _m_onth _y_ear date specs\n\nUSAGE &lt;- inner_join(TRIPS, MILES) |&gt;\n  mutate(`NTD ID` = as.integer(`NTD ID`))\n\nFINANCIALS &lt;- inner_join(FARES, EXPENSES, join_by(`NTD ID`, `Mode`))\n\nFINANCIALS &lt;- FINANCIALS |&gt;\n  rename(\n         \"mode\" = \"Mode\"\n  )\n\nFINANCIALS &lt;- FINANCIALS |&gt;\n  mutate(mode=case_when(\n    mode == \"HR\" ~ \"Heavy Rail\",\n    mode == \"DR\" ~ \"Demand Response\",\n    mode == \"FB\" ~ \"Ferry Boat\",\n    mode == \"MB\" ~ \"Motor Bus\",\n    mode == \"SR\" ~ \"Streetcar\",\n    mode == \"TB\" ~ \"Trolleybus\",\n    mode == \"VP\" ~ \"Vanpool\",\n    mode == \"CB\" ~ \"Commuter Bus\",\n    mode == \"RB\" ~ \"Bus Rapid Transit\",\n    mode == \"LR\" ~ \"Light Rail\",\n    mode == \"YR\" ~ \"Hybrid Rail\",\n    mode == \"MG\" ~ \"Guided Transit (Monorail)\",\n    mode == \"CR\" ~ \"Commuter Rail\",\n    mode == \"AR\" ~ \"Alaska Railroad\",\n    mode == \"TR\" ~ \"Tramway\",\n    mode == \"HR\" ~ \"Heavy Rail\",\n    mode == \"IP\" ~ \"Inclined Plane\",\n    mode == \"PB\" ~ \"Publico\",\n    mode == \"CC\" ~ \"Cable Car\",\n    TRUE ~ \"Unknown\"))"
  },
  {
    "objectID": "miniprojects/mp01.html#fiscal-characteristics-of-major-us-public-transit-systems",
    "href": "miniprojects/mp01.html#fiscal-characteristics-of-major-us-public-transit-systems",
    "title": "Jason Amey Mini Project 01",
    "section": "",
    "text": "Public transit in the United States serves a critical role in urban mobility. Serving millions of commuters while reducing congestion, pollution, and reliance on personal vehicles, transit is a critical institution in the success of the United States.\nHowever there exists a wide variation in the fiscal efficiency of these systems. Understanding these financial dimensions is essential for evaluating both the sustainability and performance of transit services.\nThis report explores data from major U.S. public transit systems, with analysis focused on factors such as: fare revenue per mile, vehicle revenue miles (VRM), unlinked passenger trips (UPT), and the ratio of expenses to fare-box recovery.\nThe data thus provides insights into important components of tranist analysis including: which systems operate most efficiently, which modes of transport generate the most revenue, and how these metrics differ throughout the United States.\nUsing tools from the R programming language, we explore these trends over time along with the influence of population density, geography, and mode-type on a transit system’s financial outcomes. Through this exploration, we hope to better understand the complex relationship among transit usage, financial sustainability, and regional transit characteristics.\n\n\nif(!require(\"tidyverse\")) install.packages(\"tidyverse\")\nlibrary(tidyverse)\n\nif(!require(\"DT\")) install.packages(\"DT\")\nlibrary(DT)\n\nif(!require(\"stringr\")) install.packages(\"stringr\")\nlibrary(stringr)\n\nif(!require(\"lubridate\")) install.packages(\"lubridate\")\nlibrary(lubridate)\n\nFARES &lt;- readxl::read_xlsx(\"data/mp-01/2022_fare_revenue.xlsx\") |&gt;\n  select(-`State/Parent NTD ID`,\n         -`Reporter Type`,\n         -`Reporting Module`,\n         -`TOS`,\n         -`Passenger Paid Fares`,\n         -`Organization Paid Fares`) |&gt;\n  filter(`Expense Type` == \"Funds Earned During Period\") |&gt;\n  select(-`Expense Type`)\n\nEXPENSES &lt;- readr::read_csv(\"data/mp-01/2022_expenses.csv\") |&gt;\n  select(`NTD ID`,\n         `Agency`,\n         `Total`,\n         `Mode`) |&gt;\n  mutate(`NTD ID` = as.integer(`NTD ID`)) |&gt;\n  rename(Expenses = Total) |&gt;\n  group_by(`NTD ID`, `Mode`) |&gt;\n  summarize(Expenses = sum(Expenses)) |&gt;\n  ungroup()\n\nTRIPS &lt;- readxl::read_xlsx(\"data/mp-01/2022_ridership.xlsx\", sheet=\"UPT\") |&gt;\n  filter(`Mode/Type of Service Status` == \"Active\") |&gt;\n  select(-`Legacy NTD ID`,\n         -`Reporter Type`,\n         -`Mode/Type of Service Status`,\n         -`UACE CD`,\n         -`TOS`) |&gt;\n  pivot_longer(-c(`NTD ID`:`3 Mode`),\n               names_to=\"month\",\n               values_to=\"UPT\") |&gt;\n  drop_na() |&gt;\n  mutate(month=my(month)) # Parse _m_onth _y_ear date specs\n\nMILES &lt;- readxl::read_xlsx(\"data/mp-01/2022_ridership.xlsx\", sheet=\"VRM\") |&gt;\n  filter(`Mode/Type of Service Status` == \"Active\") |&gt;\n  select(-`Legacy NTD ID`,\n         -`Reporter Type`,\n         -`Mode/Type of Service Status`,\n         -`UACE CD`,\n         -`TOS`) |&gt;\n  pivot_longer(-c(`NTD ID`:`3 Mode`),\n               names_to=\"month\",\n               values_to=\"VRM\") |&gt;\n  drop_na() |&gt;\n  group_by(`NTD ID`, `Agency`, `UZA Name`,\n           `Mode`, `3 Mode`, month) |&gt;\n  summarize(VRM = sum(VRM)) |&gt;\n  ungroup() |&gt;\n  mutate(month=my(month)) # Parse _m_onth _y_ear date specs\n\nUSAGE &lt;- inner_join(TRIPS, MILES) |&gt;\n  mutate(`NTD ID` = as.integer(`NTD ID`))\n\nFINANCIALS &lt;- inner_join(FARES, EXPENSES, join_by(`NTD ID`, `Mode`))\n\nFINANCIALS &lt;- FINANCIALS |&gt;\n  rename(\n         \"mode\" = \"Mode\"\n  )\n\nFINANCIALS &lt;- FINANCIALS |&gt;\n  mutate(mode=case_when(\n    mode == \"HR\" ~ \"Heavy Rail\",\n    mode == \"DR\" ~ \"Demand Response\",\n    mode == \"FB\" ~ \"Ferry Boat\",\n    mode == \"MB\" ~ \"Motor Bus\",\n    mode == \"SR\" ~ \"Streetcar\",\n    mode == \"TB\" ~ \"Trolleybus\",\n    mode == \"VP\" ~ \"Vanpool\",\n    mode == \"CB\" ~ \"Commuter Bus\",\n    mode == \"RB\" ~ \"Bus Rapid Transit\",\n    mode == \"LR\" ~ \"Light Rail\",\n    mode == \"YR\" ~ \"Hybrid Rail\",\n    mode == \"MG\" ~ \"Guided Transit (Monorail)\",\n    mode == \"CR\" ~ \"Commuter Rail\",\n    mode == \"AR\" ~ \"Alaska Railroad\",\n    mode == \"TR\" ~ \"Tramway\",\n    mode == \"HR\" ~ \"Heavy Rail\",\n    mode == \"IP\" ~ \"Inclined Plane\",\n    mode == \"PB\" ~ \"Publico\",\n    mode == \"CC\" ~ \"Cable Car\",\n    TRUE ~ \"Unknown\"))"
  },
  {
    "objectID": "miniprojects.html",
    "href": "miniprojects.html",
    "title": "STA 9750 Fall 2024 - Jason Amey",
    "section": "",
    "text": "Here are my Mini-Projects :\n\nMini-Project #01"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Jason Amey - STA 9750 Fall 2024",
    "section": "",
    "text": "About Me: I work professionally as a Business Librarian in the Newman Library at Baruch College in New York City, NY.\nHere is my: Github\n\n\n1.mp #01"
  },
  {
    "objectID": "index.html#hi-my-name-is-jason-amey",
    "href": "index.html#hi-my-name-is-jason-amey",
    "title": "Jason Amey - STA 9750 Fall 2024",
    "section": "",
    "text": "About Me: I work professionally as a Business Librarian in the Newman Library at Baruch College in New York City, NY.\nHere is my: Github\n\n\n1.mp #01"
  },
  {
    "objectID": "slides/final_project_presentation.html#the-update",
    "href": "slides/final_project_presentation.html#the-update",
    "title": "Final Project Presentation",
    "section": "The Update",
    "text": "The Update"
  },
  {
    "objectID": "final_project_presentation.html#is-there-a-relationship-between-streets-and-home-values",
    "href": "final_project_presentation.html#is-there-a-relationship-between-streets-and-home-values",
    "title": "STA 9750 Final Project Presentation",
    "section": "Is there a relationship between streets and home values?",
    "text": "Is there a relationship between streets and home values?"
  },
  {
    "objectID": "final_project_presentation.html#do-streets-with-less-traffic-and-traffic-violence-increase-property-values",
    "href": "final_project_presentation.html#do-streets-with-less-traffic-and-traffic-violence-increase-property-values",
    "title": "STA 9750 Final Project Presentation",
    "section": "Do streets with less traffic and traffic violence increase property values?",
    "text": "Do streets with less traffic and traffic violence increase property values?"
  },
  {
    "objectID": "final_project_presentation.html#there-is-no-singular-identification-of-nyc-street-transformations",
    "href": "final_project_presentation.html#there-is-no-singular-identification-of-nyc-street-transformations",
    "title": "STA 9750 Final Project Presentation",
    "section": "There is no singular identification of NYC street transformations",
    "text": "There is no singular identification of NYC street transformations"
  },
  {
    "objectID": "final_project_presentation.html#identifying-significant-traffic-calming-projects-in-local-media",
    "href": "final_project_presentation.html#identifying-significant-traffic-calming-projects-in-local-media",
    "title": "STA 9750 Final Project Presentation",
    "section": "Identifying significant traffic calming projects in local media",
    "text": "Identifying significant traffic calming projects in local media"
  },
  {
    "objectID": "final_project_presentation.html#media-coverage-as-a-signal-for-significant-traffic-calming-project",
    "href": "final_project_presentation.html#media-coverage-as-a-signal-for-significant-traffic-calming-project",
    "title": "STA 9750 Final Project Presentation",
    "section": "Media Coverage as a signal for “significant traffic calming project”",
    "text": "Media Coverage as a signal for “significant traffic calming project”"
  },
  {
    "objectID": "final_project_presentation.html#parse-text-from-html-and-rank-tokens-in-search-of-street-names",
    "href": "final_project_presentation.html#parse-text-from-html-and-rank-tokens-in-search-of-street-names",
    "title": "STA 9750 Final Project Presentation",
    "section": "Parse text from html and rank tokens in search of street names",
    "text": "Parse text from html and rank tokens in search of street names"
  },
  {
    "objectID": "final_project_presentation.html#need-to-identify-block-and-lot-numbers-on-streets",
    "href": "final_project_presentation.html#need-to-identify-block-and-lot-numbers-on-streets",
    "title": "STA 9750 Final Project Presentation",
    "section": "Need to identify block and lot numbers on streets",
    "text": "Need to identify block and lot numbers on streets"
  },
  {
    "objectID": "final_project_presentation.html#with-block-and-lot-numbers-we-can-identify-tax-assessments",
    "href": "final_project_presentation.html#with-block-and-lot-numbers-we-can-identify-tax-assessments",
    "title": "STA 9750 Final Project Presentation",
    "section": "With block and lot numbers we can identify tax assessments",
    "text": "With block and lot numbers we can identify tax assessments"
  },
  {
    "objectID": "final_project_presentation.html#identify-comparable-neighboring-streets-by-traffic-flows",
    "href": "final_project_presentation.html#identify-comparable-neighboring-streets-by-traffic-flows",
    "title": "STA 9750 Final Project Presentation",
    "section": "Identify comparable, neighboring streets by traffic flows",
    "text": "Identify comparable, neighboring streets by traffic flows"
  },
  {
    "objectID": "final_project_presentation.html#attempting-to-control-for-these-influences",
    "href": "final_project_presentation.html#attempting-to-control-for-these-influences",
    "title": "STA 9750 Final Project Presentation",
    "section": "…attempting to control for these influences:",
    "text": "…attempting to control for these influences:"
  },
  {
    "objectID": "final_project_presentation.html#what-makes-a-neighborhood-expensive-in-nyc",
    "href": "final_project_presentation.html#what-makes-a-neighborhood-expensive-in-nyc",
    "title": "STA 9750 Final Project Presentation",
    "section": "What makes a neighborhood expensive in NYC?",
    "text": "What makes a neighborhood expensive in NYC?\nLocation: Proximity to Manhattan often increases prices.\nTransportation: Better access to subways, buses, and major roads raises desirability.\nAmenities: Access to parks, schools, dining, shopping, and cultural attractions.\nCrime: Safer neighborhoods tend to be more expensive.\nStatus: Historical prestige, architecture, and celebrity residents can elevate prices"
  },
  {
    "objectID": "final_project_presentation.html#project-question",
    "href": "final_project_presentation.html#project-question",
    "title": "STA 9750 Final Project Presentation",
    "section": "Project Question:",
    "text": "Project Question:\nDo streets with less traffic and traffic violence increase property values?"
  },
  {
    "objectID": "final_project_presentation.html#do-streets-with-less-traffic-and-traffic-violence-increase-property-values-1",
    "href": "final_project_presentation.html#do-streets-with-less-traffic-and-traffic-violence-increase-property-values-1",
    "title": "STA 9750 Final Project Presentation",
    "section": "Do streets with less traffic and traffic violence increase property values?",
    "text": "Do streets with less traffic and traffic violence increase property values?"
  },
  {
    "objectID": "final_project_presentation.html#when-streets-minimize-traffic-incidents-is-there-a-corresponding-increase-in-property-values",
    "href": "final_project_presentation.html#when-streets-minimize-traffic-incidents-is-there-a-corresponding-increase-in-property-values",
    "title": "STA 9750 Final Project Presentation",
    "section": "When streets minimize traffic incidents, is there a corresponding increase in property values?",
    "text": "When streets minimize traffic incidents, is there a corresponding increase in property values?"
  },
  {
    "objectID": "final_project_presentation.html#questions-for-project",
    "href": "final_project_presentation.html#questions-for-project",
    "title": "STA 9750 Final Project Presentation",
    "section": "Questions for project",
    "text": "Questions for project\n\nCan we make geographic connections among our data with code? For instance: can we find traffic calmed corridors, and then identify neighboring properties by block and lot number? Can we isolate street regions bounded by cross streets?\nWhat statistical test should we use to test for significance in tax assessment changes?\nHow do we effectively and efficiently work with large files? (The tax assessment files are ~1GB)\nIs there enough media coverage to identify significant traffic calming projects?\nHow many traffic calmed corridors should we focus on?"
  },
  {
    "objectID": "final_project_presentation.html#that-is",
    "href": "final_project_presentation.html#that-is",
    "title": "STA 9750 Final Project Presentation",
    "section": "That is:",
    "text": "That is:"
  },
  {
    "objectID": "final_project_presentation.html#question",
    "href": "final_project_presentation.html#question",
    "title": "STA 9750 Final Project Presentation",
    "section": "Question?",
    "text": "Question?"
  },
  {
    "objectID": "final_project_presentation.html#challenges-for-project",
    "href": "final_project_presentation.html#challenges-for-project",
    "title": "STA 9750 Final Project Presentation",
    "section": "Challenges for project",
    "text": "Challenges for project\n\nCan we make geographic connections among our data with code?\nWhat statistical test should we use to test for significance in tax assessment changes?\nHow do we effectively and efficiently work with large files? (The tax assessment files are ~1GB)\nIs there enough media coverage to identify significant traffic calming projects?\nHow many traffic calmed corridors should we focus on?"
  },
  {
    "objectID": "final_project_presentation.html#challenging-part-of-project-geocoding",
    "href": "final_project_presentation.html#challenging-part-of-project-geocoding",
    "title": "STA 9750 Final Project Presentation",
    "section": "Challenging part of project: Geocoding",
    "text": "Challenging part of project: Geocoding\nOnce we’ve identified areas of interest, how do we go from?\nstreet -&gt; latitude and longitude\nlatitude and longitude -&gt; block, lot number\nidentifying a corridor of a street?\ncorrectly identifying a collection of properties?\nHow do we do this in code?"
  },
  {
    "objectID": "mp02.html",
    "href": "mp02.html",
    "title": "IMDb and Me",
    "section": "",
    "text": "This project useses the following packagaes: dplyr, tidyr, stringr, lubridate, readr, scales\nFor details on the data used for this project see Appendix A.\nOriginating in the proto-Internet era of Usenet groups in the early 1990s, the Internet Movie Database (with its instantly recognizable acronym: IMDb) has long been an indispensable source of pop culture information. Movie buffs, film industry professionals, trivia enthusiasts, and casual web surfers all agree IMDb is the go-to resource for anyone engaged in the history of motion pictures."
  },
  {
    "objectID": "final_project_presentation.html#data-sets-to-use",
    "href": "final_project_presentation.html#data-sets-to-use",
    "title": "STA 9750 Final Project Presentation",
    "section": "Data Sets to Use :",
    "text": "Data Sets to Use :\nNew York City Department of City Planning. (n.d.). Bytes of the Big Apple Archive. NYC Planning. Retrieved October 8, 2024, from https://www.nyc.gov/site/planning/data-maps/open-data/bytes-archive.page"
  },
  {
    "objectID": "final_project_presentation.html#data-sets-we-will-use",
    "href": "final_project_presentation.html#data-sets-we-will-use",
    "title": "STA 9750 Final Project Presentation",
    "section": "Data sets we will use",
    "text": "Data sets we will use\nProperty Assessment Roll Archives. NYC Department of Finance. link\nAutomated Traffic Volume Counts. NYC Department of Transportation. link"
  },
  {
    "objectID": "final_project_presentation.html#data-sets-we-may-use",
    "href": "final_project_presentation.html#data-sets-we-may-use",
    "title": "STA 9750 Final Project Presentation",
    "section": "Data sets we may use",
    "text": "Data sets we may use\nNew York City Department of City Planning. NYC Tax Lot Selector. link\nCity of New York: VZV Street Improvement Projects - SIPs Corridor. NYC Open Data. link"
  },
  {
    "objectID": "final_project_presentation.html#with-block-and-lot-numbers-we-can-identify-tax-assessments-1",
    "href": "final_project_presentation.html#with-block-and-lot-numbers-we-can-identify-tax-assessments-1",
    "title": "STA 9750 Final Project Presentation",
    "section": "With block and lot numbers we can identify tax assessments",
    "text": "With block and lot numbers we can identify tax assessments"
  },
  {
    "objectID": "final_project_presentation.html#tax-lot-selector",
    "href": "final_project_presentation.html#tax-lot-selector",
    "title": "STA 9750 Final Project Presentation",
    "section": "Tax Lot Selector",
    "text": "Tax Lot Selector"
  },
  {
    "objectID": "final_project_presentation.html#challenges-continued",
    "href": "final_project_presentation.html#challenges-continued",
    "title": "STA 9750 Final Project Presentation",
    "section": "Challenges (continued…)",
    "text": "Challenges (continued…)\n\nHow many traffic calmed corridors should we focus on?"
  },
  {
    "objectID": "final_project_presentation.html#the-city-does-identify-singular-vision-zero-improvemments",
    "href": "final_project_presentation.html#the-city-does-identify-singular-vision-zero-improvemments",
    "title": "STA 9750 Final Project Presentation",
    "section": "The City does identify singular Vision Zero improvemments",
    "text": "The City does identify singular Vision Zero improvemments"
  },
  {
    "objectID": "final_project_presentation.html#nyc-does-identify-singular-vision-zero-improvemments",
    "href": "final_project_presentation.html#nyc-does-identify-singular-vision-zero-improvemments",
    "title": "STA 9750 Final Project Presentation",
    "section": "NYC does identify singular Vision Zero improvemments",
    "text": "NYC does identify singular Vision Zero improvemments"
  },
  {
    "objectID": "final_project_presentation.html#again-with-block-and-lot-numbers-we-can-identify-tax-assessments",
    "href": "final_project_presentation.html#again-with-block-and-lot-numbers-we-can-identify-tax-assessments",
    "title": "STA 9750 Final Project Presentation",
    "section": "(again) …with block and lot numbers we can identify tax assessments",
    "text": "(again) …with block and lot numbers we can identify tax assessments"
  },
  {
    "objectID": "final_project_presentation.html#challenging-geocoding",
    "href": "final_project_presentation.html#challenging-geocoding",
    "title": "STA 9750 Final Project Presentation",
    "section": "Challenging: Geocoding",
    "text": "Challenging: Geocoding\nOnce we’ve identified areas of interest, how do we go from?\nstreet -&gt; latitude and longitude\nlatitude and longitude -&gt; block, lot number\nidentifying a corridor of a street?\ncorrectly identifying a collection of properties?\nHow do we do this in code?"
  },
  {
    "objectID": "final_project_presentation.html#challenge-geocoding",
    "href": "final_project_presentation.html#challenge-geocoding",
    "title": "STA 9750 Final Project Presentation",
    "section": "Challenge: Geocoding",
    "text": "Challenge: Geocoding\nOnce we’ve identified areas of interest, how do we go from?\nstreet -&gt; latitude and longitude\nlatitude and longitude -&gt; block, lot number\nidentifying a corridor of a street?\ncorrectly identifying a collection of properties?\nHow do we do this in code?"
  },
  {
    "objectID": "final_project_presentation.html#thank-you",
    "href": "final_project_presentation.html#thank-you",
    "title": "STA 9750 Final Project Presentation",
    "section": "Thank You!",
    "text": "Thank You!\nClinta and Jason :-)"
  },
  {
    "objectID": "final_project_presentation.html#additional-questions",
    "href": "final_project_presentation.html#additional-questions",
    "title": "STA 9750 Final Project Presentation",
    "section": "Additional Questions",
    "text": "Additional Questions\n\nIs there a geographic or NYC borough trend with our conclusions?\nDid Bloomberg’s major street transformations of the late 2000s have a bigger influence on real estate values than the more modest transformations of the De Blasio and Adams administrations?\nIs there a difference between residential and commerical property changes?"
  },
  {
    "objectID": "mp02.html#footnotes",
    "href": "mp02.html#footnotes",
    "title": "IMDB and Me",
    "section": "Footnotes",
    "text": "Footnotes\n\n\ndog &lt;- \"dogg\"↩︎"
  },
  {
    "objectID": "mp02.html#how-data-was-loaded",
    "href": "mp02.html#how-data-was-loaded",
    "title": "IMDB and Me",
    "section": "How Data Was Loaded",
    "text": "How Data Was Loaded\nIn this section, I describe how the data was loaded into the project.\n# Example of loading data in R\ndata &lt;- read.csv(\"path/to/your/data.csv\")"
  },
  {
    "objectID": "mp02.html#appendixA",
    "href": "mp02.html#appendixA",
    "title": "IMDb and Me",
    "section": "Appendix A",
    "text": "Appendix A\n\nHow Data Was Loaded\nIn this section, I describe how the data was loaded into the project.\n&lt;!-- library(dplyr) --&gt;\n&lt;!-- library(tidyr) --&gt;\n&lt;!-- library(stringr) --&gt;\n&lt;!-- library(lubridate) --&gt;\n&lt;!-- library(readr) --&gt;\n\n&lt;!-- DATA_FOLDER &lt;- \"data/mp02/\" --&gt;\n\n&lt;!-- get_IMDb_file &lt;- function(fname){ --&gt;\n&lt;!--      as.data.frame(readr::read_csv(fname, lazy=FALSE)) --&gt;\n&lt;!--  } --&gt;\n\n&lt;!-- create_file_ext &lt;- function(fname){ --&gt;\n&lt;!--    paste0(DATA_FOLDER, fname) --&gt;\n&lt;!-- } --&gt;\n\n&lt;!-- # IMDb DATA --&gt;\n\n&lt;!-- NAME_BASICS &lt;- get_IMDb_file(create_file_ext(\"NAME_BASICS.csv\")) --&gt;\n&lt;!-- TITLE_RATINGS &lt;- get_IMDb_file(create_file_ext(\"TITLE_RATINGS.csv\")) --&gt;\n&lt;!-- TITLE_BASICS &lt;- get_IMDb_file(create_file_ext(\"TITLE_BASICS.csv\")) --&gt;\n&lt;!-- TITLE_CREW &lt;- get_IMDb_file(create_file_ext(\"TITLE_CREW.csv\")) --&gt;\n&lt;!-- TITLE_EPISODES &lt;- get_IMDb_file(create_file_ext(\"TITLE_EPISODES.csv\")) --&gt;\n&lt;!-- TITLE_PRINCIPALS &lt;- get_IMDb_file(create_file_ext(\"TITLE_PRINCIPALS.csv\")) --&gt;\n\n&lt;!-- NAME_BASICS &lt;- NAME_BASICS |&gt; --&gt;\n&lt;!--     mutate(birthYear = as.numeric(birthYear), --&gt;\n&lt;!--            deathYear = as.numeric(deathYear)) --&gt;\n\n&lt;!-- TITLE_RATINGS &lt;- TITLE_RATINGS |&gt; --&gt;\n&lt;!--      mutate(averageRating = as.numeric(averageRating), --&gt;\n&lt;!--             numVotes = as.numeric(numVotes)) --&gt;\n\n&lt;!-- TITLE_BASICS &lt;- TITLE_BASICS |&gt; --&gt;\n&lt;!--     mutate(isAdult = as.logical(isAdult), --&gt;\n&lt;!--            runtimeMinutes = ifelse(grepl(\"[^0-9]\", runtimeMinutes), NA, as.numeric(runtimeMinutes))) --&gt;\n\n&lt;!-- # MOVIE LENS --&gt;\n\n&lt;!-- MOVIE_LENS_RATINGS &lt;- read.csv(\"data/mp02/ml-32m/ratings.csv\") --&gt;\n\n&lt;!-- MOVIE_LENS_LINKS &lt;- read.csv(\"data/mp02/ml-32m/links.csv\") --&gt;\n\n&lt;!-- movie_lens_ratings_merged &lt;- MOVIE_LENS_RATINGS |&gt; --&gt;\n&lt;!--    group_by(movieId) |&gt; --&gt;\n&lt;!--    summarize(count_reviews = n()) --&gt;\n\n&lt;!-- # KAGGLE --&gt;\n\n&lt;!-- KAGGLE_DATA &lt;- read.csv(\"data/mp02/KAGGLE_DATA.csv\") |&gt; --&gt;\n&lt;!--    mutate(budget = ifelse(is.na(budget), 0, parse_number(budget))) --&gt;\n\n&lt;!-- # CPI --&gt;\n\n&lt;!-- HISTORICAL_CPI &lt;- read.csv(\"data/mp02/HISTORICAL_CPI.csv\") |&gt; --&gt;\n&lt;!--    mutate(year = substring(DATE,1,4)) --&gt;\n\n&lt;!-- cpi_named_vector &lt;- setNames(HISTORICAL_CPI$CPIAUCNS, HISTORICAL_CPI$year) --&gt;\nhead(names_in_many_big_productions)  \n\n\n\n\n\n\n\n\n\n\n\n&gt; show the code\n\n\nhello &lt;- \"hello\"\n\n\n\n–&gt;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n–&gt;\n\n\n\n\n\n\n\n\n–&gt;\n\n–&gt;\n\n–&gt;\n\n\n\n\n\n\n\n\n\n\n\n\n–&gt;\n\n\n\n\n\n–&gt;"
  },
  {
    "objectID": "mp02.html#how-often-has-a-producer-been-given-the-proverbial-green-light",
    "href": "mp02.html#how-often-has-a-producer-been-given-the-proverbial-green-light",
    "title": "IMDB and Me",
    "section": "How often has a producer been given the proverbial “green light”?",
    "text": "How often has a producer been given the proverbial “green light”?\nThe “M” in the moniker obviously denotes “movie” and there are indeed 131,890 traditional “movies” in IMDB. However, many take a different interpretations as to what is - and what is not - a “movie” and IMDB maintains a separate designation for tvMovie.\nThe author contends that the films produced by the premium television outlet Home Box Office are significant films all-too-often overlooked by film afficianados and sure enough, HBO films are considered television films by IMDB :\ntitleType   primaryTitle            startYear\ntvMovie     And the Band Played On  1993\n\ntitleType   primaryTitle            startYear\ntvMovie     Recount                 2008\n  \ntitleType   primaryTitle            startYear\ntvMovie     Conspiracy              2001\nNot an HBO original, but this tvMovie is partially credited for ending The Cold War:\ntitleType   primaryTitle    startYear\ntvMovie     The Day After   1983\nThe above are all noteworthy (underrated) films more than deserving to be considered and counted alongside IMDB’s critera for “movie”. If we were to count both movie and tvMovie we would find 146,915 movie titles in IMDB.\n…Speaking of television, that “M” in IMDB can be something of a misnomer. IMDB collects data on both film and television too. And within the database, IMDB doesn’t just maintain an entry for every television series, but actually has a record for each televison season and a record for every televsion episode. All told there are 29,868 series within IMDB represented by over 3,012,678 individual episdoes.\nIf television is collected this extensively in the database, what else does IMDB collect? What else is in the database?\n\nI’d argue the collection of Video Games will prove increasingly important as this media form grows in cultural influence. I can certainly see a future where Video Games are of equal cultural significance (…if were not at that momemnt already?) as film and TV is today.\n\n\n&gt; show the code\n\n# How many films are in IMDB? \nTITLE_BASICS |&gt; \n  filter(titleType == \"movie\" | titleType == \"tvMovie\") |&gt;\n  count()\n\n# What if we include TV Moives?   \nTITLE_BASICS |&gt; \n  filter(titleType == \"movie\" | titleType == \"tvMovie\") |&gt;\n  count()\n\n# What if we searched for a particular HBO Moive?    \nTITLE_BASICS |&gt; \n  filter(primaryTitle == \"And the Band Played On\") |&gt; \n  select(titleType, primaryTitle, startYear)\n\n# How many television series are in IMDB? \nTITLE_BASICS |&gt; \n  filter(titleType == \"tvSeries\") |&gt;\n  count()\n\n# How many individual episodes are collected? \nTITLE_EPISODES |&gt;\n  nrow()\n\n# What are the different title types in IMDB  \ntitle_type_counts &lt;- TITLE_BASICS |&gt; \n  group_by(titleType) |&gt; \n  summarize(count = n())\n  \n# Let's visualize the breakdown of all the different title types\nggplot(title_type_counts, aes(x = \"\", y = count, fill = titleType)) + \n  geom_bar(stat = \"identity\", width = 0.7) +\n  labs(title = \"IMDB Media Types and Their Counts\", x = NULL, y = \"Count\") +\n  scale_y_continuous(labels = label_number(scale_cut = cut_short_scale())) +\n  scale_fill_brewer(palette = \"Set3\")\n  theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())  \n\n\n\n\n&gt; show the code\n\n\n\n[1] \"doggnose\"\n\n\n\n\n\n\n\n\n\nmovies_meeting_review_threshold &lt;- movies_lens_ratings_merged |&gt; filter(count_reviews &gt;= 1000) |&gt; pull(movieId)\nfiltered_reviews &lt;- MOVIE_LENS_RATINGS |&gt; filter(movieId %in% movies_meeting_review_threshold)\nmovie_lens__IMDB &lt;- filtered_reviews |&gt; inner_join(MOVIE_LENS_LINKS, by = “movieId”)\n\n\n&gt; show the code\n\n\nhello &lt;- \"hello\"\n\n\n\nWhen we say “movie” we often think of “what is opening this Friday” and with it: “what film will win the weekend box office?”\nIf we look at the Kaggle Movie Dataset, we see\nquantile(KAGGLE_DATA$revenue, probs = seq(0,1,.05), na.rm=TRUE)\n\nNAME_BASICS |&gt; filter(birthYear &lt;= 1914 & is.na(deathYear)) |&gt; nrow() \nThe Gerontology Research Group rigorously counts “supercentarians” around the world. A supercentarian is an individual equal-to, or older-than, the age of 110. At current count, there are approximately ~310 supercentarians in the world.\nClearly there is an issue with the IMDB dataset identifying 2,514 supercentarians in the film industry. There obviously are a multitude of deaths unreported in this data.\nBut, just because you’re old and you possibly “one-time-maybe did something in the film industry”, should anyone care? There are millions of people who throughout their lives have no-doubt been involved in at least 1 movie production in their lives. Does “old person who once worked on a forgotten independent movie no-one-saw” really communicate anything to us?\nI don’t think it does.\nMy childhood friend Rob went to film school in the late 1990s. He briefly worked in the film industry for a few years after graduation but quickly decided he did not want a career in movies. While I can tell you Rob is a very talented individual, he has long since had anything to do with the film industry.\nMy friend Rob is in the IMDB dataset: https://www.imdb.com/name/nm0551343/?ref_=fn_al_nm_1\nWith all due respect to Rob, his talents and his successful post-film career (he’s a tenure-track professor of education), do we really want to count “the Robs” of our dataset?\nCan we filter out the Robs and the like and arrive on a collection of individuals “significant enough in the film industry” to warrant our interest and attention?\nI think we can.\nLet’s first try to identify “significant film productions” in our data.\nI’m going to use the measure of: “if this film had a lot of people working on it, it no doubt cost a lot of money and was of signifcant interest to some studio or production company.” So I’m going to count the\nNAME_BASICS |&gt; nrow() \nNAME_BASICS &lt;- NAME_BASICS |&gt; mutate(birthYear = as.numeric(birthYear), deathYear = as.numeric(deathYear))\nCREW_COUNTS_FOR_TITLE &lt;- TITLE_PRINCIPALS |&gt; group_by(tconst) |&gt; summarize(crew_members = n())\nquantile(CREW_COUNTS_FOR_TITLE$crew_members, probs = seq(0.1, 1, by=.1))\nBIG_PRODUCTIONS &lt;- CREW_COUNTS_FOR_TITLE |&gt; filter(crew_members &gt;= 24)\n\n\nNAMEIDS_IN_MANY_BIG_PRODUCTIONS &lt;- BIG_PRODUCTIONS |&gt; inner_join(TITLE_PRINCIPALS, join_by(tconst == tconst)) |&gt; group_by(nconst) |&gt; summarize(number_of_big_productions = n()) |&gt; filter(number_of_big_productions &gt; 20) |&gt; arrange(desc(number_of_big_productions))\nLet’s spot check out data…\nNAMES_IN_MANY_BIG_PRODUCTIONS &lt;- NAMEIDS_IN_MANY_BIG_PRODUCTIONS |&gt; inner_join(NAME_BASICS, join_by(nconst == nconst)) |&gt; mutate(deathYear = ifelse(is.na(deathYear), 0, deathYear)) |&gt; mutate(age = ifelse(deathYear == 0, 2024 - birthYear, deathYear - birthYear))\nThis data is identifying well-known voice actors:\n        \nNAMES_IN_MANY_BIG_PRODUCTIONS |&gt; filter(deathYear == 0) |&gt; arrange(desc(age)) |&gt; slice(1)\n\n\ntop_episodes &lt;- TITLE_RATINGS |&gt; filter(averageRating == 10 & numVotes &gt;= 200000)\nepisode_details &lt;- top_episodes |&gt; inner_join(TITLE_BASICS, by = “tconst”) |&gt; inner_join(TITLE_EPISODES, by = “tconst”)\nresult &lt;- episode_details |&gt; inner_join(TITLE_BASICS, by = c(“parentTconst” = “tconst”)) |&gt; select(tconst, parentTconst, seriesTitle = primaryTitle.y)\n\nmark_hamil_popular_works_IDs &lt;- NAME_BASICS |&gt; filter(primaryName == “Mark Hamill”) |&gt; separate_rows(knownForTitles, sep =“,”)\nmark_hamil_popular_works |&gt; inner_join(TITLE_BASICS, by = c(“knownForTitles” = “tconst”)) |&gt; select(-knownForTitles, -primaryProfession, -birthYear, -deathYear, -isAdult)\n\n\n\n\ntv_show_12_episodes &lt;- TITLE_EPISODES |&gt; group_by(parentTconst) |&gt; mutate(numberOfEpisodes = n()) |&gt;\narrange(desc(numberOfEpisodes))\ntv_show_12_episodes_high_rating_ID &lt;- tv_show_12_episodes |&gt; inner_join(TITLE_RATINGS, by = “tconst”) |&gt; select(-seasonNumber, -episodeNumber, -tconst) |&gt; group_by(parentTconst) |&gt; mutate(average_rating_for_series = mean(averageRating), total_votes = sum(numVotes)) |&gt;\nquantile(tv_show_12_episodes_high_rating_ID$total_votes, prob = seq(0,1,.05))\n   \ntv_show_12_episodes_high_rating_titles &lt;- tv_show_12_episodes_high_rating_ID |&gt; filter(total_votes &gt; 268000) |&gt; inner_join(TITLE_BASICS, join_by(parentTconst == tconst))\ntv_show_12_episodes_high_rating_titles &lt;- tv_show_12_episodes_high_rating_ID |&gt; filter(total_votes &gt; 268000) |&gt; inner_join(TITLE_BASICS, join_by(parentTconst == tconst)) |&gt; group_by(parentTconst, primaryTitle) |&gt;\nsummarize(average_rating_for_series = first(average_rating_for_series), .groups = ‘drop’) |&gt;\narrange(desc(average_rating_for_series))\nprint(tv_show_12_episodes_high_rating_titles, n = 50)\n        \n\n\n\ntitle_basics_movie_lens_id &lt;- TITLE_BASICS |&gt; mutate(imdbId = as.numeric(substring(tconst, 3)))\n\nmovie_lens_and_imdb &lt;- title_basics_movie_lens_id |&gt; inner_join(movie_lens_filtered_reviews_IMDB, by = “imdbId”) |&gt; select(-isAdult, -endYear, -runtimeMinutes, -tmdbId, -titleType) |&gt; mutate(yearReview = year(as.POSIXct(timestamp, origin=“1970-01-01”)))\n\nmovie_lens_and_imdb_5_year_reviews &lt;- movie_lens_and_imdb |&gt; filter(yearReview - startYear &gt;= 5) |&gt; group_by(imdbId, primaryTitle, startYear) |&gt; summarize(avg_review = mean(rating)) |&gt; select(-imdbId) |&gt; arrange(desc(avg_review))\nprint(movie_lens_and_imdb_5_year_reviews, n=50)\nmin(movie_lens_and_imdb$yearReview) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmovie_lens_and_imdb_year_review &lt;- movie_lens_and_imdb |&gt; group_by(imdbId, primaryTitle, startYear) |&gt; summarize(avg_review = mean(rating)) |&gt; arrange(desc(avg_review))\nprint(movie_lens_and_imdb_year_review, n = 50)\n         \npolarizing_films &lt;- movie_lens_and_imdb |&gt; group_by(imdbId, primaryTitle, startYear, genres) |&gt; summarise(mean_rating = mean(rating), sd_rating = sd(rating), num_ratings = n()) |&gt; arrange(desc(sd_rating)) |&gt; select(-imdbId)\npolarizing_films\npolarizing_films &lt;- movie_lens_and_imdb |&gt; group_by(movieId, primaryTitle, startYear, genres) |&gt; summarise(mean_rating = mean(rating), iqr_rating = IQR(rating), num_ratings = n()) |&gt; arrange(desc(iqr_rating))\npolarizing_films &lt;- movie_lens_and_imdb |&gt; group_by(movieId, primaryTitle, startYear, genres) |&gt; summarise(mean_rating = mean(rating), var_rating = var(rating), num_ratings = n()) |&gt; arrange(desc(var_rating))\n\nmovie_lens_and_imdb_and_kaggle &lt;- movie_lens_and_imdb |&gt; inner_join(KAGGLE_DATA, join_by(tconst == imdb_id))\nmovie_lens_and_imdb_and_kaggle\nget_dollar_adjusted_value &lt;- function(budget, year){ return (budget * cpi_named_vector[as.character(2024)]/cpi_named_vector[as.character(year)]) }\nvotes_budget &lt;- movie_lens_and_imdb_and_kaggle |&gt; group_by(imdbId, primaryTitle, budget, startYear, revenue) |&gt; summarize(num_votes = n()) |&gt; mutate(adjusted_budget = get_dollar_adjusted_value(budget, startYear), adjusted_profit = get_dollar_adjusted_value(revenue, startYear) - get_dollar_adjusted_value(budget, startYear) )\nmodel_profit &lt;- lm(votes_budget\\(num_votes ~  votes_budget\\)adjusted_profit)\nreg_line &lt;- function(x_val, model){ return(coef(model)[1] + coef(model)[2] * x_val) }\nvotes_budget_profit &lt;- votes_budget |&gt; mutate(popularity_over_profit = num_votes - reg_line(adjusted_profit, model_profit)) |&gt; arrange(desc(popularity_over_profit))\n\nggplot(data = votes_budget_profit, aes(x = adjusted_profit, y = num_votes )) + geom_point(alpha = 0.1) + geom_smooth(method=“lm”, se=FALSE)\nmodel_budget &lt;- lm(votes_budget\\(num_votes ~  votes_budget\\)adjusted_budget)\nvotes_budget_budget &lt;- votes_budget |&gt; mutate(popularity_over_budget = num_votes - reg_line(adjusted_budget, model_profit)) |&gt; arrange(desc(popularity_over_budget))\nprint(votes_budget_budget, n =100)\n\nvotes_budget |&gt; arrange(desc(adjusted_budget)) |&gt; print(n = 100)\ntop_500_polarizing_films &lt;- head(polarizing_films, 500)\ntop_500_polarizing_films_w_budget &lt;- top_500_polarizing_films |&gt; inner_join(KAGGLE_DATA, join_by(imdbId == imdb_id))\ntop_500_polarizing_films_w_budget"
  },
  {
    "objectID": "mp02.html#whats-in-the-box",
    "href": "mp02.html#whats-in-the-box",
    "title": "IMDb and Me",
    "section": "What’s in the box?",
    "text": "What’s in the box?\n\nHow many green lights have been granted in Hollywood?\nThe “M” in the moniker obviously denotes “movie” and there are indeed 131,890 traditional “movies” in IMDb. However, many take a different interpretations as to what is - and what is not - a “movie” and IMDb maintains a separate designation for tvMovie.\nThe author contends that the films produced by the premium television outlet Home Box Office are significant films all-too-often overlooked by film afficianados and sure enough, HBO films are considered television films by IMDb :\ntitleType   primaryTitle            startYear\ntvMovie     And the Band Played On  1993\n\ntitleType   primaryTitle            startYear\ntvMovie     Recount                 2008\n  \ntitleType   primaryTitle            startYear\ntvMovie     Conspiracy              2001\nNot an HBO original, but this tvMovie is partially credited for ending The Cold War:\ntitleType   primaryTitle    startYear\ntvMovie     The Day After   1983\nThe above are all noteworthy (underrated) films more than deserving to be considered and counted alongside IMDb’s critera for “movie”. If we were to count both movie and tvMovie we would find 146,915 movie titles in IMDb.\n…Speaking of television, that “M” in IMDb can be something of a misnomer. IMDb collects data on both film and television too. And within the database, IMDb doesn’t just maintain an entry for every television series, but actually has a record for each televison season and a record for every televsion episode. All told there are 29,868 series within IMDb represented by over 3,012,678 individual episdoes.\nIf television is collected this extensively in the database, what else does IMDb collect? What else is in the database?\n\nI’d argue the collection of Video Games will prove increasingly important as this media form grows in cultural influence. I can certainly see a future where Video Games are of equal cultural significance (…if were not at that momemnt already?) as film and TV is today.\n\n\n&gt; show the code\n\n# How many films are in IMDb? \nTITLE_BASICS |&gt; \n  filter(titleType == \"movie\" | titleType == \"tvMovie\") |&gt;\n  count()\n\n# What if we include TV Moives?   \nTITLE_BASICS |&gt; \n  filter(titleType == \"movie\" | titleType == \"tvMovie\") |&gt;\n  count()\n\n# What if we searched for a particular HBO Moive?    \nTITLE_BASICS |&gt; \n  filter(primaryTitle == \"And the Band Played On\") |&gt; \n  select(titleType, primaryTitle, startYear)\n\n# How many television series are in IMDb? \nTITLE_BASICS |&gt; \n  filter(titleType == \"tvSeries\") |&gt;\n  count()\n\n# How many individual episodes are collected? \nTITLE_EPISODES |&gt;\n  nrow()\n\n# What are the different title types in IMDb  \ntitle_type_counts &lt;- TITLE_BASICS |&gt; \n  group_by(titleType) |&gt; \n  summarize(count = n())\n\n# Let's visualize the breakdown of all the different title types\nggplot(title_type_counts, aes(x = \"\", y = count, fill = titleType)) + \n  geom_bar(stat = \"identity\", width = 0.7) +\n  labs(title = \"IMDb Media Types and Their Counts\", x = NULL, y = \"Count\") +\n  scale_y_continuous(labels = label_number(scale_cut = cut_short_scale())) +\n  scale_fill_brewer(palette = \"Paired\")\n  theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())  \n\n\n\n\n110 years old you reach, look as good you will not\nIMBb is a unrivaled resource for assessing film history. And by history, there is actually some capital “H” history in IMDb.\nIMDb counts 4 as the oldest birthYear for any individual in its dataset. And not just 4, there are also birthYear values for 46, 69, 70, 163, 254. As far as we know, film production is a ~150 year old technology.\nWhat is going on?\nWho was born in year 4? Year 46? Year 69?\n             primaryName\n1       Flavius Josephus\n2 Publius Vergilius Maro\n3                   Ovid\n4  Titus Maccius Plautus\n5     Lucio Anneo Seneca\n6            Cassius Dio\n7               Plutarch\n8              Suetonius\nAre you entertained? A fascinating qwirk of IMDb database is that it credits classical writers and historians for modern film production, again, proving IMDb is if nothing else an historical resource and begs the important question?\nDoes Zach Snyder share 300 points with Plutarch?\nBut how about someone we know or can identify? Who is eldest creator still alive in the IMDb database? A seemingly easy way to identify “oldest creator in IMDb” would be to seek out creators with an NA for deathYear.\nUnfortunately there are quite a few people IMDb considers living in their sunset years. IMDb idetifies 2,514 “supercentarians” - individuals 110 years of age or older - who at one time worked the film industry.\nThe Gerontology Research Group rigorously counts “supercentarians” around the world. A supercentarian is an individual equal-to, or older-than, the age of 110. At current count, there are approximately ~310 supercentarians in the world.\nClearly there is an issue with the IMDb dataset identifying 2,514 supercentarians in the film industry. There obviously are a multitude of deaths unreported in this data.\nBut, just because you’re old and you possibly “one-time-maybe did something in the film industry”, should anyone care? There are millions of people who throughout their lives have no-doubt been involved in at least 1 movie production in their lives. Does “old person who once worked on a forgotten independent movie no-one-saw” really communicate anything to us?\nI posit that anyone who did anything significant in the film industry would have their deathYear duly reported. Therefore, let’s re-start our search and see if we can arrive at a collection of individuals “significant enough in the film industry” to warrant our interest and attention.\nLet’s first try to identify “significant film productions” in our data.\nI’m going to use the measure of: “if this film had a lot of people working on it, it no doubt cost a lot of money and was of notable interest to some studio or production company.” So I’m going to count the number of crew on a film and look for a threshold for top produciton.\nHere are the quantiles for the crew counts:\n10%  20%  30%  40%  50%  60%  70%  80%  90% 100% \n10   14   16   18   19   20   21   22   24   65 \n90% of all productions have 24+ or more crew numbers working on them. I’m going to identify any person “significant” in the films industry as someone who has worked on 20+ such productions. Sorted on number_of_big_productions worked on, sure enough this yields useful information:\n\nData for Big Productions by Various Individuals, Including Age \n\n\n\n\n\n\n\n\n\nName\nBirth Year\nnumber_of_big_productions\nage\ndeathYear\n\n\n\n\nSeth MacFarlane\n1973\n2505\n51\n0\n\n\nDee Bradley Baker\n1962\n2311\n62\n0\n\n\nDan Castellaneta\n1957\n2242\n67\n0\n\n\nHank Azaria\n1964\n2191\n60\n0\n\n\nHarry Shearer\n1943\n2162\n81\n0\n\n\nEric Stuart\n1967\n2043\n57\n0\n\n\n\nThese names are all identifiable as prominent voice actors. So with this collection of notable individuals, let’s idenfity the oldest individual in this data set:\n\nWhat a find\n\n\n\n\n\n\n\n\n\nprimaryName\nbirthYear\nnumber_of_big_productions\nage\ndeathYear\n\n\n\n\nMel Brooks\n1926\n37\n98\n0\n\n\n\n\n\n&gt; show the code\n\n# Who is the oldest individual in IMDb?\nmin(NAME_BASICS$birthYear, na.rm=TRUE)\n\n# A birthyear of '4'! Is this a mistake? \nsort(unique(NAME_BASICS$birthYear))\n\n# Who are these individuals? \nNAME_BASICS |&gt; \n  filter(\n    birthYear == 4 | \n    birthYear ==  37 |\n    birthYear ==  43 | \n    birthYear == 46 | \n    birthYear == 69 | \n    birthYear == 70 |\n    birthYear == 163 | \n    birthYear == 254\n    ) |&gt; \n  select(primaryName)\n  \n# Are there really that many 110 year-olds in this database? \nNAME_BASICS |&gt;\n  filter(birthYear &lt;= 1914 & is.na(deathYear)) |&gt;\n  nrow()\n\n# Let's count the amont of crew working for a poduction \ncrew_counts_for_title &lt;- TITLE_PRINCIPALS |&gt; \n  group_by(tconst) |&gt; \n  summarize(crew_members = n()) \n\n# Can we identify the threshold for 'big production' by crew count?\nquantile(crew_counts_for_title$crew_members, probs = seq(0.1, 1, by=.1))\n\n# Top 90% of productions have 24 crew members, so let's use that threshold\nbig_productions &lt;- crew_counts_for_title |&gt; \n  filter(crew_members &gt;= 24)\n\n# Using 24 crew members as a citeria for \"big production\", this\n# identifies all of the individuals who have worked on 20 or more \n# such productions, creating the criteria we're using for \"significant \n# individuals in film and television\"\nname_ids_in_many_big_productions &lt;- big_productions |&gt; \n  inner_join(TITLE_PRINCIPALS, by=\"tconst\") |&gt;\n  group_by(nconst) |&gt; \n  summarize(number_of_big_productions = n()) |&gt; \n  filter(number_of_big_productions &gt; 20) |&gt; \n  arrange(desc(number_of_big_productions))\n\n# Mathching up these ids with names \nnames_in_many_big_productions &lt;- name_ids_in_many_big_productions |&gt;\n  inner_join(NAME_BASICS, join_by(nconst == nconst)) |&gt;\n  mutate(deathYear = ifelse(is.na(deathYear), 0, deathYear)) |&gt; \n  mutate(age = ifelse(deathYear == 0, 2024 - birthYear, deathYear - birthYear)) |&gt; \n  select(primaryName, birthYear, number_of_big_productions, age, deathYear, nconst)\n\n# Who is the oldest individual in this data set?\nnames_in_many_big_productions |&gt; \n  filter(deathYear == 0) |&gt;\n  arrange(desc(age)) |&gt;\n  slice(1)\n\n\n\n\nSingular TV Episode rated highly\n\nHank!\n\n\nseries_title\nepisode_title\nyear\n\n\n\n\nBreaking Bad\nOzymandias\n2013\n\n\n\n\n\n&gt; show the code\n\ntop_episodes &lt;- TITLE_RATINGS |&gt;\n  filter(averageRating == 10 & numVotes &gt;= 200000)\n\nepisode_details &lt;- top_episodes |&gt;\n  inner_join(TITLE_BASICS, by = \"tconst\") |&gt;\n  inner_join(TITLE_EPISODES, by = \"tconst\")\n  \nepisode_details |&gt;\n  inner_join(TITLE_BASICS, join_by(\"parentTconst\" == \"tconst\")) |&gt;\n  select(series_title = primaryTitle.y, episode_title = primaryTitle.x, year = startYear.x)\n\n\n\nStar Wars and Mark Hamill\n\nData for Mark Hamill’s Star Wars Movies\n\n\n\n\n\n\n\nprimaryName\nprimaryTitle\nstartYear\n\n\n\n\nMark Hamill\nStar Wars: Episode IV - A New Hope\n1977\n\n\nMark Hamill\nStar Wars: Episode V - The Empire Strikes Back\n1980\n\n\nMark Hamill\nStar Wars: Episode VI - Return of the Jedi\n1983\n\n\nMark Hamill\nStar Wars: Episode VIII - The Last Jedi\n2017\n\n\n\n\n\n&gt; show the code\n\nmark_hamil_popular_works_IDs &lt;- NAME_BASICS |&gt;\n  filter(primaryName == \"Mark Hamill\") |&gt;\n  separate_rows(knownForTitles, sep =\",\")\n  \nmark_hamil_popular_works_IDs |&gt; \n  inner_join(TITLE_BASICS, by = c(\"knownForTitles\" = \"tconst\")) |&gt; \n  select(primaryName, primaryTitle, startYear) |&gt;\n  arrange(startYear)\n\n\n\n\n\n\n\nWhat Television Show with at least 12 episodes has the highest average rating?\nThis is really unsatisfactory:\n\nData for TV Series and Their Average Ratings\n\n\n\n\n\n\n\nparentTconst\nprimaryTitle\naverage_rating_for_series\n\n\n\n\ntt0409579\nMade\n10\n\n\ntt11289784\nUnus Annus\n10\n\n\ntt11363282\nThe Real Housewives of Salt Lake City\n10\n\n\ntt21278628\nCowboys of Thunder\n10\n\n\ntt0060008\nThe Milton Berle Show\n9.9\n\n\ntt0168358\nParkinson\n9.9\n\n\ntt0372654\nDe película\n9.9\n\n\ntt0491739\nIn the Nick of Time\n9.9\n\n\ntt14117438\nTough Love with Hilary Farr\n9.9\n\n\ntt31806594\nWar of Faith\n9.9\n\n\n\nLet’s investigate the quantiles for number of votes:\n\nDiscounting the disotrting effect of few people voting on a television program, we’ll settle on the the top 10% most popular shows, Admittedly this may miss out on underrecognized, cult programs.\n\nI had never heard of Attack on Titan. The Internet loves Anime. \n\n\nparentTconst\nprimaryTitle\naverage_rating_for_series\n\n\n\n\ntt2560140\nAttack on Titan\n9.02\n\n\ntt0903747\nBreaking Bad\n8.96\n\n\ntt5753856\nDark\n8.89\n\n\ntt4158110\nMr. Robot\n8.89\n\n\ntt3322312\nDaredevil\n8.84\n\n\ntt1839578\nPerson of Interest\n8.80\n\n\ntt3032476\nBetter Call Saul\n8.80\n\n\ntt7660850\nSuccession\n8.75\n\n\ntt0944947\nGame of Thrones\n8.75\n\n\ntt3581920\nThe Last of Us\n8.73\n\n\n\n\n\n&gt; show the code\n\n\n# Group television shows by their parents\ntv_show_12_episodes &lt;- \n  TITLE_EPISODES |&gt; \n  group_by(parentTconst) |&gt;\n  mutate(numberOfEpisodes = n()) |&gt;  \n  filter(numberOfEpisodes &gt; 12) |&gt;\n  arrange(desc(numberOfEpisodes))\n\n# Identify the popular series by averaging the ratings of all episodes\ntv_show_12_episodes_high_rating_ID &lt;- \n  tv_show_12_episodes |&gt; \n  inner_join(TITLE_RATINGS, by = \"tconst\") |&gt; \n  select(-seasonNumber, -episodeNumber, -tconst) |&gt;\n  group_by(parentTconst) |&gt; \n  mutate(average_rating_for_series = mean(averageRating), total_votes = sum(numVotes))\n\n# Join our working list with the master Title list to identify the series\ntv_show_12_episodes_high_rating_ID |&gt; \n  inner_join(TITLE_BASICS, join_by(parentTconst == tconst)) \n  \n# Investigate the name of the most popular shows\ntv_show_12_episodes_high_rating_titles &lt;- \n  tv_show_12_episodes_high_rating_ID |&gt; \n  inner_join(TITLE_BASICS, join_by(parentTconst == tconst)) |&gt;\n  group_by(parentTconst, primaryTitle) |&gt;  \n  summarize(average_rating_for_series = first(average_rating_for_series), .groups = 'drop') |&gt;\n  arrange(desc(average_rating_for_series))  \ntv_show_12_episodes_high_rating_titles\n\n# This yielded unsatisfactory, unidentifiable series, let's try to limit by quantile\nquantile(tv_show_12_episodes_high_rating_ID$total_votes, prob = seq(0,1,.1))\n\n# Graph used to visualize the quantiles\nggplot(quantile_data, aes(x = quantile, y = votes, fill = quantile)) + \n  geom_col() + \n  scale_fill_brewer(palette = \"Set3\") +  \n  labs(title = \"Quantile Breakdown of Number of Votes\", \n       x = \"Percentage of Shows Receiving Votes\", \n       y = \"Number of Votes\") +\n   scale_y_continuous(labels = label_number(scale_cut = cut_short_scale())) +\n  theme_minimal() +\n  theme(legend.position = \"none\",  plot.title = element_text(hjust = 0.5))  \n\n# Investegating the top 10% of shows \ntv_show_12_episodes_high_rating_titles &lt;- \n  tv_show_12_episodes_high_rating_ID |&gt; \n  inner_join(TITLE_BASICS, join_by(parentTconst == tconst)) |&gt;\n  filter(total_votes &gt; 327732) |&gt;\n  group_by(parentTconst, primaryTitle) |&gt;  \n  summarize(average_rating_for_series = first(average_rating_for_series), .groups = 'drop') |&gt;\n  arrange(desc(average_rating_for_series)) |&gt;\n  slice_max(order_by = average_rating_for_series, n = 10)\n\n\n\n\nJump the Shark with Happy Days\nWikipedia suggests the famous “jumping the shark” episode from Happy Days happened episode 3 season 5.\nAfter we identify all the episdoes of Happy Days in our IMDb data we create two sets of data filtered around the pivot point of season 5 episode 3 : before shark and after shark.\nPerforming calculations on these two sets we see:\n&gt; mean(happy_days_episodes_ratings_before_shark$averageRating)\n[1] 7.484404\n\n&gt; mean(happy_days_episodes_after_shark$averageRating)\n[1] 6.878571\nHappy Days did, in fact, jump its own proverbial shark.\n\n\n&gt; show the code\n\n# Identifying the IMDb ID for television series \"Happy Days\"\nTITLE_BASICS |&gt; \n  filter(titleType == \"tvSeries\" & primaryTitle == \"Happy Days\") \n\n# Singling out all \"Happy Days\" epsidoes in our titles dataset \nhappy_days_episodes &lt;- TITLE_EPISODES |&gt; \n  filter(parentTconst == \"tt0070992\")\n\n# Joining our \"Happy Days\" episodes with their ratings\nhappy_days_episodes_ratings &lt;- happy_days_episodes |&gt; \n  inner_join(TITLE_RATINGS, by = \"tconst\")\n\n# Filtering on all episodes before the infamous \"shark jump\" episode of \n# Episode 3, Season 5\nhappy_days_episodes_ratings_before_shark &lt;- happy_days_episodes_ratings |&gt; \n  filter((seasonNumber &lt; 5) | (seasonNumber == 5 & episodeNumber &lt; 3)) \n\n# With our \"before shark\" episodes, using a filter join to create a data set\n# for \"after shark\" \nhappy_days_episodes_after_shark &lt;- happy_days_episodes_ratings |&gt;\n  anti_join(happy_days_episodes_ratings_before_shark, by = \"tconst\") \n\n# With \"before shark\" and \"after shark\" data sets, we can perform our calculations\nmean(happy_days_episodes_ratings_before_shark$averageRating)\nmean(happy_days_episodes_after_shark$averageRating)"
  },
  {
    "objectID": "mp02.html#beyond-the-spotlight",
    "href": "mp02.html#beyond-the-spotlight",
    "title": "IMDb and Me",
    "section": "Beyond the Spotlight",
    "text": "Beyond the Spotlight\nWe’re going to use ratings in IMDb to create a measure to document the significant, successful films. IMDb ratings are crowdsources from its users. Films with more votes are going to have more stable rating and there is a left skew to the distribution of films and the number of individuals who have rated the film:\n     0%     10%     20%     30%     40%     50%     60%     70%     80%     90% \n    100     120     148     187     246     332     473     738    1332    3355\nI’m going to filter out the top ~20% of rated films.\nIn an attempt to single out noteworthy remaining films, I created a statistical quantification of a movie’s positioning by evaluating both its IMDb rating and the number of IMDb users who voted on the film. This approach aims to capture both the quality (via the rating) and the popularity (via the number of votes) of the film.\nTo achieve this, I calculated Z-scores for both the film’s rating and its number of votes, which measure how far each value deviates from the mean in terms of standard deviations. I then transformed these Z-scores into cumulative probabilities using the pnorm() function, which maps the Z-scores to probabilities between 0 and 1, effectively scaling the values from 1 to 100. To emphasize quality, I assigned a weight of 2 to the film’s rating in the final combined score.\n\\[\n\\text{Total Score} = 2 \\cdot \\Phi(\\text{rating score}) + \\Phi(\\text{votes score})\n\\]\nHere are the results for the top films:\n\nTable: Top 10 Movies by Film Score\n\n\n\n\n\n\n\nPrimary Title\nStart Year\nFilm Score\n\n\n\n\nThe Shawshank Redemption\n1994\n99.97593\n\n\nThe Godfather\n1972\n99.97335\n\n\nThe Godfather Part II\n1974\n99.96597\n\n\nSchindler’s List\n1993\n99.96597\n\n\nThe Lord of the Rings: The Return of the King\n2003\n99.96597\n\n\nThe Dark Knight\n2008\n99.96597\n\n\n12 Angry Men\n1957\n99.96597\n\n\nPulp Fiction\n1994\n99.96070\n\n\nThe Lord of the Rings: The Fellowship of the Ring\n2001\n99.96070\n\n\nForrest Gump\n1994\n99.95391\n\n\n\nHere are the results for the bottom films:\n\nTable: Movies with Low Film Scores\n\n\n\n\n\n\n\nPrimary Title\nStart Year\nFilm Score\n\n\n\n\nTrack of the Moon Beast\n1976\n6.580106\n\n\nBoggy Creek II: And the Legend Continues\n1983\n6.577407\n\n\nAnne B. Real\n2003\n6.576749\n\n\nKayhan\n2018\n6.576689\n\n\nOrgy of the Dead\n1965\n6.576307\n\n\nAmazing China\n2018\n6.575677\n\n\nDarling Nikki\n2019\n6.573956\n\n\nAlien Warfare\n2019\n6.572054\n\n\nAnus Magillicutty\n2003\n6.569317\n\n\nHole in One\n2009\n6.564986\n\n\n\nMovie Box Office is reported in several popular, widely available media outlets and box office data is the type of low-stakes, hobby-friendly metrics that Internet-curated resources like Kaggle are uniquely suited for. To check the box office returns of the Total Score calculation, the Kaggle Movies Dataset was used for box office under the variable revenue.\nHowever, films can span several decades and box office figures are not as useless unless the numbers are controlled in constant dollars. To correct for this the following variable was added to our data:\n\\(\\text{Box Office Adjusted in 2024 Dollars} = \\text{Box Office} \\times \\frac{\\text{Consumer Price Index 2024}}{\\text{Consumer Price Index Historical Year}}\\)\nIt’s always interesting to view films ranked by adjust box office figures :\n\nTable: Top 10 Movies by Adjusted Box Office in 2024 Dollars\n\n\n\n\n\n\n\nPrimary Title\nStart Year\nAdjusted Box Office\n\n\n\n\nGone with the Wind\n1939\n$8,815,801,640\n\n\nAlice in Wonderland\n1951\n$6,945,453,701\n\n\nBambi\n1942\n$5,253,837,431\n\n\nStar Wars: Episode IV - A New Hope\n1977\n$4,087,964,566\n\n\nAvatar\n2009\n$4,072,386,147\n\n\nSnow White and the Seven Dwarfs\n1937\n$4,044,976,143\n\n\nTitanic\n1997\n$3,576,617,908\n\n\nCinderella\n1950\n$3,459,407,380\n\n\nThe Exorcist\n1973\n$3,194,983,975\n\n\nThe Sound of Music\n1965\n$2,829,274,085\n\n\n\nHere now is our data with our box office figures. This table suggests Film Score identifies financially successful films:\n\nTable: Top 10 Movies by Film Score and Adjusted Box Office\n\n\n\n\n\n\n\n\nPrimary Title\nStart Year\nFilm Score\nAdjusted Box Office\n\n\n\n\nThe Shawshank Redemption\n1994\n99.97593\n$59,787,899\n\n\nThe Godfather\n1972\n99.97335\n$1,838,993,851\n\n\nThe Godfather Part II\n1974\n99.96597\n$314,657,090\n\n\nSchindler’s List\n1993\n99.96597\n$695,053,325\n\n\nThe Lord of the Rings: The Return of the King\n2003\n99.96597\n$1,899,198,581\n\n\nThe Dark Knight\n2008\n99.96597\n$1,467,798,473\n\n\n12 Angry Men\n1957\n99.96597\n$11,174,529\n\n\nPulp Fiction\n1994\n99.96070\n$451,294,576\n\n\nThe Lord of the Rings: The Fellowship of the Ring\n2001\n99.96070\n$1,534,807,634\n\n\nForrest Gump\n1994\n99.95391\n$1,430,163,380\n\n\n\nWhile The Shawshank Redemption looks like a “failure” here, it famously more than made up for its lackluster Box Office returns in DVD sales, cable television licensing and streaming agreements:\n\n“It’s an incredible moneymaking asset that continues to resonate with viewers,” said Jeff Baker, the former executive vice president and general manager of Warner Bros. Home Entertainment theatrical catalog, in that Wall Street Journal piece. “Shawshank” is one of the best performers in the studio’s library, in no small part thanks to strong DVD/Blu-ray sales, not to mention streaming\n\nDoes Film Score work in reverse? Does it correctly identify “bad” movies?\nFiltering for films that are in the top 80% of movies voted on, and sorting on film_score yields some truly terrible films:\n\nTable: Movies with Moderate Film Scores and Adjusted Box Office\n\n\n\n\n\n\n\n\nPrimary Title\nStart Year\nFilm Score\nAdjusted Box Office\n\n\n\n\nThe Starfighters\n1964\n6.541835\n$0\n\n\nFinal Justice\n1984\n6.547430\n$0\n\n\nTime Chasers\n1994\n6.552881\n$0\n\n\nMega Shark vs. Mecha Shark\n2014\n6.553869\n$0\n\n\nOrgy of the Dead\n1965\n6.576307\n$0\n\n\nBoggy Creek II: And the Legend Continues\n1983\n6.577407\n$0\n\n\nTrack of the Moon Beast\n1976\n6.580106\n$0\n\n\nLevottomat 3 - kun mikään ei riitä\n2004\n6.581920\n$0\n\n\nThe Blade Master\n1983\n6.583010\n$0\n\n\nGirl in Gold Boots\n1968\n6.585128\n$0\n\n\n\nHow about examining a prominent director? Is there any direcor more prominent than Steven Spielberg? Querying for film_score, we find Steven Spielberg’s films score :\n[1] 88.5889\nEven including Indiana Jones and the Kingdom of the Crystal Skull (2008), The BFG (2016), and Always (1989) Steven Spielberg films collectively average in the top 89% of all films. film_score correctly identifies the most prominent talent in the industry.\nHow does another director compare to Steven Spielberg?\nDirecor Uwe Boll is famous for being a critically reviled filmmaker. He’s actually known as “The Worst Director in the World”.\nDoes film_score correctly identify Uwe Boll’s filmography as not-Spielbergian?\nIt certainly does. Here is the collective film_score rating of all Uwe Boll films:\n[1] 14.53452\nTo identify a film_score cut-off, I exported the data into a spread sheet for ease of viewing. I scrolled through the films assessing the quality of the neighboring films until I started to identify a good number of forgettable films. I used the entirely scientific process of scanning this list until I reached the point of “I really don’t see many good films below this number.” I found a fitting threshold with Indiana Jones and the Kingdom of the Crystal Skull (2008).\nI’m going to settle on 77.46 as the film_score threshold dividing “good movie” from “bad movie”:\n\n\n\n&gt; show the code\n\n# Surveying the distriubtion of films by number of votes\nquantile(TITLE_RATINGS$numVotes, probs=seq(0,1,0.05))\n\n# Filtering those films accordingly \nfiltered_title_ratings &lt;- TITLE_RATINGS |&gt; \n  filter(numVotes &gt; 3335)\n\n\n\n# Finding the standard deviations and mean for ratings and votes\nSD_RATING &lt;- sd(filtered_title_ratings$averageRating)\nMEAN_RATING &lt;- mean(filtered_title_ratings$averageRating)\nSD_VOTES &lt;- sd(filtered_title_ratings$numVotes)\nMEAN_VOTES &lt;-mean(filtered_title_ratings$numVotes)\n\n# Calculating the cumulative probabilities for ratings and votes \n# and created total_score metric\nfilms_scores &lt;- filtered_title_ratings |&gt; \n  inner_join(TITLE_BASICS, by = \"tconst\") |&gt; \n  filter(titleType == \"movie\") |&gt;\n  mutate(\n    rating_score = pnorm((averageRating - MEAN_RATING) / SD_RATING),\n    votes_score = pnorm((numVotes - MEAN_VOTES) / SD_VOTES)\n  ) |&gt;\n  mutate(total_score = 2 * rating_score + votes_score) |&gt;\n  arrange(desc(total_score)) \n\n\n# Re-calculating the standard deviations for total_score\nSD_SCORE &lt;- sd(films_scores$total_score)\nMEAN_SCORE &lt;- mean(films_scores$total_score)\n\n# Converting total_score to film_score via cumulative probabilities\nfilms_scores &lt;- films_scores |&gt; \n  mutate(film_score = pnorm((total_score - MEAN_SCORE) / SD_SCORE) * 100) |&gt; \n  arrange(desc(film_score)) \n\n# Checking if film_score identifies good films\nfilms_scores |&gt; \n  head(films_scores, 10) |&gt;\n  select(primaryTitle, startYear, film_score)\n\n# Checking if film_score identifies bad films\nfilms_scores |&gt; \n  tail(films_scores, 10) |&gt;\n  select(primaryTitle, startYear, film_score)\n\n##### CONSUMER PRICE INDEX CALCULATIONS #####\n\n# Reading the historical CPI figure for each year\nHISTORICAL_CPI &lt;- read.csv(\"data/mp02/HISTORICAL_CPI.csv\") |&gt;\n   mutate(year = substring(DATE,1,4))\n\n# Create a named vector for CPI figures for each year\ncpi_named_vector &lt;- setNames(HISTORICAL_CPI$CPIAUCNS, HISTORICAL_CPI$year)\n\n# Function for calculating a dollar figure by 2024 dollars\nget_dollar_adjusted_value &lt;- function(budget, year){\n  return (budget * cpi_named_vector[as.character(2024)]/cpi_named_vector[as.character(year)]) \n\n#############################################\n  \n# Add adjusted_box_office figure now with CPI calculation\nfilms_scores_box_office &lt;- films_scores |&gt;\n  inner_join(KAGGLE_DATA, join_by(tconst == imdb_id)) |&gt; \n  mutate(adjusted_box_office = get_dollar_adjusted_value(revenue, startYear))\n\n# Surveying how good film_score is at documenting box office successes\nfilms_scores_box_office |&gt; \n  select(primaryTitle, startYear, film_score, adjusted_box_office ) |&gt;\n  arrange(desc(film_score)) |&gt; \n  slice(1:10)\n\n# Surveying how good film_score is at documenting box office failures\nfilms_scores_box_office |&gt; \n  select(primaryTitle, startYear, film_score)\n  tail(films_scores, 10) |&gt;\n  \n# Finding Steven Spielberg\nss_id &lt;- NAME_BASICS |&gt; \n  filter(primaryName == \"Steven Spielberg\") |&gt; \n  pull(nconst)\n\n# Identifying all Steven Spielberg films\nss_films &lt;- TITLE_PRINCIPALS |&gt; \n  filter(nconst == ss_id[1] & category == \"director\") |&gt;\n  pull(tconst)\n\n# Calculating average score for all Steven Spielberg films\nfilms_scores_box_office |&gt;\n  filter(tconst %in% ss_films) |&gt;\n  summarize(average_film_score = mean(film_score, na.rm = TRUE)) |&gt;\n  pull(average_film_score)\n\n# Finding Uwe Boll\nub_id &lt;- NAME_BASICS |&gt; \n  filter(primaryName == \"Uwe Boll\") |&gt; \n  pull(nconst)\n\n# Identifying all Uwe Boll films\nub_films &lt;- TITLE_PRINCIPALS |&gt; \n  filter(nconst == ub_id[1] & category == \"director\") |&gt;\n  pull(tconst)\n\n# Calculating the average score for all Uwe Boll films\nfilms_scores_box_office |&gt;\n  filter(tconst %in% ub_films) |&gt;\n  summarize(average_film_score = mean(film_score, na.rm = TRUE)) |&gt;\n  pull(average_film_score)\n\n# Data Frame exported for analysis \ndf_csv &lt;- films_scores_box_office |&gt;\n  select(primaryTitle, startYear, film_score, adjusted_box_office)\n\n# Export a .csv for viewing\nwrite.csv(df_csv, \"films_scores_box_office.csv\", row.names = FALSE)"
  },
  {
    "objectID": "mp02.html#best-in-decade",
    "href": "mp02.html#best-in-decade",
    "title": "IMDb and Me",
    "section": "Best in Decade",
    "text": "Best in Decade\nAssessing the popularity of film genres across decades yields interesting insight into American Culture.\n\nWe can see Western indeed being a forgotten genre, falling out of favor by the time of the 1970s and 1980s. Same with War, likely a reflection of the fading legacy of America’s triumphant relationship with World War II. And for the horniest segment of this project, this chart does indeed document the famed Adult Entertainment Film Production Heyday of the 1970s and 1980s.\nThe existence of Comedy and Drama is pretty steady in this data. What if we were to?:\n\nRemove all Comedy and Drama films\nRemove all independent or films that did not gross any revenue\n\n\n\n\nThis yields an edifying chart as it more visably identifies the rise and fall of genre trends - with the understanding Comedy and Drama are longstanding genres that are unlikely to fall out of favor anytime soon.\n\n\n\nBureau of Labor Statistics\n\n\n\n\n&gt; show the code\n\nslim_title_basics &lt;- TITLE_BASICS |&gt; \n  filter(startYear &gt; 1940 & titleType == \"movie\") |&gt; \n  select(tconst, primaryTitle, startYear, genres, titleType) |&gt; \n  separate_rows(genres, sep = \",\") |&gt; \n    filter(!(genres %in% c(\"Music\",\"Musical\", \"Reality-TV\", \"News\",\"\\\\N\", \"Talk-Show\", \"Film-Noir\",\"Game-Show\",  \"History\",\"Biography\", \"Crime\", \"Sport\"))) |&gt;\n  mutate(startYear = as.numeric(startYear), \n         decade = floor(startYear / 10) * 10,\n         decade = factor(decade, levels = sort(unique(floor(as.numeric(startYear) / 10) * 10))))\n\ngenre_count_by_decade &lt;- slim_title_basics |&gt;\n  group_by(decade, genres) |&gt;\n  summarize(genre_count = n(), .groups = 'drop')\n\nggplot(genre_count_by_decade, aes(x = decade, y = genre_count, fill = genres)) +\n  geom_bar(stat = \"identity\", position = \"fill\", color = \"black\") +\n  scale_y_continuous(labels = scales::percent) +  # Makes the y-axis percentages\n  labs(y = \"Percentage\", x = \"Decade\", fill = \"Genres\", title = \"Genre Popularity by Decade\",\n  subtitle = \"With Independent Films\") +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5),           \n        plot.subtitle = element_text(hjust = 0.5))\n\nslim_title &lt;- films_scores |&gt; \n  filter(startYear &gt; 1940 & titleType == \"movie\") |&gt; \n  select(tconst, primaryTitle, startYear, genres, titleType) |&gt; \n  separate_rows(genres, sep = \",\") |&gt; \n    filter(!(genres %in% c(\"Music\",\"Musical\", \"Reality-TV\", \"News\",\"\\\\N\", \"Talk-Show\", \"Film-Noir\",\"Game-Show\",  \"History\",\"Biography\", \"Crime\", \"Sport\"))) |&gt;\n  mutate(startYear = as.numeric(startYear), \n         decade = floor(startYear / 10) * 10,\n         decade = factor(decade, levels = sort(unique(floor(as.numeric(startYear) / 10) * 10))))\n\ngenre_count_by_decade &lt;- slim_title |&gt;\n  group_by(decade, genres) |&gt;\n  summarize(genre_count = n(), .groups = 'drop')\n\nggplot(genre_count_by_decade, aes(x = decade, y = genre_count, fill = genres)) +\n  geom_bar(stat = \"identity\", position = \"fill\", color = \"black\") +\n  scale_y_continuous(labels = scales::percent) +  # Makes the y-axis percentages\n  labs(y = \"Percentage\", x = \"Decade\", fill = \"Genres\", title = \"Genre Popularity by Decade\",\n  subtitle = \"Without Independent Films\") +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5),           \n        plot.subtitle = element_text(hjust = 0.5))\n  \nslim_title_no_comedy_no_drama &lt;- films_scores |&gt; \n  filter(startYear &gt; 1940 & titleType == \"movie\") |&gt; \n  select(tconst, primaryTitle, startYear, genres, titleType) |&gt; \n  separate_rows(genres, sep = \",\") |&gt; \n    filter(!(genres %in% c(\"Music\",\"Musical\",\"Comedy\", \"Drama\", \"Reality-TV\", \"News\",\"\\\\N\", \"Talk-Show\", \"Film-Noir\",\"Game-Show\",  \"History\",\"Biography\", \"Crime\", \"Sport\"))) |&gt;\n  mutate(startYear = as.numeric(startYear), \n         decade = floor(startYear / 10) * 10,\n         decade = factor(decade, levels = sort(unique(floor(as.numeric(startYear) / 10) * 10))))\n\ngenre_count_by_decade_no_comedy &lt;- slim_title_no_comedy_no_drama |&gt;\n  group_by(decade, genres) |&gt;\n  summarize(genre_count = n(), .groups = 'drop')\n\nggplot(genre_count_by_decade_no_comedy, aes(x = decade, y = genre_count, fill = genres)) +\n  geom_bar(stat = \"identity\", position = \"fill\", color = \"black\") +\n  scale_y_continuous(labels = scales::percent) + \n  labs(y = \"Percentage\", x = \"Decade\", fill = \"Genres\", title = \"Genre Popularity by Decade\", subtitle = \"Without Independent films or Comedy or Drama\") +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5),           \n        plot.subtitle = element_text(hjust = 0.5))\n        \nwages &lt;- read.csv(\"data/mp02/wages.csv\")\nwages$Men &lt;- as.numeric(gsub(\",\", \"\", wages$Men))\nwages$Women &lt;- as.numeric(gsub(\",\", \"\", wages$Women))\nwages &lt;- wages[-nrow(wages), ]\n\nggplot(wages, aes(x=X)) +\n  geom_line(aes(y = Women, color = \"Women\"), size = 1.2) +\n  geom_line(aes(y = Men, color = \"Men\"), linetype = \"twodash\", size = 1.2) +\n  geom_smooth(aes(y = Women), method = \"lm\", se = FALSE, color=\"black\", linetype = \"dashed\", size = .2) +\n  geom_smooth(aes(y = Men), method = \"lm\", se = FALSE, color=\"black\", linetype = \"dashed\", size = .2) +\n  labs(y = \"Weekly Wages\", x = \"Decade\", title = \"40 Year Trend in Wages by Gender\", color=\"Gender\") +\n  scale_y_continuous(labels = dollar_format()) + \n  theme_bw() +\n  theme(plot.title = element_text(hjust = 0.5)) \n\n\n&lt;!-- genre_count_by_decade_no_comedy |&gt; finish for romance trend --&gt;\n  \n\nHere is an image detailing gender disparities in Hollywood.\n\nHere is me looking for actors who have been in prominent films. The top 2 look like a great choice!\n\nTable: Actors and Actresses by Age and Movie Count\n\n\nPrimary Name\nCategory\nAge\nMovie Count\n\n\n\n\nScarlett Johansson\nActress\n40\n35\n\n\nJake Gyllenhaal\nActor\n44\n23\n\n\nChris Evans\nActor\n43\n20\n\n\nSeth Rogen\nActor\n42\n17\n\n\nChris Hemsworth\nActor\n41\n16\n\n\nEmma Stone\nActress\n36\n16\n\n\nNatalie Portman\nActress\n43\n15\n\n\nChris Pratt\nActor\n45\n15\n\n\nRajkummar Rao\nActor\n40\n15\n\n\nKirsten Dunst\nActress\n42\n14\n\n\n\nTop Women Directors:\n\nTable: Top Women Directors by Movie Count\n\n\nPrimary Name\nCategory\nAge\nMovie Count\n\n\n\n\nLilly Wachowski\nDirector\n57\n5\n\n\nLana Wachowski\nDirector\n59\n5\n\n\nZoya Akhtar\nDirector\n52\n2\n\n\nJoan Chen\nDirector\n63\n1\n\n\nGail Mancuso\nDirector\n66\n1\n\n\nMary Elizabeth McGlynn\nDirector\n58\n1\n\n\nJessie Nelson\nDirector\nNA\n1\n\n\nMaria Schrader\nDirector\n59\n1\n\n\nReema Kagti\nDirector\nNA\n1\n\n\nOlivia Wilde\nDirector\n40\n1\n\n\n\nJordan Peele looks like a great choice…\n\nTable: Directors by Age and Movie Count\n\n\nPrimary Name\nCategory\nAge\nMovie Count\n\n\n\n\nBenny Safdie\nDirector\n38\n2\n\n\nJohn Francis Daley\nDirector\n39\n2\n\n\nOlivia Wilde\nDirector\n40\n1\n\n\nSeth Rogen\nDirector\n42\n2\n\n\nEvan Goldberg\nDirector\n42\n2\n\n\nJoseph Gordon-Levitt\nDirector\n43\n1\n\n\nFran Kranz\nDirector\n43\n1\n\n\nJordan Peele\nDirector\n45\n3\n\n\nJohn Krasinski\nDirector\n45\n2\n\n\nMert Baykal\nDirector\n45\n1\n\n\n\n\n\n&gt; show the code\n\ntop_movies &lt;- films_scores |&gt;\n  filter(film_score &gt; 77.46)\n\n\n\ntalent &lt;- TITLE_PRINCIPALS |&gt;\n  filter(tconst %in% top_movies$tconst, category %in% c(\"actor\", \"actress\", \"director\")) |&gt;\n  inner_join(names_in_many_big_productions, by = \"nconst\") |&gt;\n  inner_join(films_scores, by = \"tconst\") |&gt;\n  group_by(nconst, primaryName, category, age) |&gt;\n  summarize(movie_count = n()) |&gt;\n  arrange(desc(movie_count))\n\ntalent_again &lt;- TITLE_PRINCIPALS |&gt;\n  filter(tconst %in% top_movies$tconst, category %in% c(\"actor\", \"actress\", \"director\")) |&gt;\n  inner_join(names_in_many_big_productions, by = \"nconst\") |&gt;\n  inner_join(films_scores, by = \"tconst\") |&gt;\n  group_by(nconst, primaryName, category, age) |&gt;\n  summarize(movie_count = n(), mean_film_score = mean(film_score, na.rm = TRUE)) |&gt;\n  arrange(desc(movie_count))\n\n\ntop_actors &lt;- talent_again |&gt;\n  filter(category %in% c(\"actor\", \"actress\"), age &gt;= 20 & age &lt;= 45 & movie_count &gt; 4) |&gt;\n  arrange(desc(mean_film_score))\n\nactors_summary &lt;- top_actors |&gt; \n  group_by(category) |&gt; \n  summarize(total_movie = sum(movie_count), number_of_performers = n(), score = mean(mean_film_score))\n\nglimpse(top_actors)\n\nggplot(top_actors, aes(x = mean_film_score, fill = category)) +\n  geom_density(alpha = 0.6) +\n  labs(title = \"Density of Mean Film Scores by Gender\", x = \"Mean Film Score\", y = \"Density\") +\n  theme_minimal()\n  \nggplot(top_actors, aes(x = movie_count, y = mean_film_score, color = category)) +\n  geom_point(alpha = 0.5, size = 3) +\n  labs(title = \"Movie Count vs. Mean Film Score by Gender\", x = \"Movie Count\", y = \"Mean Film Score\", color = NULL) +  \n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5)) \n\ntop_directors &lt;- talent |&gt; \n  filter(category == \"director\") \n\ntop_directors |&gt; \n  arrange(age, desc(movie_count)) |&gt;\n  head(20)\n\nWitness jumps out at me here :\n\nTable: Films by Year and Film Score\n\n\nTitle\nYear\nFilm Score\n\n\n\n\nVertigo\n1958\n99.68\n\n\nThe Handmaiden\n2016\n99.20\n\n\nMatch Point\n2005\n97.93\n\n\nRoja\n1992\n92.96\n\n\nWitness\n1985\n92.05\n\n\nThe Wind\n1928\n91.02\n\n\nSpark: L.I.F.E.\n2023\n90.81\n\n\nA Story from Chikamatsu\n1954\n90.76\n\n\nTo Catch a Thief\n1955\n89.51\n\n\nVaalee\n1999\n89.06\n\n\n\n\nromance_thrillers &lt;- TITLE_BASICS |&gt; filter(titleType == “movie”) |&gt;\nfilter(grepl(“Romance”, genres) & grepl(“Thriller”, genres)) |&gt; inner_join(films_scores, by = “tconst”) |&gt; filter(film_score &gt; 77.46) |&gt; select(primaryTitle.x, startYear.x, film_score) |&gt; arrange(desc(film_score))\nhead(romance_thrillers, 19)\nnrow(romance_thrillers) glimpse(romance_thrillers) glimpse(films_scores)\n\n&gt; show me the code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n–&gt;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n–&gt;\n\n\n\n\n\n\n\n\n\n\n–&gt;"
  },
  {
    "objectID": "mp02.html#section",
    "href": "mp02.html#section",
    "title": "IMDb and Me",
    "section": "",
    "text": "polarizing_films &lt;- movie_lens_and_IMDb |&gt; group_by(IMDbId, primaryTitle, startYear, genres) |&gt; summarise(mean_rating = mean(rating), sd_rating = sd(rating), num_ratings = n()) |&gt; arrange(desc(sd_rating)) |&gt; select(-IMDbId)\npolarizing_films\npolarizing_films &lt;- movie_lens_and_IMDb |&gt; group_by(movieId, primaryTitle, startYear, genres) |&gt; summarise(mean_rating = mean(rating), iqr_rating = IQR(rating), num_ratings = n()) |&gt; arrange(desc(iqr_rating))\npolarizing_films &lt;- movie_lens_and_IMDb |&gt; group_by(movieId, primaryTitle, startYear, genres) |&gt; summarise(mean_rating = mean(rating), var_rating = var(rating), num_ratings = n()) |&gt; arrange(desc(var_rating))\n\nmovie_lens_and_IMDb_and_kaggle &lt;- movie_lens_and_IMDb |&gt; inner_join(KAGGLE_DATA, join_by(tconst == IMDb_id))\nmovie_lens_and_IMDb_and_kaggle\nget_dollar_adjusted_value &lt;- function(budget, year){ return (budget * cpi_named_vector[as.character(2024)]/cpi_named_vector[as.character(year)]) }\nvotes_budget &lt;- movie_lens_and_IMDb_and_kaggle |&gt; group_by(IMDbId, primaryTitle, budget, startYear, revenue) |&gt; summarize(num_votes = n()) |&gt; mutate(adjusted_budget = get_dollar_adjusted_value(budget, startYear), adjusted_profit = get_dollar_adjusted_value(revenue, startYear) - get_dollar_adjusted_value(budget, startYear) )\nmodel_profit &lt;- lm(votes_budget\\(num_votes ~  votes_budget\\)adjusted_profit)\nreg_line &lt;- function(x_val, model){ return(coef(model)[1] + coef(model)[2] * x_val) }\nvotes_budget_profit &lt;- votes_budget |&gt; mutate(popularity_over_profit = num_votes - reg_line(adjusted_profit, model_profit)) |&gt; arrange(desc(popularity_over_profit))\n\nggplot(data = votes_budget_profit, aes(x = adjusted_profit, y = num_votes )) + geom_point(alpha = 0.1) + geom_smooth(method=“lm”, se=FALSE)\nmodel_budget &lt;- lm(votes_budget\\(num_votes ~  votes_budget\\)adjusted_budget)\nvotes_budget_budget &lt;- votes_budget |&gt; mutate(popularity_over_budget = num_votes - reg_line(adjusted_budget, model_profit)) |&gt; arrange(desc(popularity_over_budget))\nprint(votes_budget_budget, n =100)\n\nvotes_budget |&gt; arrange(desc(adjusted_budget)) |&gt; print(n = 100)\ntop_500_polarizing_films &lt;- head(polarizing_films, 500)\ntop_500_polarizing_films_w_budget &lt;- top_500_polarizing_films |&gt; inner_join(KAGGLE_DATA, join_by(IMDbId == IMDb_id))\ntop_500_polarizing_films_w_budget"
  }
]