[
  {
    "objectID": "final_project.html",
    "href": "final_project.html",
    "title": "Traffic Calming and Property Values In New York City: Analyzing the Economic Impact of the Prospect Park Bike Lane",
    "section": "",
    "text": "AUTHORS  Jason Amey  Clinta Varghese\nI. Introduction\nII. Methodology\nIII. Data Visualization and Dynamic Analysis\nIV. Findings\nV. Conclusion\n\n\n\nPark Slope in Brooklyn is a neighborhood of considerable interest. In 2010, it became the center of significant media attention following the New York City Department of Transportation’s (NYC DOT) decision to remove a lane of traffic on Prospect Park West - the street that runs adjacent to Prospect Park - and install a protected bike lane. This decision sparked a lawsuit and drew widespread media attention1.\nDespite the initial backlash, the project proved to be a success in terms of safety metrics2 and has since become a beloved feature of the neighborhood. However, an intriguing question remains: did this transformative change have an impact on the corridor’s real estate values?\nThis project seeks to evaluate the potential effects of the bike lane installation on property values along Prospect Park West. To provide a comprehensive analysis, it compares Prospect Park West to all parallel streets in Park Slope - 8th Avenue, 7th Avenue, 6th Avenue and 5th Avenue - as well as Prospect Park Southwest—a park-facing street in the adjacent neighborhood of Windsor Terrace.\nThrough this evaluation, the project seeks to determine whether the bike lane influenced changes in the local real estate market, while also opening the door to a broader exploration of urban economics and the ever-topical issue of rising real estate values in New York City.\n\n\n\nThis project investigates historical property tax assessment values in Park Slope and Windsor Terrace, Brooklyn, using data sourced from the New York City Department of Finance Property Assessment Roll Archives. These archives provide a complete digital repository of property valuation data available from 2010 to the present.\n\n\nProperty Valuation Source: The NYC Department of Finance’s online Property Assessment Roll Archives, includes dozens of property valuation metrics for all residential and commercial properties throughout New York City.\nSelected Metric: After careful consideration, the team settled on using the New Full Value, Total (NEW_FV_T) as the best metric reflecting market value of the land, the property and surrounding neighborhood trends.\nChallenges with Disparate Data: The data spanned multiple years and formats, with differing data schemes. To create a consistent dataset, significant processing and cleaning were undertaken to standardize the information.\n\n\n\nTax Classifications : NYC property is divided into four tax classifications, each reflecting a different type of property3:\n\nClass 1: Primarily residential properties of up to three units, including family homes and small mixed-use properties (e.g., homes with small stores or offices).\nClass 2: Larger residential properties such as rentals, cooperatives, and condominiums. This class is further subdivided:\n\n2A: 4–6 unit rental buildings\n2B: 7–10 unit rental buildings\n2C: 2–10 unit cooperative or condominium buildings\n\nClass 2 (general): Residential properties with 11 or more units.\nClass 3: Utility properties.\nClass 4: Commercial and industrial properties.\n\nFor this study, we focused on residential property classifications: 1, 1A, 1B, 1C, 1D, 2, 2A, 2B, 2C. These categories captured the majority of residential properties relevant to Park Slope and Windsor Terrace.\nGeographic Scope: To ensure the analysis remained localized, the data was filtered for properties located within the relevant ZIP codes for Park Slope and Windsor Terrace.\nFinal Dataset: The cleaned and filtered dataset was saved for analysis. While the dataset covers 2010 to the present, it is acknowledged that a more robust analysis would incorporate property values from earlier periods, especially prior to the installation of the Prospect Park bike lane. This would provide greater insight into pre- and post-infrastructure changes and their potential impact on property values. The pre-2010 data is available at the New York City Municipal Archive4\nMapping: To visualize the change in property values in Park Slope, .shp files (shapefiles) were collected from the NYC Department of City Planning’s Lot Selector tool. The shapefiles were downloaded to map property parcels in the Park Slope area, enabling detailed spatial visualizations and the highlighting of valuation trends over time.\n\n\n\nData Transformation: Code was developed to manipulate the original tax assessment data, enabling the calculation of percentage changes in property values across any selected range of years. For each year pair within the specified range, the code calculates the changes and appends these as new columns to the dataset, facilitating a comparison of year-over-year trends across various streets.\nStatistical Analysis: A t-test was chosen to evaluate whether percentage changes in property values on Prospect Park West (PPW) differ significantly from those on parallel streets, such as 8th Avenue, 7th Avenue, and 5th Avenue. The t-test is appropriate for comparing the means of two independent groups, particularly when examining whether observed differences in property value trends are likely due to random variation or reflect genuine distinctions.\nt-test Table: It was decided to create a t-test results table to provide a clear and formatted summary of the statistical comparisons performed for PPW and its neighboring streets. The table is organized by year ranges, making it easy to identify periods of significant valuation changes. By presenting the results in a structured format, the table concisely summarizes the outcomes of potentially dozens of tests at once. This approach leverages the capabilities of statistical software, providing an efficient means to review a broad range of analyses.\nRidge Plot: Ridge plots were created to add deeper insight into the density distributions of percentage changes in property values by street.\nBox Plot: It was decided to create box plot visualizations for another visualization of the distribution of changes, highlighting trends, outliers, and differences in variability.\nPercentage Change Summary: Summary tables were developed to aggregate key statistics for percentage changes by street. These tables calculate the mean and standard deviation for each street, providing a quantitative overview of average trends and their variability. The summaries were designed to contextualize the insights from the box and ridge plots, offering concrete data to support the observed patterns in property value changes.\n\n\n\n\nTo effectively communicate the findings from this analysis, a dynamic web-based app was developed using Shiny and deployed on shinyapps.io. This application integrates geospatial and statistical visualizations to provide an interactive and user-friendly platform for exploring property value trends in Park Slope and Windsor Terrace. The visualizations were designed to cater to various analytical needs, from exploring geographic trends to examining statistical patterns in property values.\n\n\nLeaflet Maps: The app utilizes the leaflet R package to render detailed maps based on the .shp files collected from the NYC Department of City Planning. These interactive maps allow users to explore property parcels and their associated change in property valuations.\nTime Frame Selector: The app includes an interface that allows users to specify the time frame of interest. This feature enables customized analyses, making it easy to compare property values before and after events of interest.\nHere is a link to the application :\nhttps://jasonamey.shinyapps.io/park-slope-property-app/\n\n\n\n\nImmediately following the installation of the Prospect Park bike lane in 2010, there was a noticeable statistical difference in the uptick of property values on Prospect Park West compared to its neighboring streets. Analysis of property assessment data from 2010 through 2013 revealed a consistent and significant increase in values along Prospect Park West, suggesting a positive correlation between the bike lane installation and property value appreciation:\n\n\nThis is evident in the following ridge plot, with Prospect Park West leading other corridors in Park Slope:\n\n\nThis map visualization, highlights the dominance of green on Prospect Park West compared to its neighboring streets:\n\n\n…but this analysis is arguably limited by the immeasurable economic influence of gentrification and the outsized desirability of Park Slope as a premier residential neighborhood in Brooklyn.\nHere is that story in images.\n5th Avenue, Park Slope 2011:\n\n5th Avenue, Park Slope 2023:\n\n\nHighlighted by these images, with the financial crisis of the late 2000s in the rear-view mirror, property values in Park Slope skyrocketed, reflecting both the neighborhood’s intrinsic appeal and broader market forces. While the installation of the Prospect Park bike lane may have contributed to local value increases, isolating its specific impact from these larger trends presents a challenge in the face of gentrification.\nThis ridge plot vividly demonstrates the dominant role of gentrification in driving property value changes in Park Slope during the mid-2010s.The clustering of density curves toward higher percentage changes underscores the broad and profound market pressures, as the neighborhood became increasingly attractive to higher-income residents amplifying the impact of gentrification during this period:\n\n\nReflecting the influx of new businesses, you can see the pronounced effect of gentrification with the high peaks of the 2 dominant commercial stretches in Park Slope: 5th avenue and 7th avenue during the prime growth years of the2010’s:\n\n\nThe pre-Covid 2010’s truly represented a period of healthy valuations of Park Slope real estate:\n\n The dominance of gentrication arguable muddles the ability to fully assess the influence of the Prospect Park West traffic calming project on Park Slope real estate values. As evidence in this document of t-tests, there is a series of inconclusive results during this period of explosive growth in the Park Slope real estate market:\n\n\nYet, one of the advantages of creating an interactive application, is the ability to draw dynamic analysis. This visualization clearly highlights the impact of the Covid pandemic on Park Slope real estate:\n\n\nThe app also demostrates how resilient and stable property values on Prospect Park West remain - compared the extreme variance seen on other streets - as evidenced by their performance during the height of pandemic:\n\n\nThis project originally intended to be a static analysis of statistical significance of the change in property values on Prospect Park West compared to comparable corridors in Park Slope from 2011 (1-year after installation of the Prospect Park bike lane) to today. Despite muddle results in the mid-2010’s, this table communicates a statistically significant increase in property values on Prospect Park West from 2011-2023:\n\n\n\n\n\nThis analysis provides valuable insights into the relationship between urban infrastructure improvements and property values, yet it is undeniably complicated by the dominant forces of gentrification.\nThe impact of traffic calming projects, like the Prospect Park bike lane, cannot be fully disentangled from the broader market pressures of an overheated real estate market in neighborhoods like Brooklyn’s beloved Park Slope.\nIt raises the question:\nAre such projects inherently tied to gentrifying areas, creating a chicken-and-egg dilemma? Are traffic calming initiatives a catalyst or a product of gentrification?\nTo gain a deeper understanding, future research could examine property values from earlier periods, such as the 1990s and 2000s, and perform a paired t-test on Prospect Park West properties to assess pre- and post-intervention trends. However, challenges exist with the t-tests due to issues like bimodal distributions, extreme outliers, and inconsistent variance in the data. These statistical limitations suggest the need for more robust methodologies, such as non-parametric tests or resampling techniques like bootstrapping, to better capture the complexities and variability in the dataset."
  },
  {
    "objectID": "final_project.html#footnotes",
    "href": "final_project.html#footnotes",
    "title": "Traffic Calming and Property Values In New York City: Analyzing the Economic Impact of the Prospect Park Bike Lane",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nFoderaro, L. W. (2011, March 8). Bike lane debate in Brooklyn is set for court. The New York Times. Retrieved December 19, 2024, from https://www.nytimes.com/2011/03/09/nyregion/09bike.html↩︎\nProject for Public Spaces. (n.d.). Prospect Park West: Overcoming controversy to create safety and mobility benefits in Brooklyn. Retrieved December 19, 2024, from https://www.pps.org/article/prospect-park-west-overcoming-controversy-to-create-safety-and-mobility-benefits-in-brooklyn↩︎\nNew York City Department of Finance. (n.d.). Definitions of property assessment terms. NYC.gov. Retrieved December 19, 2024, from https://www.nyc.gov/site/finance/property/definitions-of-property-assessment-terms.page↩︎\nNew York City Department of Records and Information Services. (n.d.). Municipal archives. NYC.gov. Retrieved December 19, 2024, from https://www.nyc.gov/site/records/about/municipal-archives.page↩︎"
  },
  {
    "objectID": "jason_amey_final_report.html",
    "href": "jason_amey_final_report.html",
    "title": "Final Project Individual Report: Jason Amey",
    "section": "",
    "text": "Final Project Individual Report: Jason Amey\nWhat follows are my contributions our project on assessing Park Slope real estate values with the 2010 completion of the Prospect Park West bike lane.\nHere is a singular Git repo for the project :\nhttps://github.com/jasonamey/park-slope-west-property-analysis/tree/main\nMuch of my contributions for this project can be summed in this image:\n\nHandling and processing 10GB of government tax assessment valuation data across multiple file types was immeasurably challenging. The project began with data acquisition, which involved identifying and scraping URLs for the data files hosted by the NYC Department of Finance.\nThe NYC Department of Finance site relies on JavaScript for rendering and did not allow for direct scraping, so the HTML for the site itself was downloaded and scraped locally. The code was designed to scrape and process links to .zip files containing NYC tax assessment archive data from the local HTML file.\n\n\n&gt; show the code\n\n# Code extracts all the links to the .zip files from the NYC tax assessment archive data\n# HTML was copy/pasted and saved locally as page is generated with javascript\n\nlibrary(httr2)\nlibrary(rvest)\n\nhtml_file_path &lt;- \"final_project/src/scripts/scraping/dept_of_finance_tax_assessment_archives.html\"\n\nbase_url &lt;- \"https://www.nyc.gov\"\n\nwebpage &lt;- read_html(html_file_path)\n# Extract all &lt;a&gt; tags\nlinks &lt;- webpage |&gt;\n  html_elements(\"a\") |&gt;\n  html_attr(\"href\")\n\n# Append the base URL for relative links\nfull_urls &lt;- ifelse(grepl(\"^/\", links), paste0(base_url, links), links)\n\n# Filter for .zip files and for those related to /tar/tc or 2023/2024\nfull_urls &lt;- full_urls[grepl(\"\\\\.zip$\", full_urls)] # Only .zip files\nfull_urls &lt;- full_urls[grepl(\"tar/tc|2023|2024\", full_urls)] # Match files for 2023 and 2024\n\n# Create a data frame to store the results\nurl_data &lt;- data.frame(\n  full_urls\n)\n\n# Define the output file path and save the data\noutput_csv_path &lt;- \"final_project/data/tax_class_urls_t.csv\"\nwrite.csv(url_data, file = output_csv_path, row.names = FALSE)\n\nThese files were downloaded using R and organized into a temporary directory structure to ensure proper categorization by year and type. This initial step, supported by the use of libraries like httr2 and readr, was essential for maintaining an efficient workflow while managing the sheer volume of files.\n\n\n&gt; show the code\n\n# Cycle through all urls to download\nfor (i in 1:length(urls)) {\n  url &lt;- urls[i]\n\n  temp_file &lt;- tempfile(fileext = \".zip\")  # Create a temporary file for downloading the .zip\n  temp_dir &lt;- \"final_project/data/temp\"    # Define the temporary directory path\n\n  response &lt;- request(url) |&gt;             # Send an HTTP request to the URL\n    req_perform()                         # Perform the request and download the file\n\n  writeBin(resp_body_raw(response), temp_file)  # Save the downloaded file to the temporary location\n\n  unzip(temp_file, exdir = temp_dir)      # Unzip the contents into the temporary directory\n\n  # Add a sleep to avoid hitting rate limits\n  Sys.sleep(1)\n}\n\nPARENT_DIR &lt;- \"final_project/data/temp\"\n\nfor (i in 9:23) {                         # Loop through a specified range of years (e.g., 2009 to 2023)\n  dir_name &lt;- paste(PARENT_DIR, i, sep = \"/\")  # Create a folder for each year\n  dir.create(dir_name, showWarnings = FALSE)  # Ensure the directory is created if it doesn't already exist\n  print(paste(\"Created directory:\", dir_name))\n}\n\nThe next step focused on file extraction and organization. .zip files from the downloaded data were restructured into folders reflecting their source year. Code was created to rename extracted files with a consistent naming convention, making it easier to track and combine data later in the process. This work required handling .zip, .mdb, and .txt files. For instance,\n\n\n&gt; show the code\n\n\nPARENT_DIR &lt;- \"final_project/data/temp\"\n\nfor (i in 9:23) {\n  dir_name &lt;- paste(PARENT_DIR, i, sep = \"/\")\n  dir.create(dir_name, showWarnings = FALSE)\n  print(paste(\"Created directory:\", dir_name))\n}\n\nFILES &lt;- list.files(\"final_project/data/temp\", pattern = \"\\\\.zip$\", full.names = TRUE)\n\nfor (i in 1:length(FILES)) {\n  number &lt;- sub(\".*_(\\\\d+)\\\\.zip$\", \"\\\\1\", FILES[i])\n\n  # Extract the number from the file name\n  number &lt;- sub(\".*_(\\\\d+)\\\\.zip$\", \"\\\\1\", FILES[i])\n\n  # New Directory\n  dir_name &lt;- paste0(\"final_project/data/temp/\", number)\n\n  # New file path\n  new_file_path &lt;- file.path(dir_name, basename(FILES[i]))\n\n  # Move the file to the corresponding directory\n  file.rename(FILES[i], new_file_path)\n}\n\n\nBASE_DIR &lt;- \"final_project/data/temp\"\n\n# List subdirectories in the base directory\nfolders &lt;- list.dirs(BASE_DIR, full.names = TRUE, recursive = FALSE)\n\n# Loop through each folder\nfor (folder in folders) {\n  # Skip if the folder name is not numeric (i.e., avoid the 'extracted' folder)\n  folder_name &lt;- basename(folder)\n  if (!grepl(\"^\\\\d+$\", folder_name)) {\n    next\n  }\n\n  # List .zip files in the folder\n  zip_files &lt;- list.files(folder, pattern = \"\\\\.zip$\", full.names = TRUE)\n\n  # Extract and rename files\n  for (zip_file in zip_files) {\n    # Create a subfolder named \"extracted\" within the current folder\n    extracted_dir &lt;- file.path(folder, \"extracted\")\n    if (!dir.exists(extracted_dir)) {\n      dir.create(extracted_dir)\n    }\n\n    # Unzip the file into the 'extracted' directory within the current folder\n    unzip(zip_file, exdir = extracted_dir)\n\n    # List all files extracted in the 'extracted' folder\n    extracted_files &lt;- list.files(extracted_dir, full.names = TRUE)\n\n    # Rename each extracted file by adding the folder name to the file\n    for (extracted_file in extracted_files) {\n      new_name &lt;- paste0(folder_name, \"_\", basename(extracted_file))\n      new_path &lt;- file.path(extracted_dir, new_name)\n\n      file.rename(extracted_file, new_path)\n    }\n  }\n}\n\n# Define the base directory\nBASE_DIR &lt;- \"final_project/data/temp\"\n\n# List all subdirectories (recursive) and find those named 'extracted'\nextracted_folders &lt;- list.dirs(BASE_DIR, full.names = TRUE, recursive = TRUE)\nextracted_folders &lt;- extracted_folders[grepl(\"extracted$\", extracted_folders)]\n\n# Loop through each 'extracted' folder\nfor (folder in extracted_folders) {\n  # List all files in the 'extracted' folder\n  extracted_files &lt;- list.files(folder, full.names = TRUE)\n\n  # Move each file to the 'temp' directory\n  for (file in extracted_files) {\n    # Define the new location in the 'temp' directory\n    new_location &lt;- file.path(BASE_DIR, basename(file))\n\n    # Move the file\n    file.rename(file, new_location)\n  }\n\n  # Remove the now-empty 'extracted' folder\n  unlink(folder, recursive = TRUE)\n}\n\n# List all items in the directory\nall_items &lt;- list.files(BASE_DIR, full.names = TRUE)\n\n# Filter for directories\nfolders &lt;- all_items[file.info(all_items)$isdir]\n\n# List all .mdb and .txt files\nfiles_to_keep &lt;- list.files(BASE_DIR, pattern = \"\\\\.(mdb|txt)$\", full.names = TRUE)\n\n# Loop through each folder and delete it if it's not a .mdb or .txt file\nfor (folder in folders) {\n  if (!(folder %in% files_to_keep)) {\n    unlink(folder, recursive = TRUE)\n  }\n}\n\nThe .mdb files had to be converted to .csv format using an external cli toolmdb-export. (I unsuccessfully tried to write a bash script to handle this) i.e :\nMacBook-Pro temp % mdb-tables 16_16_tc1.mdb\nNameTable tc1\nMacBook-Pro temp % mdb-export 16_16_tc1.mdb tc1 &gt; 16_TC1.csv\n\nThe end result looked like this: \nWith the files prepared, data cleaning and integration became the focus. Working with dozens of variables across different data definitions required creating a pipeline to standardizing variable names, trimming space, and ensure consistent formatting. Borough-specific filtering was implemented to focus on Brooklyn properties (Borough 3) with ZIP codes in the target neighborhoods (11215 and 11218) and the correct tax class (2, 2A, 2B, 2C). Additionally, each property was assigned a unique ID based on its BLOCK and LOT number, which facilitated the merging across the different datasets. All of the relevant varialbes were selected.\n\n\n&gt; show the code\n\nbase_property_info_1 &lt;- read_csv(csv_files[1]) |&gt;\n  mutate(BORO = as.numeric(BORO)) |&gt;\n  filter(BORO == 3) |&gt;\n  mutate(LOT = trimws(LOT)) |&gt;\n  mutate(ID = paste(BLOCK, LOT, sep = \"-\")) |&gt;\n  filter(ZIP %in% c(11215, 11218)) |&gt;\n  select(ID, BORO, BLOCK, LOT, TXCL, ZIP, YRB, TOT_UNIT, RES_UNIT, STR_NAME, BLDGCL, HNUM_LO, HNUM_HI)\n\nbase_property_info_2 &lt;- read_csv(csv_files[2]) |&gt;\n  mutate(BORO = as.numeric(BORO)) |&gt;\n  filter(BORO == 3, TXCL %in% c(\"2\", \"2A\", \"2B\", \"2C\")) |&gt;\n  mutate(LOT = trimws(LOT)) |&gt;\n  mutate(ID = paste(BLOCK, LOT, sep = \"-\")) |&gt;\n  filter(ZIP %in% c(11215, 11218)) |&gt;\n  select(ID, BORO, BLOCK, LOT, TXCL, ZIP, YRB, TOT_UNIT, RES_UNIT, STR_NAME, BLDGCL, HNUM_LO, HNUM_HI)\n\nbase_joined &lt;- bind_rows(base_property_info_1, base_property_info_2)\n\n# Merge the 2 classes of commercial properties\nfor (i in seq(1, length(csv_files), by = 2)) {\n  number &lt;- sub(\".*\\\\/([0-9]+)_.+\", \"\\\\1\", csv_files[i])\n  col_name &lt;- paste(\"VALUE\", number, sep = \"_\")\n  first &lt;- read.csv(csv_files[i])\n  second &lt;- read.csv(csv_files[i + 1])\n  first_t &lt;- first |&gt;\n    mutate(BORO = as.numeric(BORO)) |&gt;\n    filter(BORO == 3) |&gt;\n    mutate(LOT = trimws(LOT)) |&gt;\n    mutate(ID = paste(BLOCK, LOT, sep = \"-\")) |&gt;\n    rename(!!sym(col_name) := NEW_FV_T) |&gt;\n    filter(ZIP %in% c(11215, 11218)) |&gt;\n    select(ID, !!sym(col_name))\n\n  second_t &lt;- second |&gt;\n    mutate(BORO = as.numeric(BORO)) |&gt;\n    filter(BORO == 3, TXCL %in% c(\"2\", \"2A\", \"2B\", \"2C\")) |&gt;\n    mutate(LOT = trimws(LOT)) |&gt;\n    mutate(ID = paste(BLOCK, LOT, sep = \"-\")) |&gt;\n    rename(!!sym(col_name) := NEW_FV_T) |&gt;\n    filter(ZIP %in% c(11215, 11218)) |&gt;\n    select(ID, !!sym(col_name))\n\n  joined &lt;- bind_rows(second_t, first_t)\n\n  reference_base_2010_2019 &lt;- reference_base_2010_2019 |&gt;\n    left_join(joined, by = \"ID\")\n}\n\nreference_base_copy &lt;- reference_base_2010_2019\n\nCombining datasets for analysis involved merging and aggregating files from different years and formats. For the years 2010 to 2019, .csv files were used to construct a base dataset of residential properties, focusing on relevant fields such as tax class, total units, residential units, and street name. But for 2020 to 2023, .txt files were parsed using string manipulation functions to extract and process tab-delimited data, ensuring alignment with the structure of the earlier dataset.\nThe .txt files are a sight to behold: \nOnce the 2019 - 2023 .txt files were processed, they were merged with the 2011 - 2019 data and saved as one singular .csv file.\n\n\n&gt; show the code\n\n\n# Open all the .txt files for 2020 - 2023\ntxt_files &lt;- list.files(\"final_project/data/temp\", pattern = \"\\\\.(txt|TXT)$\", full.names = TRUE)\n\n# Process all .txt files from 2020 - 2023 then merge with the base_copy file of 2010 - 2019 values\nfor (i in seq(1, length(csv_files), by = 2)) {\n  # change to i\n  number &lt;- sub(\".*/(\\\\d+)_.*\", \"\\\\1\", txt_files[i])\n\n  col_name &lt;- paste(\"VALUE\", number, sep = \"_\")\n\n  # change to i\n  first &lt;- readLines(txt_files[i])\n  first_records &lt;- strsplit(first, \"\\n\")\n  first_parsed &lt;- lapply(first_records, function(record) strsplit(record, \"\\t\"))\n  first_rows &lt;- do.call(rbind, lapply(first_parsed, function(x) unlist(x)))\n  first_df &lt;- as.data.frame(first_rows)\n\n  # change to i\n  second &lt;- readLines(txt_files[i + 1])\n  second_records &lt;- strsplit(second, \"\\n\")\n  second_parsed &lt;- lapply(second_records, function(record) strsplit(record, \"\\t\"))\n  second_rows &lt;- do.call(rbind, lapply(second_parsed, function(x) unlist(x)))\n  second_df &lt;- as.data.frame(second_rows)\n\n  nrow(first_df)\n  nrow(second_df)\n\n  first_t &lt;- first_df |&gt;\n    mutate(V3 = as.numeric(V3), V4 = as.numeric(V4), V25 = as.numeric(V25)) |&gt;\n    mutate(V78 = trimws(V78)) |&gt;\n    filter(V78 %in% c(\"11215\", \"11218\")) |&gt;\n    mutate(V34 = trimws(V34)) |&gt;\n    filter(V2 == \"3\", V34 %in% c(\"1\", \"1A\", \"1B\", \"1C\", \"1D\", \"2\", \"2A\", \"2B\", \"2C\")) |&gt;\n    mutate(ID = paste(V3, V4, sep = \"-\")) |&gt;\n    rename(!!sym(col_name) := V25) |&gt;\n    select(ID, !!sym(col_name))\n\n  second_t &lt;- second_df |&gt;\n    mutate(V3 = as.numeric(V3), V4 = as.numeric(V4), V25 = as.numeric(V25)) |&gt;\n    mutate(V78 = trimws(V78)) |&gt;\n    filter(V78 %in% c(\"11215\", \"11218\")) |&gt;\n    mutate(V34 = trimws(V34)) |&gt;\n    filter(V2 == \"3\", V34 %in% c(\"1\", \"1A\", \"1B\", \"1C\", \"1D\", \"2\", \"2A\", \"2B\", \"2C\")) |&gt;\n    mutate(ID = paste(V3, V4, sep = \"-\")) |&gt;\n    rename(!!sym(col_name) := V25) |&gt;\n    select(ID, !!sym(col_name))\n\n  joined_2020_2023 &lt;- bind_rows(second_t, first_t)\n\n  reference_base_copy &lt;- reference_base_copy |&gt;\n    inner_join(joined_2020_2023, by = \"ID\")\n}\n\n# No understanding why, but this code is creating duplicates of ID \"874-68\"\nreference_base_copy_t &lt;- reference_base_copy |&gt;\n  filter(ID != \"874-68\")\n\n# Save data to a .csv\nwrite.csv(x = reference_base_copy_t, \"final_project/data/finance/2010_2023_park_slope_values.csv\")\n\nThroughout this process, testing and debugging played a critical role in ensuring the integrity of the data. Duplicate IDs, inconsistent formatting, and discrepancies in variable definitions were recurring issues that required careful attention.\nOf note:\n\nthe problems created by \"2C\" vs. \"2C \" (shoot me)\nphantom, unrecognizable, bug-creating UTF-8 characters randomly created in 10GB+ of government data\nthe NAs (so many NAs)\nthe inconsistencies in year-to-year reporting\n\nAfter (painful) cleaning, parsing, and integration, the dataset was saved as a consolidated .csv file.\nAll told, that process above was honestly ~5 seasons of The Sopranos worth of coding (fyi: this is still the funniest scene in the series), and by far the majority of work I did for the project.\nI think it’s very cool I was able to do this.\nBeyond that, I :\n\nCreated the scaffolding of the interactive app to integrate the data (Clinta did the hard work of getting the maps with leaflet to work)\nDid all of the work involved with hosting the app (This is harder than it sounds - the code needs to be migrated to another, older, computer. Don’t ask.)"
  },
  {
    "objectID": "individual_report.html",
    "href": "individual_report.html",
    "title": "Final Project Individual Report: Jason Amey",
    "section": "",
    "text": "Final Project Individual Report: Jason Amey\nWhat follows are my contributions our project on assessing Park Slope real estate values with the 2010 completion of the Prospect Park West bike lane.\nHere is a singular Git repo for the project :\nhttps://github.com/jasonamey/park-slope-west-property-analysis/tree/main\nMuch of my contributions for this project can be summed in this image:\n\nHandling and processing 10GB of government tax assessment valuation data across multiple file types was immeasurably challenging. The project began with data acquisition, which involved identifying and scraping URLs for the data files hosted by the NYC Department of Finance.\nThe NYC Department of Finance site relies on JavaScript for rendering and did not allow for direct scraping, so the HTML for the site itself was downloaded and scraped locally. The code was designed to scrape and process links to .zip files containing NYC tax assessment archive data from the local HTML file.\n\n\n&gt; show the code\n\n# Code extracts all the links to the .zip files from the NYC tax assessment archive data\n# HTML was copy/pasted and saved locally as page is generated with javascript\n\nlibrary(httr2)\nlibrary(rvest)\n\nhtml_file_path &lt;- \"final_project/src/scripts/scraping/dept_of_finance_tax_assessment_archives.html\"\n\nbase_url &lt;- \"https://www.nyc.gov\"\n\nwebpage &lt;- read_html(html_file_path)\n# Extract all &lt;a&gt; tags\nlinks &lt;- webpage |&gt;\n  html_elements(\"a\") |&gt;\n  html_attr(\"href\")\n\n# Append the base URL for relative links\nfull_urls &lt;- ifelse(grepl(\"^/\", links), paste0(base_url, links), links)\n\n# Filter for .zip files and for those related to /tar/tc or 2023/2024\nfull_urls &lt;- full_urls[grepl(\"\\\\.zip$\", full_urls)] # Only .zip files\nfull_urls &lt;- full_urls[grepl(\"tar/tc|2023|2024\", full_urls)] # Match files for 2023 and 2024\n\n# Create a data frame to store the results\nurl_data &lt;- data.frame(\n  full_urls\n)\n\n# Define the output file path and save the data\noutput_csv_path &lt;- \"final_project/data/tax_class_urls_t.csv\"\nwrite.csv(url_data, file = output_csv_path, row.names = FALSE)\n\nThese files were downloaded using R and organized into a temporary directory structure to ensure proper categorization by year and type. This initial step, supported by the use of libraries like httr2 and readr, was essential for maintaining an efficient workflow while managing the sheer volume of files.\n\n\n&gt; show the code\n\n# Cycle through all urls to download\nfor (i in 1:length(urls)) {\n  url &lt;- urls[i]\n\n  temp_file &lt;- tempfile(fileext = \".zip\")  # Create a temporary file for downloading the .zip\n  temp_dir &lt;- \"final_project/data/temp\"    # Define the temporary directory path\n\n  response &lt;- request(url) |&gt;             # Send an HTTP request to the URL\n    req_perform()                         # Perform the request and download the file\n\n  writeBin(resp_body_raw(response), temp_file)  # Save the downloaded file to the temporary location\n\n  unzip(temp_file, exdir = temp_dir)      # Unzip the contents into the temporary directory\n\n  # Add a sleep to avoid hitting rate limits\n  Sys.sleep(1)\n}\n\nPARENT_DIR &lt;- \"final_project/data/temp\"\n\nfor (i in 9:23) {                         # Loop through a specified range of years (e.g., 2009 to 2023)\n  dir_name &lt;- paste(PARENT_DIR, i, sep = \"/\")  # Create a folder for each year\n  dir.create(dir_name, showWarnings = FALSE)  # Ensure the directory is created if it doesn't already exist\n  print(paste(\"Created directory:\", dir_name))\n}\n\nThe next step focused on file extraction and organization. .zip files from the downloaded data were restructured into folders reflecting their source year. Code was created to rename extracted files with a consistent naming convention, making it easier to track and combine data later in the process. This work required handling .zip, .mdb, and .txt files. For instance,\n\n\n&gt; show the code\n\n\nPARENT_DIR &lt;- \"final_project/data/temp\"\n\nfor (i in 9:23) {\n  dir_name &lt;- paste(PARENT_DIR, i, sep = \"/\")\n  dir.create(dir_name, showWarnings = FALSE)\n  print(paste(\"Created directory:\", dir_name))\n}\n\nFILES &lt;- list.files(\"final_project/data/temp\", pattern = \"\\\\.zip$\", full.names = TRUE)\n\nfor (i in 1:length(FILES)) {\n  number &lt;- sub(\".*_(\\\\d+)\\\\.zip$\", \"\\\\1\", FILES[i])\n\n  # Extract the number from the file name\n  number &lt;- sub(\".*_(\\\\d+)\\\\.zip$\", \"\\\\1\", FILES[i])\n\n  # New Directory\n  dir_name &lt;- paste0(\"final_project/data/temp/\", number)\n\n  # New file path\n  new_file_path &lt;- file.path(dir_name, basename(FILES[i]))\n\n  # Move the file to the corresponding directory\n  file.rename(FILES[i], new_file_path)\n}\n\n\nBASE_DIR &lt;- \"final_project/data/temp\"\n\n# List subdirectories in the base directory\nfolders &lt;- list.dirs(BASE_DIR, full.names = TRUE, recursive = FALSE)\n\n# Loop through each folder\nfor (folder in folders) {\n  # Skip if the folder name is not numeric (i.e., avoid the 'extracted' folder)\n  folder_name &lt;- basename(folder)\n  if (!grepl(\"^\\\\d+$\", folder_name)) {\n    next\n  }\n\n  # List .zip files in the folder\n  zip_files &lt;- list.files(folder, pattern = \"\\\\.zip$\", full.names = TRUE)\n\n  # Extract and rename files\n  for (zip_file in zip_files) {\n    # Create a subfolder named \"extracted\" within the current folder\n    extracted_dir &lt;- file.path(folder, \"extracted\")\n    if (!dir.exists(extracted_dir)) {\n      dir.create(extracted_dir)\n    }\n\n    # Unzip the file into the 'extracted' directory within the current folder\n    unzip(zip_file, exdir = extracted_dir)\n\n    # List all files extracted in the 'extracted' folder\n    extracted_files &lt;- list.files(extracted_dir, full.names = TRUE)\n\n    # Rename each extracted file by adding the folder name to the file\n    for (extracted_file in extracted_files) {\n      new_name &lt;- paste0(folder_name, \"_\", basename(extracted_file))\n      new_path &lt;- file.path(extracted_dir, new_name)\n\n      file.rename(extracted_file, new_path)\n    }\n  }\n}\n\n# Define the base directory\nBASE_DIR &lt;- \"final_project/data/temp\"\n\n# List all subdirectories (recursive) and find those named 'extracted'\nextracted_folders &lt;- list.dirs(BASE_DIR, full.names = TRUE, recursive = TRUE)\nextracted_folders &lt;- extracted_folders[grepl(\"extracted$\", extracted_folders)]\n\n# Loop through each 'extracted' folder\nfor (folder in extracted_folders) {\n  # List all files in the 'extracted' folder\n  extracted_files &lt;- list.files(folder, full.names = TRUE)\n\n  # Move each file to the 'temp' directory\n  for (file in extracted_files) {\n    # Define the new location in the 'temp' directory\n    new_location &lt;- file.path(BASE_DIR, basename(file))\n\n    # Move the file\n    file.rename(file, new_location)\n  }\n\n  # Remove the now-empty 'extracted' folder\n  unlink(folder, recursive = TRUE)\n}\n\n# List all items in the directory\nall_items &lt;- list.files(BASE_DIR, full.names = TRUE)\n\n# Filter for directories\nfolders &lt;- all_items[file.info(all_items)$isdir]\n\n# List all .mdb and .txt files\nfiles_to_keep &lt;- list.files(BASE_DIR, pattern = \"\\\\.(mdb|txt)$\", full.names = TRUE)\n\n# Loop through each folder and delete it if it's not a .mdb or .txt file\nfor (folder in folders) {\n  if (!(folder %in% files_to_keep)) {\n    unlink(folder, recursive = TRUE)\n  }\n}\n\nThe .mdb files had to be converted to .csv format using an external cli toolmdb-export. (I unsuccessfully tried to write a bash script to handle this) i.e :\nMacBook-Pro temp % mdb-tables 16_16_tc1.mdb\nNameTable tc1\nMacBook-Pro temp % mdb-export 16_16_tc1.mdb tc1 &gt; 16_TC1.csv\n\nThe end result looked like this: \nWith the files prepared, data cleaning and integration became the focus. Working with dozens of variables across different data definitions required creating a pipeline to standardizing variable names, trimming space, and ensure consistent formatting. Borough-specific filtering was implemented to focus on Brooklyn properties (Borough 3) with ZIP codes in the target neighborhoods (11215 and 11218) and the correct tax class (2, 2A, 2B, 2C). Additionally, each property was assigned a unique ID based on its BLOCK and LOT number, which facilitated the merging across the different datasets. All of the relevant varialbes were selected.\n\n\n&gt; show the code\n\nbase_property_info_1 &lt;- read_csv(csv_files[1]) |&gt;\n  mutate(BORO = as.numeric(BORO)) |&gt;\n  filter(BORO == 3) |&gt;\n  mutate(LOT = trimws(LOT)) |&gt;\n  mutate(ID = paste(BLOCK, LOT, sep = \"-\")) |&gt;\n  filter(ZIP %in% c(11215, 11218)) |&gt;\n  select(ID, BORO, BLOCK, LOT, TXCL, ZIP, YRB, TOT_UNIT, RES_UNIT, STR_NAME, BLDGCL, HNUM_LO, HNUM_HI)\n\nbase_property_info_2 &lt;- read_csv(csv_files[2]) |&gt;\n  mutate(BORO = as.numeric(BORO)) |&gt;\n  filter(BORO == 3, TXCL %in% c(\"2\", \"2A\", \"2B\", \"2C\")) |&gt;\n  mutate(LOT = trimws(LOT)) |&gt;\n  mutate(ID = paste(BLOCK, LOT, sep = \"-\")) |&gt;\n  filter(ZIP %in% c(11215, 11218)) |&gt;\n  select(ID, BORO, BLOCK, LOT, TXCL, ZIP, YRB, TOT_UNIT, RES_UNIT, STR_NAME, BLDGCL, HNUM_LO, HNUM_HI)\n\nbase_joined &lt;- bind_rows(base_property_info_1, base_property_info_2)\n\n# Merge the 2 classes of commercial properties\nfor (i in seq(1, length(csv_files), by = 2)) {\n  number &lt;- sub(\".*\\\\/([0-9]+)_.+\", \"\\\\1\", csv_files[i])\n  col_name &lt;- paste(\"VALUE\", number, sep = \"_\")\n  first &lt;- read.csv(csv_files[i])\n  second &lt;- read.csv(csv_files[i + 1])\n  first_t &lt;- first |&gt;\n    mutate(BORO = as.numeric(BORO)) |&gt;\n    filter(BORO == 3) |&gt;\n    mutate(LOT = trimws(LOT)) |&gt;\n    mutate(ID = paste(BLOCK, LOT, sep = \"-\")) |&gt;\n    rename(!!sym(col_name) := NEW_FV_T) |&gt;\n    filter(ZIP %in% c(11215, 11218)) |&gt;\n    select(ID, !!sym(col_name))\n\n  second_t &lt;- second |&gt;\n    mutate(BORO = as.numeric(BORO)) |&gt;\n    filter(BORO == 3, TXCL %in% c(\"2\", \"2A\", \"2B\", \"2C\")) |&gt;\n    mutate(LOT = trimws(LOT)) |&gt;\n    mutate(ID = paste(BLOCK, LOT, sep = \"-\")) |&gt;\n    rename(!!sym(col_name) := NEW_FV_T) |&gt;\n    filter(ZIP %in% c(11215, 11218)) |&gt;\n    select(ID, !!sym(col_name))\n\n  joined &lt;- bind_rows(second_t, first_t)\n\n  reference_base_2010_2019 &lt;- reference_base_2010_2019 |&gt;\n    left_join(joined, by = \"ID\")\n}\n\nreference_base_copy &lt;- reference_base_2010_2019\n\nCombining datasets for analysis involved merging and aggregating files from different years and formats. For the years 2010 to 2019, .csv files were used to construct a base dataset of residential properties, focusing on relevant fields such as tax class, total units, residential units, and street name. But for 2020 to 2023, .txt files were parsed using string manipulation functions to extract and process tab-delimited data, ensuring alignment with the structure of the earlier dataset.\nThe .txt files are a sight to behold: \nOnce the 2019 - 2023 .txt files were processed, they were merged with the 2011 - 2019 data and saved as one singular .csv file.\n\n\n&gt; show the code\n\n\n# Open all the .txt files for 2020 - 2023\ntxt_files &lt;- list.files(\"final_project/data/temp\", pattern = \"\\\\.(txt|TXT)$\", full.names = TRUE)\n\n# Process all .txt files from 2020 - 2023 then merge with the base_copy file of 2010 - 2019 values\nfor (i in seq(1, length(csv_files), by = 2)) {\n  # change to i\n  number &lt;- sub(\".*/(\\\\d+)_.*\", \"\\\\1\", txt_files[i])\n\n  col_name &lt;- paste(\"VALUE\", number, sep = \"_\")\n\n  # change to i\n  first &lt;- readLines(txt_files[i])\n  first_records &lt;- strsplit(first, \"\\n\")\n  first_parsed &lt;- lapply(first_records, function(record) strsplit(record, \"\\t\"))\n  first_rows &lt;- do.call(rbind, lapply(first_parsed, function(x) unlist(x)))\n  first_df &lt;- as.data.frame(first_rows)\n\n  # change to i\n  second &lt;- readLines(txt_files[i + 1])\n  second_records &lt;- strsplit(second, \"\\n\")\n  second_parsed &lt;- lapply(second_records, function(record) strsplit(record, \"\\t\"))\n  second_rows &lt;- do.call(rbind, lapply(second_parsed, function(x) unlist(x)))\n  second_df &lt;- as.data.frame(second_rows)\n\n  nrow(first_df)\n  nrow(second_df)\n\n  first_t &lt;- first_df |&gt;\n    mutate(V3 = as.numeric(V3), V4 = as.numeric(V4), V25 = as.numeric(V25)) |&gt;\n    mutate(V78 = trimws(V78)) |&gt;\n    filter(V78 %in% c(\"11215\", \"11218\")) |&gt;\n    mutate(V34 = trimws(V34)) |&gt;\n    filter(V2 == \"3\", V34 %in% c(\"1\", \"1A\", \"1B\", \"1C\", \"1D\", \"2\", \"2A\", \"2B\", \"2C\")) |&gt;\n    mutate(ID = paste(V3, V4, sep = \"-\")) |&gt;\n    rename(!!sym(col_name) := V25) |&gt;\n    select(ID, !!sym(col_name))\n\n  second_t &lt;- second_df |&gt;\n    mutate(V3 = as.numeric(V3), V4 = as.numeric(V4), V25 = as.numeric(V25)) |&gt;\n    mutate(V78 = trimws(V78)) |&gt;\n    filter(V78 %in% c(\"11215\", \"11218\")) |&gt;\n    mutate(V34 = trimws(V34)) |&gt;\n    filter(V2 == \"3\", V34 %in% c(\"1\", \"1A\", \"1B\", \"1C\", \"1D\", \"2\", \"2A\", \"2B\", \"2C\")) |&gt;\n    mutate(ID = paste(V3, V4, sep = \"-\")) |&gt;\n    rename(!!sym(col_name) := V25) |&gt;\n    select(ID, !!sym(col_name))\n\n  joined_2020_2023 &lt;- bind_rows(second_t, first_t)\n\n  reference_base_copy &lt;- reference_base_copy |&gt;\n    inner_join(joined_2020_2023, by = \"ID\")\n}\n\n# No understanding why, but this code is creating duplicates of ID \"874-68\"\nreference_base_copy_t &lt;- reference_base_copy |&gt;\n  filter(ID != \"874-68\")\n\n# Save data to a .csv\nwrite.csv(x = reference_base_copy_t, \"final_project/data/finance/2010_2023_park_slope_values.csv\")\n\nThroughout this process, testing and debugging played a critical role in ensuring the integrity of the data. Duplicate IDs, inconsistent formatting, and discrepancies in variable definitions were recurring issues that required careful attention.\nOf note:\n\nthe problems created by \"2C\" vs. \"2C \" (shoot me)\nphantom, unrecognizable, bug-creating UTF-8 characters randomly created in 10GB+ of government data\nthe NAs (so many NAs)\nthe inconsistencies in year-to-year reporting\n\nAfter (painful) cleaning, parsing, and integration, the dataset was saved as a consolidated .csv file.\nAll told, that process above was honestly ~5 seasons of The Sopranos worth of coding (fyi: this is still the funniest scene in the series), and by far the majority of work I did for the project.\nI think it’s very cool I was able to do this.\nBeyond that, I :\n\nCreated the scaffolding of the interactive app to integrate the data (Clinta did the hard work of getting the maps with leaflet to work)\nDid all of the work involved with hosting the app (This is harder than it sounds - the code needs to be migrated to another, older, computer. Don’t ask.)"
  },
  {
    "objectID": "summary_report.html",
    "href": "summary_report.html",
    "title": "Traffic Calming and Property Values In New York City: Analyzing the Economic Impact of the Prospect Park Bike Lane",
    "section": "",
    "text": "AUTHORS  Jason Amey  INDIVIDUAL REPORT\nClinta Varghesehttps  INDIVIDUAL REPORT\nI. Introduction\nII. Methodology\nIII. Data Visualization and Dynamic Analysis\nIV. Findings\nV. Conclusion\n\n\n\nPark Slope in Brooklyn is a neighborhood of considerable interest. In 2010, it became the center of significant media attention following the New York City Department of Transportation’s (NYC DOT) decision to remove a lane of traffic on Prospect Park West - the street that runs adjacent to Prospect Park - and install a protected bike lane. This decision sparked a lawsuit and drew widespread media attention1.\nDespite the initial backlash, the project proved to be a success in terms of safety metrics2 and has since become a beloved feature of the neighborhood. However, an intriguing question remains: did this transformative change have an impact on the corridor’s real estate values?\nThis project seeks to evaluate the potential effects of the bike lane installation on property values along Prospect Park West. To provide a comprehensive analysis, it compares Prospect Park West to all parallel streets in Park Slope - 8th Avenue, 7th Avenue, 6th Avenue and 5th Avenue - as well as Prospect Park Southwest—a park-facing street in the adjacent neighborhood of Windsor Terrace.\nThrough this evaluation, the project seeks to determine whether the bike lane influenced changes in the local real estate market, while also opening the door to a broader exploration of urban economics and the ever-topical issue of rising real estate values in New York City.\n\n\n\nThis project investigates historical property tax assessment values in Park Slope and Windsor Terrace, Brooklyn, using data sourced from the New York City Department of Finance Property Assessment Roll Archives. These archives provide a complete digital repository of property valuation data available from 2010 to the present.\n\n\nProperty Valuation Source: The NYC Department of Finance’s online Property Assessment Roll Archives, includes dozens of property valuation metrics for all residential and commercial properties throughout New York City.\nSelected Metric: After careful consideration, the team settled on using the New Full Value, Total (NEW_FV_T) as the best metric reflecting market value of the land, the property and surrounding neighborhood trends.\nChallenges with Disparate Data: The data spanned multiple years and formats, with differing data schemes. To create a consistent dataset, significant processing and cleaning were undertaken to standardize the information.\n\n\n\nTax Classifications : NYC property is divided into four tax classifications, each reflecting a different type of property3:\n\nClass 1: Primarily residential properties of up to three units, including family homes and small mixed-use properties (e.g., homes with small stores or offices).\nClass 2: Larger residential properties such as rentals, cooperatives, and condominiums. This class is further subdivided:\n\n2A: 4–6 unit rental buildings\n2B: 7–10 unit rental buildings\n2C: 2–10 unit cooperative or condominium buildings\n\nClass 2 (general): Residential properties with 11 or more units.\nClass 3: Utility properties.\nClass 4: Commercial and industrial properties.\n\nFor this study, we focused on residential property classifications: 1, 1A, 1B, 1C, 1D, 2, 2A, 2B, 2C. These categories captured the majority of residential properties relevant to Park Slope and Windsor Terrace.\nGeographic Scope: To ensure the analysis remained localized, the data was filtered for properties located within the relevant ZIP codes for Park Slope and Windsor Terrace.\nFinal Dataset: The cleaned and filtered dataset was saved for analysis. While the dataset covers 2010 to the present, it is acknowledged that a more robust analysis would incorporate property values from earlier periods, especially prior to the installation of the Prospect Park bike lane. This would provide greater insight into pre- and post-infrastructure changes and their potential impact on property values. The pre-2010 data is available at the New York City Municipal Archive4\nMapping: To visualize the change in property values in Park Slope, .shp files (shapefiles) were collected from the NYC Department of City Planning’s Lot Selector tool. The shapefiles were downloaded to map property parcels in the Park Slope area, enabling detailed spatial visualizations and the highlighting of valuation trends over time.\n\n\n\nData Transformation: Code was developed to manipulate the original tax assessment data, enabling the calculation of percentage changes in property values across any selected range of years. For each year pair within the specified range, the code calculates the changes and appends these as new columns to the dataset, facilitating a comparison of year-over-year trends across various streets.\nStatistical Analysis: A t-test was chosen to evaluate whether percentage changes in property values on Prospect Park West (PPW) differ significantly from those on parallel streets, such as 8th Avenue, 7th Avenue, and 5th Avenue. The t-test is appropriate for comparing the means of two independent groups, particularly when examining whether observed differences in property value trends are likely due to random variation or reflect genuine distinctions.\nt-test Table: It was decided to create a t-test results table to provide a clear and formatted summary of the statistical comparisons performed for PPW and its neighboring streets. The table is organized by year ranges, making it easy to identify periods of significant valuation changes. By presenting the results in a structured format, the table concisely summarizes the outcomes of potentially dozens of tests at once. This approach leverages the capabilities of statistical software, providing an efficient means to review a broad range of analyses.\nRidge Plot: Ridge plots were created to add deeper insight into the density distributions of percentage changes in property values by street.\nBox Plot: It was decided to create box plot visualizations for another visualization of the distribution of changes, highlighting trends, outliers, and differences in variability.\nPercentage Change Summary: Summary tables were developed to aggregate key statistics for percentage changes by street. These tables calculate the mean and standard deviation for each street, providing a quantitative overview of average trends and their variability. The summaries were designed to contextualize the insights from the box and ridge plots, offering concrete data to support the observed patterns in property value changes.\n\n\n\n\nTo effectively communicate the findings from this analysis, a dynamic web-based app was developed using Shiny and deployed on shinyapps.io. This application integrates geospatial and statistical visualizations to provide an interactive and user-friendly platform for exploring property value trends in Park Slope and Windsor Terrace. The visualizations were designed to cater to various analytical needs, from exploring geographic trends to examining statistical patterns in property values.\n\n\nLeaflet Maps: The app utilizes the leaflet R package to render detailed maps based on the .shp files collected from the NYC Department of City Planning. These interactive maps allow users to explore property parcels and their associated change in property valuations.\nTime Frame Selector: The app includes an interface that allows users to specify the time frame of interest. This feature enables customized analyses, making it easy to compare property values before and after events of interest.\nHere is a link to the application :\nhttps://jasonamey.shinyapps.io/park-slope-property-app/\n\n\n\n\nImmediately following the installation of the Prospect Park bike lane in 2010, there was a noticeable statistical difference in the uptick of property values on Prospect Park West compared to its neighboring streets. Analysis of property assessment data from 2010 through 2013 revealed a consistent and significant increase in values along Prospect Park West, suggesting a positive correlation between the bike lane installation and property value appreciation:\n\n\nThis is evident in the following ridge plot, with Prospect Park West leading other corridors in Park Slope:\n\n\nThis map visualization, highlights the dominance of green on Prospect Park West compared to its neighboring streets:\n\n\n…but this analysis is arguably limited by the immeasurable economic influence of gentrification and the outsized desirability of Park Slope as a premier residential neighborhood in Brooklyn.\nHere is that story in images.\n5th Avenue, Park Slope 2011:\n\n5th Avenue, Park Slope 2023:\n\n\nHighlighted by these images, with the financial crisis of the late 2000s in the rear-view mirror, property values in Park Slope skyrocketed, reflecting both the neighborhood’s intrinsic appeal and broader market forces. While the installation of the Prospect Park bike lane may have contributed to local value increases, isolating its specific impact from these larger trends presents a challenge in the face of gentrification.\nThis ridge plot vividly demonstrates the dominant role of gentrification in driving property value changes in Park Slope during the mid-2010s.The clustering of density curves toward higher percentage changes underscores the broad and profound market pressures, as the neighborhood became increasingly attractive to higher-income residents amplifying the impact of gentrification during this period:\n\n\nReflecting the influx of new businesses, you can see the pronounced effect of gentrification with the high peaks of the 2 dominant commercial stretches in Park Slope: 5th avenue and 7th avenue during the prime growth years of the2010’s:\n\n\nThe pre-Covid 2010’s truly represented a period of healthy valuations of Park Slope real estate:\n\n The dominance of gentrication arguable muddles the ability to fully assess the influence of the Prospect Park West traffic calming project on Park Slope real estate values. As evidence in this document of t-tests, there is a series of inconclusive results during this period of explosive growth in the Park Slope real estate market:\n\n\nYet, one of the advantages of creating an interactive application, is the ability to draw dynamic analysis. This visualization clearly highlights the impact of the Covid pandemic on Park Slope real estate:\n\n\nThe app also demostrates how resilient and stable property values on Prospect Park West remain - compared the extreme variance seen on other streets - as evidenced by their performance during the height of pandemic:\n\n\nThis project originally intended to be a static analysis of statistical significance of the change in property values on Prospect Park West compared to comparable corridors in Park Slope from 2011 (1-year after installation of the Prospect Park bike lane) to today. Despite muddle results in the mid-2010’s, this table communicates a statistically significant increase in property values on Prospect Park West from 2011-2023:\n\n\n\n\n\nThis analysis provides valuable insights into the relationship between urban infrastructure improvements and property values, yet it is undeniably complicated by the dominant forces of gentrification.\nThe impact of traffic calming projects, like the Prospect Park bike lane, cannot be fully disentangled from the broader market pressures of an overheated real estate market in neighborhoods like Brooklyn’s beloved Park Slope.\nIt raises the question:\nAre such projects inherently tied to gentrifying areas, creating a chicken-and-egg dilemma? Are traffic calming initiatives a catalyst or a product of gentrification?\nTo gain a deeper understanding, future research could examine property values from earlier periods, such as the 1990s and 2000s, and perform a paired t-test on Prospect Park West properties to assess pre- and post-intervention trends. However, challenges exist with the t-tests due to issues like bimodal distributions, extreme outliers, and inconsistent variance in the data. These statistical limitations suggest the need for more robust methodologies, such as non-parametric tests or resampling techniques like bootstrapping, to better capture the complexities and variability in the dataset."
  },
  {
    "objectID": "summary_report.html#footnotes",
    "href": "summary_report.html#footnotes",
    "title": "Traffic Calming and Property Values In New York City: Analyzing the Economic Impact of the Prospect Park Bike Lane",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nFoderaro, L. W. (2011, March 8). Bike lane debate in Brooklyn is set for court. The New York Times. Retrieved December 19, 2024, from https://www.nytimes.com/2011/03/09/nyregion/09bike.html↩︎\nProject for Public Spaces. (n.d.). Prospect Park West: Overcoming controversy to create safety and mobility benefits in Brooklyn. Retrieved December 19, 2024, from https://www.pps.org/article/prospect-park-west-overcoming-controversy-to-create-safety-and-mobility-benefits-in-brooklyn↩︎\nNew York City Department of Finance. (n.d.). Definitions of property assessment terms. NYC.gov. Retrieved December 19, 2024, from https://www.nyc.gov/site/finance/property/definitions-of-property-assessment-terms.page↩︎\nNew York City Department of Records and Information Services. (n.d.). Municipal archives. NYC.gov. Retrieved December 19, 2024, from https://www.nyc.gov/site/records/about/municipal-archives.page↩︎"
  }
]