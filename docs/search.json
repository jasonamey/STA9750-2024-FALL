[
  {
    "objectID": "mp01.html",
    "href": "mp01.html",
    "title": "Jason Amey Mini Project 01",
    "section": "",
    "text": "Public transit in the United States serves a critical role in urban mobility. Serving millions of commuters while reducing congestion, pollution, and reliance on personal vehicles, transit is a critical institution in the success of the United States.\nHowever there exists a wide variation in the fiscal efficiency of these systems. Understanding these financial dimensions is essential for evaluating both the sustainability and performance of transit services.\nThis report explores data from major U.S. public transit systems, with analysis focused on factors such as: fare revenue per mile, vehicle revenue miles (VRM), unlinked passenger trips (UPT), and the ratio of expenses to fare-box recovery.\nThe data thus provides insights into important components of tranist analysis including: which systems operate most efficiently, which modes of transport generate the most revenue, and how these metrics differ throughout the United States.\nUsing tools from the R programming language, we explore these trends over time along with the influence of population density, geography, and mode-type on a transit system’s financial outcomes. Through this exploration, we hope to better understand the complex relationship among transit usage, financial sustainability, and regional transit characteristics.\n\n\nif(!require(\"tidyverse\")) install.packages(\"tidyverse\")\nlibrary(tidyverse)\n\nif(!require(\"DT\")) install.packages(\"DT\")\nlibrary(DT)\n\nif(!require(\"stringr\")) install.packages(\"stringr\")\nlibrary(stringr)\n\nif(!require(\"lubridate\")) install.packages(\"lubridate\")\nlibrary(lubridate)\n\nFARES &lt;- readxl::read_xlsx(\"data/mp-01/2022_fare_revenue.xlsx\") |&gt;\n  select(-`State/Parent NTD ID`,\n         -`Reporter Type`,\n         -`Reporting Module`,\n         -`TOS`,\n         -`Passenger Paid Fares`,\n         -`Organization Paid Fares`) |&gt;\n  filter(`Expense Type` == \"Funds Earned During Period\") |&gt;\n  select(-`Expense Type`)\n\nEXPENSES &lt;- readr::read_csv(\"data/mp-01/2022_expenses.csv\") |&gt;\n  select(`NTD ID`,\n         `Agency`,\n         `Total`,\n         `Mode`) |&gt;\n  mutate(`NTD ID` = as.integer(`NTD ID`)) |&gt;\n  rename(Expenses = Total) |&gt;\n  group_by(`NTD ID`, `Mode`) |&gt;\n  summarize(Expenses = sum(Expenses)) |&gt;\n  ungroup()\n\nTRIPS &lt;- readxl::read_xlsx(\"data/mp-01/2022_ridership.xlsx\", sheet=\"UPT\") |&gt;\n  filter(`Mode/Type of Service Status` == \"Active\") |&gt;\n  select(-`Legacy NTD ID`,\n         -`Reporter Type`,\n         -`Mode/Type of Service Status`,\n         -`UACE CD`,\n         -`TOS`) |&gt;\n  pivot_longer(-c(`NTD ID`:`3 Mode`),\n               names_to=\"month\",\n               values_to=\"UPT\") |&gt;\n  drop_na() |&gt;\n  mutate(month=my(month)) # Parse _m_onth _y_ear date specs\n\nMILES &lt;- readxl::read_xlsx(\"data/mp-01/2022_ridership.xlsx\", sheet=\"VRM\") |&gt;\n  filter(`Mode/Type of Service Status` == \"Active\") |&gt;\n  select(-`Legacy NTD ID`,\n         -`Reporter Type`,\n         -`Mode/Type of Service Status`,\n         -`UACE CD`,\n         -`TOS`) |&gt;\n  pivot_longer(-c(`NTD ID`:`3 Mode`),\n               names_to=\"month\",\n               values_to=\"VRM\") |&gt;\n  drop_na() |&gt;\n  group_by(`NTD ID`, `Agency`, `UZA Name`,\n           `Mode`, `3 Mode`, month) |&gt;\n  summarize(VRM = sum(VRM)) |&gt;\n  ungroup() |&gt;\n  mutate(month=my(month)) # Parse _m_onth _y_ear date specs\n\nUSAGE &lt;- inner_join(TRIPS, MILES) |&gt;\n  mutate(`NTD ID` = as.integer(`NTD ID`))\n\nFINANCIALS &lt;- inner_join(FARES, EXPENSES, join_by(`NTD ID`, `Mode`))\n\nFINANCIALS &lt;- FINANCIALS |&gt;\n  rename(\n         \"mode\" = \"Mode\"\n  )\n\nFINANCIALS &lt;- FINANCIALS |&gt;\n  mutate(mode=case_when(\n    mode == \"HR\" ~ \"Heavy Rail\",\n    mode == \"DR\" ~ \"Demand Response\",\n    mode == \"FB\" ~ \"Ferry Boat\",\n    mode == \"MB\" ~ \"Motor Bus\",\n    mode == \"SR\" ~ \"Streetcar\",\n    mode == \"TB\" ~ \"Trolleybus\",\n    mode == \"VP\" ~ \"Vanpool\",\n    mode == \"CB\" ~ \"Commuter Bus\",\n    mode == \"RB\" ~ \"Bus Rapid Transit\",\n    mode == \"LR\" ~ \"Light Rail\",\n    mode == \"YR\" ~ \"Hybrid Rail\",\n    mode == \"MG\" ~ \"Guided Transit (Monorail)\",\n    mode == \"CR\" ~ \"Commuter Rail\",\n    mode == \"AR\" ~ \"Alaska Railroad\",\n    mode == \"TR\" ~ \"Tramway\",\n    mode == \"HR\" ~ \"Heavy Rail\",\n    mode == \"IP\" ~ \"Inclined Plane\",\n    mode == \"PB\" ~ \"Publico\",\n    mode == \"CC\" ~ \"Cable Car\",\n    TRUE ~ \"Unknown\"))"
  },
  {
    "objectID": "mp01.html#fiscal-characteristics-of-major-us-public-transit-systems",
    "href": "mp01.html#fiscal-characteristics-of-major-us-public-transit-systems",
    "title": "Jason Amey Mini Project 01",
    "section": "",
    "text": "Public transit in the United States serves a critical role in urban mobility. Serving millions of commuters while reducing congestion, pollution, and reliance on personal vehicles, transit is a critical institution in the success of the United States.\nHowever there exists a wide variation in the fiscal efficiency of these systems. Understanding these financial dimensions is essential for evaluating both the sustainability and performance of transit services.\nThis report explores data from major U.S. public transit systems, with analysis focused on factors such as: fare revenue per mile, vehicle revenue miles (VRM), unlinked passenger trips (UPT), and the ratio of expenses to fare-box recovery.\nThe data thus provides insights into important components of tranist analysis including: which systems operate most efficiently, which modes of transport generate the most revenue, and how these metrics differ throughout the United States.\nUsing tools from the R programming language, we explore these trends over time along with the influence of population density, geography, and mode-type on a transit system’s financial outcomes. Through this exploration, we hope to better understand the complex relationship among transit usage, financial sustainability, and regional transit characteristics.\n\n\nif(!require(\"tidyverse\")) install.packages(\"tidyverse\")\nlibrary(tidyverse)\n\nif(!require(\"DT\")) install.packages(\"DT\")\nlibrary(DT)\n\nif(!require(\"stringr\")) install.packages(\"stringr\")\nlibrary(stringr)\n\nif(!require(\"lubridate\")) install.packages(\"lubridate\")\nlibrary(lubridate)\n\nFARES &lt;- readxl::read_xlsx(\"data/mp-01/2022_fare_revenue.xlsx\") |&gt;\n  select(-`State/Parent NTD ID`,\n         -`Reporter Type`,\n         -`Reporting Module`,\n         -`TOS`,\n         -`Passenger Paid Fares`,\n         -`Organization Paid Fares`) |&gt;\n  filter(`Expense Type` == \"Funds Earned During Period\") |&gt;\n  select(-`Expense Type`)\n\nEXPENSES &lt;- readr::read_csv(\"data/mp-01/2022_expenses.csv\") |&gt;\n  select(`NTD ID`,\n         `Agency`,\n         `Total`,\n         `Mode`) |&gt;\n  mutate(`NTD ID` = as.integer(`NTD ID`)) |&gt;\n  rename(Expenses = Total) |&gt;\n  group_by(`NTD ID`, `Mode`) |&gt;\n  summarize(Expenses = sum(Expenses)) |&gt;\n  ungroup()\n\nTRIPS &lt;- readxl::read_xlsx(\"data/mp-01/2022_ridership.xlsx\", sheet=\"UPT\") |&gt;\n  filter(`Mode/Type of Service Status` == \"Active\") |&gt;\n  select(-`Legacy NTD ID`,\n         -`Reporter Type`,\n         -`Mode/Type of Service Status`,\n         -`UACE CD`,\n         -`TOS`) |&gt;\n  pivot_longer(-c(`NTD ID`:`3 Mode`),\n               names_to=\"month\",\n               values_to=\"UPT\") |&gt;\n  drop_na() |&gt;\n  mutate(month=my(month)) # Parse _m_onth _y_ear date specs\n\nMILES &lt;- readxl::read_xlsx(\"data/mp-01/2022_ridership.xlsx\", sheet=\"VRM\") |&gt;\n  filter(`Mode/Type of Service Status` == \"Active\") |&gt;\n  select(-`Legacy NTD ID`,\n         -`Reporter Type`,\n         -`Mode/Type of Service Status`,\n         -`UACE CD`,\n         -`TOS`) |&gt;\n  pivot_longer(-c(`NTD ID`:`3 Mode`),\n               names_to=\"month\",\n               values_to=\"VRM\") |&gt;\n  drop_na() |&gt;\n  group_by(`NTD ID`, `Agency`, `UZA Name`,\n           `Mode`, `3 Mode`, month) |&gt;\n  summarize(VRM = sum(VRM)) |&gt;\n  ungroup() |&gt;\n  mutate(month=my(month)) # Parse _m_onth _y_ear date specs\n\nUSAGE &lt;- inner_join(TRIPS, MILES) |&gt;\n  mutate(`NTD ID` = as.integer(`NTD ID`))\n\nFINANCIALS &lt;- inner_join(FARES, EXPENSES, join_by(`NTD ID`, `Mode`))\n\nFINANCIALS &lt;- FINANCIALS |&gt;\n  rename(\n         \"mode\" = \"Mode\"\n  )\n\nFINANCIALS &lt;- FINANCIALS |&gt;\n  mutate(mode=case_when(\n    mode == \"HR\" ~ \"Heavy Rail\",\n    mode == \"DR\" ~ \"Demand Response\",\n    mode == \"FB\" ~ \"Ferry Boat\",\n    mode == \"MB\" ~ \"Motor Bus\",\n    mode == \"SR\" ~ \"Streetcar\",\n    mode == \"TB\" ~ \"Trolleybus\",\n    mode == \"VP\" ~ \"Vanpool\",\n    mode == \"CB\" ~ \"Commuter Bus\",\n    mode == \"RB\" ~ \"Bus Rapid Transit\",\n    mode == \"LR\" ~ \"Light Rail\",\n    mode == \"YR\" ~ \"Hybrid Rail\",\n    mode == \"MG\" ~ \"Guided Transit (Monorail)\",\n    mode == \"CR\" ~ \"Commuter Rail\",\n    mode == \"AR\" ~ \"Alaska Railroad\",\n    mode == \"TR\" ~ \"Tramway\",\n    mode == \"HR\" ~ \"Heavy Rail\",\n    mode == \"IP\" ~ \"Inclined Plane\",\n    mode == \"PB\" ~ \"Publico\",\n    mode == \"CC\" ~ \"Cable Car\",\n    TRUE ~ \"Unknown\"))"
  },
  {
    "objectID": "miniprojects/mp01.html",
    "href": "miniprojects/mp01.html",
    "title": "Jason Amey Mini Project 01",
    "section": "",
    "text": "Public transit in the United States serves a critical role in urban mobility. Serving millions of commuters while reducing congestion, pollution, and reliance on personal vehicles, transit is a critical institution in the success of the United States.\nHowever there exists a wide variation in the fiscal efficiency of these systems. Understanding these financial dimensions is essential for evaluating both the sustainability and performance of transit services.\nThis report explores data from major U.S. public transit systems, with analysis focused on factors such as: fare revenue per mile, vehicle revenue miles (VRM), unlinked passenger trips (UPT), and the ratio of expenses to fare-box recovery.\nThe data thus provides insights into important components of tranist analysis including: which systems operate most efficiently, which modes of transport generate the most revenue, and how these metrics differ throughout the United States.\nUsing tools from the R programming language, we explore these trends over time along with the influence of population density, geography, and mode-type on a transit system’s financial outcomes. Through this exploration, we hope to better understand the complex relationship among transit usage, financial sustainability, and regional transit characteristics.\n\n\nif(!require(\"tidyverse\")) install.packages(\"tidyverse\")\nlibrary(tidyverse)\n\nif(!require(\"DT\")) install.packages(\"DT\")\nlibrary(DT)\n\nif(!require(\"stringr\")) install.packages(\"stringr\")\nlibrary(stringr)\n\nif(!require(\"lubridate\")) install.packages(\"lubridate\")\nlibrary(lubridate)\n\nFARES &lt;- readxl::read_xlsx(\"data/mp-01/2022_fare_revenue.xlsx\") |&gt;\n  select(-`State/Parent NTD ID`,\n         -`Reporter Type`,\n         -`Reporting Module`,\n         -`TOS`,\n         -`Passenger Paid Fares`,\n         -`Organization Paid Fares`) |&gt;\n  filter(`Expense Type` == \"Funds Earned During Period\") |&gt;\n  select(-`Expense Type`)\n\nEXPENSES &lt;- readr::read_csv(\"data/mp-01/2022_expenses.csv\") |&gt;\n  select(`NTD ID`,\n         `Agency`,\n         `Total`,\n         `Mode`) |&gt;\n  mutate(`NTD ID` = as.integer(`NTD ID`)) |&gt;\n  rename(Expenses = Total) |&gt;\n  group_by(`NTD ID`, `Mode`) |&gt;\n  summarize(Expenses = sum(Expenses)) |&gt;\n  ungroup()\n\nTRIPS &lt;- readxl::read_xlsx(\"data/mp-01/2022_ridership.xlsx\", sheet=\"UPT\") |&gt;\n  filter(`Mode/Type of Service Status` == \"Active\") |&gt;\n  select(-`Legacy NTD ID`,\n         -`Reporter Type`,\n         -`Mode/Type of Service Status`,\n         -`UACE CD`,\n         -`TOS`) |&gt;\n  pivot_longer(-c(`NTD ID`:`3 Mode`),\n               names_to=\"month\",\n               values_to=\"UPT\") |&gt;\n  drop_na() |&gt;\n  mutate(month=my(month)) # Parse _m_onth _y_ear date specs\n\nMILES &lt;- readxl::read_xlsx(\"data/mp-01/2022_ridership.xlsx\", sheet=\"VRM\") |&gt;\n  filter(`Mode/Type of Service Status` == \"Active\") |&gt;\n  select(-`Legacy NTD ID`,\n         -`Reporter Type`,\n         -`Mode/Type of Service Status`,\n         -`UACE CD`,\n         -`TOS`) |&gt;\n  pivot_longer(-c(`NTD ID`:`3 Mode`),\n               names_to=\"month\",\n               values_to=\"VRM\") |&gt;\n  drop_na() |&gt;\n  group_by(`NTD ID`, `Agency`, `UZA Name`,\n           `Mode`, `3 Mode`, month) |&gt;\n  summarize(VRM = sum(VRM)) |&gt;\n  ungroup() |&gt;\n  mutate(month=my(month)) # Parse _m_onth _y_ear date specs\n\nUSAGE &lt;- inner_join(TRIPS, MILES) |&gt;\n  mutate(`NTD ID` = as.integer(`NTD ID`))\n\nFINANCIALS &lt;- inner_join(FARES, EXPENSES, join_by(`NTD ID`, `Mode`))\n\nFINANCIALS &lt;- FINANCIALS |&gt;\n  rename(\n         \"mode\" = \"Mode\"\n  )\n\nFINANCIALS &lt;- FINANCIALS |&gt;\n  mutate(mode=case_when(\n    mode == \"HR\" ~ \"Heavy Rail\",\n    mode == \"DR\" ~ \"Demand Response\",\n    mode == \"FB\" ~ \"Ferry Boat\",\n    mode == \"MB\" ~ \"Motor Bus\",\n    mode == \"SR\" ~ \"Streetcar\",\n    mode == \"TB\" ~ \"Trolleybus\",\n    mode == \"VP\" ~ \"Vanpool\",\n    mode == \"CB\" ~ \"Commuter Bus\",\n    mode == \"RB\" ~ \"Bus Rapid Transit\",\n    mode == \"LR\" ~ \"Light Rail\",\n    mode == \"YR\" ~ \"Hybrid Rail\",\n    mode == \"MG\" ~ \"Guided Transit (Monorail)\",\n    mode == \"CR\" ~ \"Commuter Rail\",\n    mode == \"AR\" ~ \"Alaska Railroad\",\n    mode == \"TR\" ~ \"Tramway\",\n    mode == \"HR\" ~ \"Heavy Rail\",\n    mode == \"IP\" ~ \"Inclined Plane\",\n    mode == \"PB\" ~ \"Publico\",\n    mode == \"CC\" ~ \"Cable Car\",\n    TRUE ~ \"Unknown\"))"
  },
  {
    "objectID": "miniprojects/mp01.html#fiscal-characteristics-of-major-us-public-transit-systems",
    "href": "miniprojects/mp01.html#fiscal-characteristics-of-major-us-public-transit-systems",
    "title": "Jason Amey Mini Project 01",
    "section": "",
    "text": "Public transit in the United States serves a critical role in urban mobility. Serving millions of commuters while reducing congestion, pollution, and reliance on personal vehicles, transit is a critical institution in the success of the United States.\nHowever there exists a wide variation in the fiscal efficiency of these systems. Understanding these financial dimensions is essential for evaluating both the sustainability and performance of transit services.\nThis report explores data from major U.S. public transit systems, with analysis focused on factors such as: fare revenue per mile, vehicle revenue miles (VRM), unlinked passenger trips (UPT), and the ratio of expenses to fare-box recovery.\nThe data thus provides insights into important components of tranist analysis including: which systems operate most efficiently, which modes of transport generate the most revenue, and how these metrics differ throughout the United States.\nUsing tools from the R programming language, we explore these trends over time along with the influence of population density, geography, and mode-type on a transit system’s financial outcomes. Through this exploration, we hope to better understand the complex relationship among transit usage, financial sustainability, and regional transit characteristics.\n\n\nif(!require(\"tidyverse\")) install.packages(\"tidyverse\")\nlibrary(tidyverse)\n\nif(!require(\"DT\")) install.packages(\"DT\")\nlibrary(DT)\n\nif(!require(\"stringr\")) install.packages(\"stringr\")\nlibrary(stringr)\n\nif(!require(\"lubridate\")) install.packages(\"lubridate\")\nlibrary(lubridate)\n\nFARES &lt;- readxl::read_xlsx(\"data/mp-01/2022_fare_revenue.xlsx\") |&gt;\n  select(-`State/Parent NTD ID`,\n         -`Reporter Type`,\n         -`Reporting Module`,\n         -`TOS`,\n         -`Passenger Paid Fares`,\n         -`Organization Paid Fares`) |&gt;\n  filter(`Expense Type` == \"Funds Earned During Period\") |&gt;\n  select(-`Expense Type`)\n\nEXPENSES &lt;- readr::read_csv(\"data/mp-01/2022_expenses.csv\") |&gt;\n  select(`NTD ID`,\n         `Agency`,\n         `Total`,\n         `Mode`) |&gt;\n  mutate(`NTD ID` = as.integer(`NTD ID`)) |&gt;\n  rename(Expenses = Total) |&gt;\n  group_by(`NTD ID`, `Mode`) |&gt;\n  summarize(Expenses = sum(Expenses)) |&gt;\n  ungroup()\n\nTRIPS &lt;- readxl::read_xlsx(\"data/mp-01/2022_ridership.xlsx\", sheet=\"UPT\") |&gt;\n  filter(`Mode/Type of Service Status` == \"Active\") |&gt;\n  select(-`Legacy NTD ID`,\n         -`Reporter Type`,\n         -`Mode/Type of Service Status`,\n         -`UACE CD`,\n         -`TOS`) |&gt;\n  pivot_longer(-c(`NTD ID`:`3 Mode`),\n               names_to=\"month\",\n               values_to=\"UPT\") |&gt;\n  drop_na() |&gt;\n  mutate(month=my(month)) # Parse _m_onth _y_ear date specs\n\nMILES &lt;- readxl::read_xlsx(\"data/mp-01/2022_ridership.xlsx\", sheet=\"VRM\") |&gt;\n  filter(`Mode/Type of Service Status` == \"Active\") |&gt;\n  select(-`Legacy NTD ID`,\n         -`Reporter Type`,\n         -`Mode/Type of Service Status`,\n         -`UACE CD`,\n         -`TOS`) |&gt;\n  pivot_longer(-c(`NTD ID`:`3 Mode`),\n               names_to=\"month\",\n               values_to=\"VRM\") |&gt;\n  drop_na() |&gt;\n  group_by(`NTD ID`, `Agency`, `UZA Name`,\n           `Mode`, `3 Mode`, month) |&gt;\n  summarize(VRM = sum(VRM)) |&gt;\n  ungroup() |&gt;\n  mutate(month=my(month)) # Parse _m_onth _y_ear date specs\n\nUSAGE &lt;- inner_join(TRIPS, MILES) |&gt;\n  mutate(`NTD ID` = as.integer(`NTD ID`))\n\nFINANCIALS &lt;- inner_join(FARES, EXPENSES, join_by(`NTD ID`, `Mode`))\n\nFINANCIALS &lt;- FINANCIALS |&gt;\n  rename(\n         \"mode\" = \"Mode\"\n  )\n\nFINANCIALS &lt;- FINANCIALS |&gt;\n  mutate(mode=case_when(\n    mode == \"HR\" ~ \"Heavy Rail\",\n    mode == \"DR\" ~ \"Demand Response\",\n    mode == \"FB\" ~ \"Ferry Boat\",\n    mode == \"MB\" ~ \"Motor Bus\",\n    mode == \"SR\" ~ \"Streetcar\",\n    mode == \"TB\" ~ \"Trolleybus\",\n    mode == \"VP\" ~ \"Vanpool\",\n    mode == \"CB\" ~ \"Commuter Bus\",\n    mode == \"RB\" ~ \"Bus Rapid Transit\",\n    mode == \"LR\" ~ \"Light Rail\",\n    mode == \"YR\" ~ \"Hybrid Rail\",\n    mode == \"MG\" ~ \"Guided Transit (Monorail)\",\n    mode == \"CR\" ~ \"Commuter Rail\",\n    mode == \"AR\" ~ \"Alaska Railroad\",\n    mode == \"TR\" ~ \"Tramway\",\n    mode == \"HR\" ~ \"Heavy Rail\",\n    mode == \"IP\" ~ \"Inclined Plane\",\n    mode == \"PB\" ~ \"Publico\",\n    mode == \"CC\" ~ \"Cable Car\",\n    TRUE ~ \"Unknown\"))"
  },
  {
    "objectID": "miniprojects.html",
    "href": "miniprojects.html",
    "title": "STA 9750 Fall 2024 - Jason Amey",
    "section": "",
    "text": "Here are my Mini-Projects :\n\nMini-Project #01"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Jason Amey - STA 9750 Fall 2024",
    "section": "",
    "text": "About Me: Hello. I work professionally as a Business Librarian in the Newman Library at Baruch College in New York City, NY.\nHere is my: Github\n\n\n1.mp #01"
  },
  {
    "objectID": "index.html#hi-my-name-is-jason-amey",
    "href": "index.html#hi-my-name-is-jason-amey",
    "title": "Jason Amey - STA 9750 Fall 2024",
    "section": "",
    "text": "About Me: Hello. I work professionally as a Business Librarian in the Newman Library at Baruch College in New York City, NY.\nHere is my: Github\n\n\n1.mp #01"
  },
  {
    "objectID": "slides/final_project_presentation.html#the-update",
    "href": "slides/final_project_presentation.html#the-update",
    "title": "Final Project Presentation",
    "section": "The Update",
    "text": "The Update"
  },
  {
    "objectID": "final_project_presentation.html#is-there-a-relationship-between-streets-and-home-values",
    "href": "final_project_presentation.html#is-there-a-relationship-between-streets-and-home-values",
    "title": "STA 9750 Final Project Presentation",
    "section": "Is there a relationship between streets and home values?",
    "text": "Is there a relationship between streets and home values?"
  },
  {
    "objectID": "final_project_presentation.html#do-streets-with-less-traffic-and-traffic-violence-increase-property-values",
    "href": "final_project_presentation.html#do-streets-with-less-traffic-and-traffic-violence-increase-property-values",
    "title": "STA 9750 Final Project Presentation",
    "section": "Do streets with less traffic and traffic violence increase property values?",
    "text": "Do streets with less traffic and traffic violence increase property values?"
  },
  {
    "objectID": "final_project_presentation.html#there-is-no-singular-identification-of-nyc-street-transformations",
    "href": "final_project_presentation.html#there-is-no-singular-identification-of-nyc-street-transformations",
    "title": "STA 9750 Final Project Presentation",
    "section": "There is no singular identification of NYC street transformations",
    "text": "There is no singular identification of NYC street transformations"
  },
  {
    "objectID": "final_project_presentation.html#identifying-significant-traffic-calming-projects-in-local-media",
    "href": "final_project_presentation.html#identifying-significant-traffic-calming-projects-in-local-media",
    "title": "STA 9750 Final Project Presentation",
    "section": "Identifying significant traffic calming projects in local media",
    "text": "Identifying significant traffic calming projects in local media"
  },
  {
    "objectID": "final_project_presentation.html#media-coverage-as-a-signal-for-significant-traffic-calming-project",
    "href": "final_project_presentation.html#media-coverage-as-a-signal-for-significant-traffic-calming-project",
    "title": "STA 9750 Final Project Presentation",
    "section": "Media Coverage as a signal for “significant traffic calming project”",
    "text": "Media Coverage as a signal for “significant traffic calming project”"
  },
  {
    "objectID": "final_project_presentation.html#parse-text-from-html-and-rank-tokens-in-search-of-street-names",
    "href": "final_project_presentation.html#parse-text-from-html-and-rank-tokens-in-search-of-street-names",
    "title": "STA 9750 Final Project Presentation",
    "section": "Parse text from html and rank tokens in search of street names",
    "text": "Parse text from html and rank tokens in search of street names"
  },
  {
    "objectID": "final_project_presentation.html#need-to-identify-block-and-lot-numbers-on-streets",
    "href": "final_project_presentation.html#need-to-identify-block-and-lot-numbers-on-streets",
    "title": "STA 9750 Final Project Presentation",
    "section": "Need to identify block and lot numbers on streets",
    "text": "Need to identify block and lot numbers on streets"
  },
  {
    "objectID": "final_project_presentation.html#with-block-and-lot-numbers-we-can-identify-tax-assessments",
    "href": "final_project_presentation.html#with-block-and-lot-numbers-we-can-identify-tax-assessments",
    "title": "STA 9750 Final Project Presentation",
    "section": "With block and lot numbers we can identify tax assessments",
    "text": "With block and lot numbers we can identify tax assessments"
  },
  {
    "objectID": "final_project_presentation.html#identify-comparable-neighboring-streets-by-traffic-flows",
    "href": "final_project_presentation.html#identify-comparable-neighboring-streets-by-traffic-flows",
    "title": "STA 9750 Final Project Presentation",
    "section": "Identify comparable, neighboring streets by traffic flows",
    "text": "Identify comparable, neighboring streets by traffic flows"
  },
  {
    "objectID": "final_project_presentation.html#attempting-to-control-for-these-influences",
    "href": "final_project_presentation.html#attempting-to-control-for-these-influences",
    "title": "STA 9750 Final Project Presentation",
    "section": "…attempting to control for these influences:",
    "text": "…attempting to control for these influences:"
  },
  {
    "objectID": "final_project_presentation.html#what-makes-a-neighborhood-expensive-in-nyc",
    "href": "final_project_presentation.html#what-makes-a-neighborhood-expensive-in-nyc",
    "title": "STA 9750 Final Project Presentation",
    "section": "What makes a neighborhood expensive in NYC?",
    "text": "What makes a neighborhood expensive in NYC?\nLocation: Proximity to Manhattan often increases prices.\nTransportation: Better access to subways, buses, and major roads raises desirability.\nAmenities: Access to parks, schools, dining, shopping, and cultural attractions.\nCrime: Safer neighborhoods tend to be more expensive.\nStatus: Historical prestige, architecture, and celebrity residents can elevate prices"
  },
  {
    "objectID": "final_project_presentation.html#project-question",
    "href": "final_project_presentation.html#project-question",
    "title": "STA 9750 Final Project Presentation",
    "section": "Project Question:",
    "text": "Project Question:\nDo streets with less traffic and traffic violence increase property values?"
  },
  {
    "objectID": "final_project_presentation.html#do-streets-with-less-traffic-and-traffic-violence-increase-property-values-1",
    "href": "final_project_presentation.html#do-streets-with-less-traffic-and-traffic-violence-increase-property-values-1",
    "title": "STA 9750 Final Project Presentation",
    "section": "Do streets with less traffic and traffic violence increase property values?",
    "text": "Do streets with less traffic and traffic violence increase property values?"
  },
  {
    "objectID": "final_project_presentation.html#when-streets-minimize-traffic-incidents-is-there-a-corresponding-increase-in-property-values",
    "href": "final_project_presentation.html#when-streets-minimize-traffic-incidents-is-there-a-corresponding-increase-in-property-values",
    "title": "STA 9750 Final Project Presentation",
    "section": "When streets minimize traffic incidents, is there a corresponding increase in property values?",
    "text": "When streets minimize traffic incidents, is there a corresponding increase in property values?"
  },
  {
    "objectID": "final_project_presentation.html#questions-for-project",
    "href": "final_project_presentation.html#questions-for-project",
    "title": "STA 9750 Final Project Presentation",
    "section": "Questions for project",
    "text": "Questions for project\n\nCan we make geographic connections among our data with code? For instance: can we find traffic calmed corridors, and then identify neighboring properties by block and lot number? Can we isolate street regions bounded by cross streets?\nWhat statistical test should we use to test for significance in tax assessment changes?\nHow do we effectively and efficiently work with large files? (The tax assessment files are ~1GB)\nIs there enough media coverage to identify significant traffic calming projects?\nHow many traffic calmed corridors should we focus on?"
  },
  {
    "objectID": "final_project_presentation.html#that-is",
    "href": "final_project_presentation.html#that-is",
    "title": "STA 9750 Final Project Presentation",
    "section": "That is:",
    "text": "That is:"
  },
  {
    "objectID": "final_project_presentation.html#question",
    "href": "final_project_presentation.html#question",
    "title": "STA 9750 Final Project Presentation",
    "section": "Question?",
    "text": "Question?"
  },
  {
    "objectID": "final_project_presentation.html#challenges-for-project",
    "href": "final_project_presentation.html#challenges-for-project",
    "title": "STA 9750 Final Project Presentation",
    "section": "Challenges for project",
    "text": "Challenges for project\n\nCan we make geographic connections among our data with code?\nWhat statistical test should we use to test for significance in tax assessment changes?\nHow do we effectively and efficiently work with large files? (The tax assessment files are ~1GB)\nIs there enough media coverage to identify significant traffic calming projects?\nHow many traffic calmed corridors should we focus on?"
  },
  {
    "objectID": "final_project_presentation.html#challenging-part-of-project-geocoding",
    "href": "final_project_presentation.html#challenging-part-of-project-geocoding",
    "title": "STA 9750 Final Project Presentation",
    "section": "Challenging part of project: Geocoding",
    "text": "Challenging part of project: Geocoding\nOnce we’ve identified areas of interest, how do we go from?\nstreet -&gt; latitude and longitude\nlatitude and longitude -&gt; block, lot number\nidentifying a corridor of a street?\ncorrectly identifying a collection of properties?\nHow do we do this in code?"
  },
  {
    "objectID": "mp02.html",
    "href": "mp02.html",
    "title": "IMDb and Me",
    "section": "",
    "text": "Originating in the proto-Internet era of Usenet groups in the early 1990s, The Internet Movie Database (with its instantly recognizable acronym, IMDb) has evolved from a small hobbyist project into a global resource to a significant part of popular culture. Originally started as a collaborative database by movie fans sharing information on films and, IMDb has quickly become the go-to source for movie buffs, film industry professionals, trivia enthusiasts, and casual web surfers alike.\nWith a dynamic catalog that collects not only motion pictures but also television, video games, and even web series, IMDb provides users with comprehensive information on cast, crew and reviews. IMDb stands as the the favorite resource for anyone engaged in the rich history of motion pictures. Today, it’s not just a website, but a symbol of how the Internet has transformed how we both catalog, and enjoy the art of film."
  },
  {
    "objectID": "final_project_presentation.html#data-sets-to-use",
    "href": "final_project_presentation.html#data-sets-to-use",
    "title": "STA 9750 Final Project Presentation",
    "section": "Data Sets to Use :",
    "text": "Data Sets to Use :\nNew York City Department of City Planning. (n.d.). Bytes of the Big Apple Archive. NYC Planning. Retrieved October 8, 2024, from https://www.nyc.gov/site/planning/data-maps/open-data/bytes-archive.page"
  },
  {
    "objectID": "final_project_presentation.html#data-sets-we-will-use",
    "href": "final_project_presentation.html#data-sets-we-will-use",
    "title": "STA 9750 Final Project Presentation",
    "section": "Data sets we will use",
    "text": "Data sets we will use\nProperty Assessment Roll Archives. NYC Department of Finance. link\nAutomated Traffic Volume Counts. NYC Department of Transportation. link"
  },
  {
    "objectID": "final_project_presentation.html#data-sets-we-may-use",
    "href": "final_project_presentation.html#data-sets-we-may-use",
    "title": "STA 9750 Final Project Presentation",
    "section": "Data sets we may use",
    "text": "Data sets we may use\nNew York City Department of City Planning. NYC Tax Lot Selector. link\nCity of New York: VZV Street Improvement Projects - SIPs Corridor. NYC Open Data. link"
  },
  {
    "objectID": "final_project_presentation.html#with-block-and-lot-numbers-we-can-identify-tax-assessments-1",
    "href": "final_project_presentation.html#with-block-and-lot-numbers-we-can-identify-tax-assessments-1",
    "title": "STA 9750 Final Project Presentation",
    "section": "With block and lot numbers we can identify tax assessments",
    "text": "With block and lot numbers we can identify tax assessments"
  },
  {
    "objectID": "final_project_presentation.html#tax-lot-selector",
    "href": "final_project_presentation.html#tax-lot-selector",
    "title": "STA 9750 Final Project Presentation",
    "section": "Tax Lot Selector",
    "text": "Tax Lot Selector"
  },
  {
    "objectID": "final_project_presentation.html#challenges-continued",
    "href": "final_project_presentation.html#challenges-continued",
    "title": "STA 9750 Final Project Presentation",
    "section": "Challenges (continued…)",
    "text": "Challenges (continued…)\n\nHow many traffic calmed corridors should we focus on?"
  },
  {
    "objectID": "final_project_presentation.html#the-city-does-identify-singular-vision-zero-improvemments",
    "href": "final_project_presentation.html#the-city-does-identify-singular-vision-zero-improvemments",
    "title": "STA 9750 Final Project Presentation",
    "section": "The City does identify singular Vision Zero improvemments",
    "text": "The City does identify singular Vision Zero improvemments"
  },
  {
    "objectID": "final_project_presentation.html#nyc-does-identify-singular-vision-zero-improvemments",
    "href": "final_project_presentation.html#nyc-does-identify-singular-vision-zero-improvemments",
    "title": "STA 9750 Final Project Presentation",
    "section": "NYC does identify singular Vision Zero improvemments",
    "text": "NYC does identify singular Vision Zero improvemments"
  },
  {
    "objectID": "final_project_presentation.html#again-with-block-and-lot-numbers-we-can-identify-tax-assessments",
    "href": "final_project_presentation.html#again-with-block-and-lot-numbers-we-can-identify-tax-assessments",
    "title": "STA 9750 Final Project Presentation",
    "section": "(again) …with block and lot numbers we can identify tax assessments",
    "text": "(again) …with block and lot numbers we can identify tax assessments"
  },
  {
    "objectID": "final_project_presentation.html#challenging-geocoding",
    "href": "final_project_presentation.html#challenging-geocoding",
    "title": "STA 9750 Final Project Presentation",
    "section": "Challenging: Geocoding",
    "text": "Challenging: Geocoding\nOnce we’ve identified areas of interest, how do we go from?\nstreet -&gt; latitude and longitude\nlatitude and longitude -&gt; block, lot number\nidentifying a corridor of a street?\ncorrectly identifying a collection of properties?\nHow do we do this in code?"
  },
  {
    "objectID": "final_project_presentation.html#challenge-geocoding",
    "href": "final_project_presentation.html#challenge-geocoding",
    "title": "STA 9750 Final Project Presentation",
    "section": "Challenge: Geocoding",
    "text": "Challenge: Geocoding\nOnce we’ve identified areas of interest, how do we go from?\nstreet -&gt; latitude and longitude\nlatitude and longitude -&gt; block, lot number\nidentifying a corridor of a street?\ncorrectly identifying a collection of properties?\nHow do we do this in code?"
  },
  {
    "objectID": "final_project_presentation.html#thank-you",
    "href": "final_project_presentation.html#thank-you",
    "title": "STA 9750 Final Project Presentation",
    "section": "Thank You!",
    "text": "Thank You!\nClinta and Jason :-)"
  },
  {
    "objectID": "final_project_presentation.html#additional-questions",
    "href": "final_project_presentation.html#additional-questions",
    "title": "STA 9750 Final Project Presentation",
    "section": "Additional Questions",
    "text": "Additional Questions\n\nIs there a geographic or NYC borough trend with our conclusions?\nDid Bloomberg’s major street transformations of the late 2000s have a bigger influence on real estate values than the more modest transformations of the De Blasio and Adams administrations?\nIs there a difference between residential and commerical property changes?"
  },
  {
    "objectID": "mp02.html#footnotes",
    "href": "mp02.html#footnotes",
    "title": "IMDB and Me",
    "section": "Footnotes",
    "text": "Footnotes\n\n\ndog &lt;- \"dogg\"↩︎"
  },
  {
    "objectID": "mp02.html#how-data-was-loaded",
    "href": "mp02.html#how-data-was-loaded",
    "title": "IMDB and Me",
    "section": "How Data Was Loaded",
    "text": "How Data Was Loaded\nIn this section, I describe how the data was loaded into the project.\n# Example of loading data in R\ndata &lt;- read.csv(\"path/to/your/data.csv\")"
  },
  {
    "objectID": "mp02.html#appendixA",
    "href": "mp02.html#appendixA",
    "title": "IMDb and Me",
    "section": "Appendix A",
    "text": "Appendix A\n\nI’d Like to Thank my Data - the Real Star of the Show\nThe IMDb data used for this project is detailed here\nThe Kaggle Movies Dataset can be found here\n\n\n&gt;show the code\n\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(stringr)\nlibrary(lubridate)\nlibrary(readr)v\n\n# Variable for data location\nDATA_FOLDER &lt;- \"data/mp02/\" --&gt;\n\n# Function to create file name\ncreate_file_ext &lt;- function(fname){\n   paste0(DATA_FOLDER, fname)\n}\n\n# Function to retrieve file as data frame\nget_IMDb_file &lt;- function(fname){\n     as.data.frame(read_csv(fname, lazy=FALSE))\n }\n\n# loading all IMDb DATA from their respective .csv files\nNAME_BASICS &lt;- get_IMDb_file(create_file_ext(\"NAME_BASICS.csv\"))\nTITLE_RATINGS &lt;- get_IMDb_file(create_file_ext(\"TITLE_RATINGS.csv\"))\nTITLE_BASICS &lt;- get_IMDb_file(create_file_ext(\"TITLE_BASICS.csv\"))\nTITLE_CREW &lt;- get_IMDb_file(create_file_ext(\"TITLE_CREW.csv\"))\nTITLE_EPISODES &lt;- get_IMDb_file(create_file_ext(\"TITLE_EPISODES.csv\"))\nTITLE_PRINCIPALS &lt;- get_IMDb_file(create_file_ext(\"TITLE_PRINCIPALS.csv\"))\n\n# Data wrangling correct data types\nNAME_BASICS &lt;- NAME_BASICS |&gt;\n    mutate(birthYear = as.numeric(birthYear),\n           deathYear = as.numeric(deathYear))\n\nTITLE_RATINGS &lt;- TITLE_RATINGS |&gt;\n     mutate(averageRating = as.numeric(averageRating),\n            numVotes = as.numeric(numVotes))\n\nTITLE_BASICS &lt;- TITLE_BASICS |&gt;\n    mutate(isAdult = as.logical(isAdult),\n           runtimeMinutes = ifelse(grepl(\"[^0-9]\", runtimeMinutes), NA, as.numeric(runtimeMinutes)))\n\n# looading Kaggle Data            \nKAGGLE_DATA &lt;- read.csv(\"data/mp02/KAGGLE_DATA.csv\") |&gt;\n   mutate(budget = ifelse(is.na(budget), 0, parse_number(budget)))"
  },
  {
    "objectID": "mp02.html#how-often-has-a-producer-been-given-the-proverbial-green-light",
    "href": "mp02.html#how-often-has-a-producer-been-given-the-proverbial-green-light",
    "title": "IMDB and Me",
    "section": "How often has a producer been given the proverbial “green light”?",
    "text": "How often has a producer been given the proverbial “green light”?\nThe “M” in the moniker obviously denotes “movie” and there are indeed 131,890 traditional “movies” in IMDB. However, many take a different interpretations as to what is - and what is not - a “movie” and IMDB maintains a separate designation for tvMovie.\nThe author contends that the films produced by the premium television outlet Home Box Office are significant films all-too-often overlooked by film afficianados and sure enough, HBO films are considered television films by IMDB :\ntitleType   primaryTitle            startYear\ntvMovie     And the Band Played On  1993\n\ntitleType   primaryTitle            startYear\ntvMovie     Recount                 2008\n  \ntitleType   primaryTitle            startYear\ntvMovie     Conspiracy              2001\nNot an HBO original, but this tvMovie is partially credited for ending The Cold War:\ntitleType   primaryTitle    startYear\ntvMovie     The Day After   1983\nThe above are all noteworthy (underrated) films more than deserving to be considered and counted alongside IMDB’s critera for “movie”. If we were to count both movie and tvMovie we would find 146,915 movie titles in IMDB.\n…Speaking of television, that “M” in IMDB can be something of a misnomer. IMDB collects data on both film and television too. And within the database, IMDB doesn’t just maintain an entry for every television series, but actually has a record for each televison season and a record for every televsion episode. All told there are 29,868 series within IMDB represented by over 3,012,678 individual episdoes.\nIf television is collected this extensively in the database, what else does IMDB collect? What else is in the database?\n\nI’d argue the collection of Video Games will prove increasingly important as this media form grows in cultural influence. I can certainly see a future where Video Games are of equal cultural significance (…if were not at that momemnt already?) as film and TV is today.\n\n\n&gt; show the code\n\n# How many films are in IMDB? \nTITLE_BASICS |&gt; \n  filter(titleType == \"movie\" | titleType == \"tvMovie\") |&gt;\n  count()\n\n# What if we include TV Moives?   \nTITLE_BASICS |&gt; \n  filter(titleType == \"movie\" | titleType == \"tvMovie\") |&gt;\n  count()\n\n# What if we searched for a particular HBO Moive?    \nTITLE_BASICS |&gt; \n  filter(primaryTitle == \"And the Band Played On\") |&gt; \n  select(titleType, primaryTitle, startYear)\n\n# How many television series are in IMDB? \nTITLE_BASICS |&gt; \n  filter(titleType == \"tvSeries\") |&gt;\n  count()\n\n# How many individual episodes are collected? \nTITLE_EPISODES |&gt;\n  nrow()\n\n# What are the different title types in IMDB  \ntitle_type_counts &lt;- TITLE_BASICS |&gt; \n  group_by(titleType) |&gt; \n  summarize(count = n())\n  \n# Let's visualize the breakdown of all the different title types\nggplot(title_type_counts, aes(x = \"\", y = count, fill = titleType)) + \n  geom_bar(stat = \"identity\", width = 0.7) +\n  labs(title = \"IMDB Media Types and Their Counts\", x = NULL, y = \"Count\") +\n  scale_y_continuous(labels = label_number(scale_cut = cut_short_scale())) +\n  scale_fill_brewer(palette = \"Set3\")\n  theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())  \n\n\n\n\n&gt; show the code\n\n\n\n[1] \"doggnose\"\n\n\n\n\n\n\n\n\n\nmovies_meeting_review_threshold &lt;- movies_lens_ratings_merged |&gt; filter(count_reviews &gt;= 1000) |&gt; pull(movieId)\nfiltered_reviews &lt;- MOVIE_LENS_RATINGS |&gt; filter(movieId %in% movies_meeting_review_threshold)\nmovie_lens__IMDB &lt;- filtered_reviews |&gt; inner_join(MOVIE_LENS_LINKS, by = “movieId”)\n\n\n&gt; show the code\n\n\nhello &lt;- \"hello\"\n\n\n\nWhen we say “movie” we often think of “what is opening this Friday” and with it: “what film will win the weekend box office?”\nIf we look at the Kaggle Movie Dataset, we see\nquantile(KAGGLE_DATA$revenue, probs = seq(0,1,.05), na.rm=TRUE)\n\nNAME_BASICS |&gt; filter(birthYear &lt;= 1914 & is.na(deathYear)) |&gt; nrow() \nThe Gerontology Research Group rigorously counts “supercentarians” around the world. A supercentarian is an individual equal-to, or older-than, the age of 110. At current count, there are approximately ~310 supercentarians in the world.\nClearly there is an issue with the IMDB dataset identifying 2,514 supercentarians in the film industry. There obviously are a multitude of deaths unreported in this data.\nBut, just because you’re old and you possibly “one-time-maybe did something in the film industry”, should anyone care? There are millions of people who throughout their lives have no-doubt been involved in at least 1 movie production in their lives. Does “old person who once worked on a forgotten independent movie no-one-saw” really communicate anything to us?\nI don’t think it does.\nMy childhood friend Rob went to film school in the late 1990s. He briefly worked in the film industry for a few years after graduation but quickly decided he did not want a career in movies. While I can tell you Rob is a very talented individual, he has long since had anything to do with the film industry.\nMy friend Rob is in the IMDB dataset: https://www.imdb.com/name/nm0551343/?ref_=fn_al_nm_1\nWith all due respect to Rob, his talents and his successful post-film career (he’s a tenure-track professor of education), do we really want to count “the Robs” of our dataset?\nCan we filter out the Robs and the like and arrive on a collection of individuals “significant enough in the film industry” to warrant our interest and attention?\nI think we can.\nLet’s first try to identify “significant film productions” in our data.\nI’m going to use the measure of: “if this film had a lot of people working on it, it no doubt cost a lot of money and was of signifcant interest to some studio or production company.” So I’m going to count the\nNAME_BASICS |&gt; nrow() \nNAME_BASICS &lt;- NAME_BASICS |&gt; mutate(birthYear = as.numeric(birthYear), deathYear = as.numeric(deathYear))\nCREW_COUNTS_FOR_TITLE &lt;- TITLE_PRINCIPALS |&gt; group_by(tconst) |&gt; summarize(crew_members = n())\nquantile(CREW_COUNTS_FOR_TITLE$crew_members, probs = seq(0.1, 1, by=.1))\nBIG_PRODUCTIONS &lt;- CREW_COUNTS_FOR_TITLE |&gt; filter(crew_members &gt;= 24)\n\n\nNAMEIDS_IN_MANY_BIG_PRODUCTIONS &lt;- BIG_PRODUCTIONS |&gt; inner_join(TITLE_PRINCIPALS, join_by(tconst == tconst)) |&gt; group_by(nconst) |&gt; summarize(number_of_big_productions = n()) |&gt; filter(number_of_big_productions &gt; 20) |&gt; arrange(desc(number_of_big_productions))\nLet’s spot check out data…\nNAMES_IN_MANY_BIG_PRODUCTIONS &lt;- NAMEIDS_IN_MANY_BIG_PRODUCTIONS |&gt; inner_join(NAME_BASICS, join_by(nconst == nconst)) |&gt; mutate(deathYear = ifelse(is.na(deathYear), 0, deathYear)) |&gt; mutate(age = ifelse(deathYear == 0, 2024 - birthYear, deathYear - birthYear))\nThis data is identifying well-known voice actors:\n        \nNAMES_IN_MANY_BIG_PRODUCTIONS |&gt; filter(deathYear == 0) |&gt; arrange(desc(age)) |&gt; slice(1)\n\n\ntop_episodes &lt;- TITLE_RATINGS |&gt; filter(averageRating == 10 & numVotes &gt;= 200000)\nepisode_details &lt;- top_episodes |&gt; inner_join(TITLE_BASICS, by = “tconst”) |&gt; inner_join(TITLE_EPISODES, by = “tconst”)\nresult &lt;- episode_details |&gt; inner_join(TITLE_BASICS, by = c(“parentTconst” = “tconst”)) |&gt; select(tconst, parentTconst, seriesTitle = primaryTitle.y)\n\nmark_hamil_popular_works_IDs &lt;- NAME_BASICS |&gt; filter(primaryName == “Mark Hamill”) |&gt; separate_rows(knownForTitles, sep =“,”)\nmark_hamil_popular_works |&gt; inner_join(TITLE_BASICS, by = c(“knownForTitles” = “tconst”)) |&gt; select(-knownForTitles, -primaryProfession, -birthYear, -deathYear, -isAdult)\n\n\n\n\ntv_show_12_episodes &lt;- TITLE_EPISODES |&gt; group_by(parentTconst) |&gt; mutate(numberOfEpisodes = n()) |&gt;\narrange(desc(numberOfEpisodes))\ntv_show_12_episodes_high_rating_ID &lt;- tv_show_12_episodes |&gt; inner_join(TITLE_RATINGS, by = “tconst”) |&gt; select(-seasonNumber, -episodeNumber, -tconst) |&gt; group_by(parentTconst) |&gt; mutate(average_rating_for_series = mean(averageRating), total_votes = sum(numVotes)) |&gt;\nquantile(tv_show_12_episodes_high_rating_ID$total_votes, prob = seq(0,1,.05))\n   \ntv_show_12_episodes_high_rating_titles &lt;- tv_show_12_episodes_high_rating_ID |&gt; filter(total_votes &gt; 268000) |&gt; inner_join(TITLE_BASICS, join_by(parentTconst == tconst))\ntv_show_12_episodes_high_rating_titles &lt;- tv_show_12_episodes_high_rating_ID |&gt; filter(total_votes &gt; 268000) |&gt; inner_join(TITLE_BASICS, join_by(parentTconst == tconst)) |&gt; group_by(parentTconst, primaryTitle) |&gt;\nsummarize(average_rating_for_series = first(average_rating_for_series), .groups = ‘drop’) |&gt;\narrange(desc(average_rating_for_series))\nprint(tv_show_12_episodes_high_rating_titles, n = 50)\n        \n\n\n\ntitle_basics_movie_lens_id &lt;- TITLE_BASICS |&gt; mutate(imdbId = as.numeric(substring(tconst, 3)))\n\nmovie_lens_and_imdb &lt;- title_basics_movie_lens_id |&gt; inner_join(movie_lens_filtered_reviews_IMDB, by = “imdbId”) |&gt; select(-isAdult, -endYear, -runtimeMinutes, -tmdbId, -titleType) |&gt; mutate(yearReview = year(as.POSIXct(timestamp, origin=“1970-01-01”)))\n\nmovie_lens_and_imdb_5_year_reviews &lt;- movie_lens_and_imdb |&gt; filter(yearReview - startYear &gt;= 5) |&gt; group_by(imdbId, primaryTitle, startYear) |&gt; summarize(avg_review = mean(rating)) |&gt; select(-imdbId) |&gt; arrange(desc(avg_review))\nprint(movie_lens_and_imdb_5_year_reviews, n=50)\nmin(movie_lens_and_imdb$yearReview) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmovie_lens_and_imdb_year_review &lt;- movie_lens_and_imdb |&gt; group_by(imdbId, primaryTitle, startYear) |&gt; summarize(avg_review = mean(rating)) |&gt; arrange(desc(avg_review))\nprint(movie_lens_and_imdb_year_review, n = 50)\n         \npolarizing_films &lt;- movie_lens_and_imdb |&gt; group_by(imdbId, primaryTitle, startYear, genres) |&gt; summarise(mean_rating = mean(rating), sd_rating = sd(rating), num_ratings = n()) |&gt; arrange(desc(sd_rating)) |&gt; select(-imdbId)\npolarizing_films\npolarizing_films &lt;- movie_lens_and_imdb |&gt; group_by(movieId, primaryTitle, startYear, genres) |&gt; summarise(mean_rating = mean(rating), iqr_rating = IQR(rating), num_ratings = n()) |&gt; arrange(desc(iqr_rating))\npolarizing_films &lt;- movie_lens_and_imdb |&gt; group_by(movieId, primaryTitle, startYear, genres) |&gt; summarise(mean_rating = mean(rating), var_rating = var(rating), num_ratings = n()) |&gt; arrange(desc(var_rating))\n\nmovie_lens_and_imdb_and_kaggle &lt;- movie_lens_and_imdb |&gt; inner_join(KAGGLE_DATA, join_by(tconst == imdb_id))\nmovie_lens_and_imdb_and_kaggle\nget_dollar_adjusted_value &lt;- function(budget, year){ return (budget * cpi_named_vector[as.character(2024)]/cpi_named_vector[as.character(year)]) }\nvotes_budget &lt;- movie_lens_and_imdb_and_kaggle |&gt; group_by(imdbId, primaryTitle, budget, startYear, revenue) |&gt; summarize(num_votes = n()) |&gt; mutate(adjusted_budget = get_dollar_adjusted_value(budget, startYear), adjusted_profit = get_dollar_adjusted_value(revenue, startYear) - get_dollar_adjusted_value(budget, startYear) )\nmodel_profit &lt;- lm(votes_budget\\(num_votes ~  votes_budget\\)adjusted_profit)\nreg_line &lt;- function(x_val, model){ return(coef(model)[1] + coef(model)[2] * x_val) }\nvotes_budget_profit &lt;- votes_budget |&gt; mutate(popularity_over_profit = num_votes - reg_line(adjusted_profit, model_profit)) |&gt; arrange(desc(popularity_over_profit))\n\nggplot(data = votes_budget_profit, aes(x = adjusted_profit, y = num_votes )) + geom_point(alpha = 0.1) + geom_smooth(method=“lm”, se=FALSE)\nmodel_budget &lt;- lm(votes_budget\\(num_votes ~  votes_budget\\)adjusted_budget)\nvotes_budget_budget &lt;- votes_budget |&gt; mutate(popularity_over_budget = num_votes - reg_line(adjusted_budget, model_profit)) |&gt; arrange(desc(popularity_over_budget))\nprint(votes_budget_budget, n =100)\n\nvotes_budget |&gt; arrange(desc(adjusted_budget)) |&gt; print(n = 100)\ntop_500_polarizing_films &lt;- head(polarizing_films, 500)\ntop_500_polarizing_films_w_budget &lt;- top_500_polarizing_films |&gt; inner_join(KAGGLE_DATA, join_by(imdbId == imdb_id))\ntop_500_polarizing_films_w_budget"
  },
  {
    "objectID": "mp02.html#whats-in-the-box",
    "href": "mp02.html#whats-in-the-box",
    "title": "IMDb and Me",
    "section": "What’s in the Box?",
    "text": "What’s in the Box?\nFor details on the data used for this project see Appendix A.\nThis project useses the following packagaes: dplyr, tidyr, stringr, lubridate, readr, scales\n\nHow Many Green Lights Have Been Granted in Hollywood?\nThe “M” in the moniker obviously denotes “movie” and there are indeed 131,890 traditional “movies” in IMDb. However, many take a different interpretations as to what is - and what is not - a “movie” and IMDb maintains a separate designation for tvMovie.\nThe author contends that the films produced by the premium television outlet Home Box Office are significant films all-too-often overlooked by film afficianados and sure enough, HBO films are considered television films by IMDb :\ntitleType   primaryTitle            startYear\ntvMovie     And the Band Played On  1993\n\ntitleType   primaryTitle            startYear\ntvMovie     Recount                 2008\n  \ntitleType   primaryTitle            startYear\ntvMovie     Conspiracy              2001\nNot an HBO original, but this tvMovie is partially credited for ending The Cold War:\ntitleType   primaryTitle    startYear\ntvMovie     The Day After   1983\nThe above are all noteworthy (underrated) films more than deserving to be considered and counted alongside IMDb’s critera for “movie”. If we were to count both movie and tvMovie we would find 146,915 movie titles in IMDb.\n…Speaking of television, that “M” in IMDb can be something of a misnomer. IMDb collects data on both film and television too. And within the database, IMDb doesn’t just maintain an entry for every television series, but actually has a record for each televison season and a record for every televsion episode. All told there are 29,868 series within IMDb represented by over 3,012,678 individual episdoes.\nIf television is collected this extensively in the database, what else does IMDb collect? What else is in the database?\n\nI suspect the collection of videoGames will prove increasingly important as this media form grows in cultural influence. Video games are also serving as a the growing source of IP and inspiration, witnessed in recent successes like television’s The Last of Us and in theaters last year’s 5 Nights at Freddy’s (2023) and Super Mario Brothers (2023) for convincing examples of their growing influence on film culture.\n\n\n&gt; show the code\n\n# How many films are in IMDb? \nTITLE_BASICS |&gt; \n  filter(titleType == \"movie\" | titleType == \"tvMovie\") |&gt;\n  count()\n\n# What if we include TV Moives?   \nTITLE_BASICS |&gt; \n  filter(titleType == \"movie\" | titleType == \"tvMovie\") |&gt;\n  count()\n\n# What if we searched for a particular HBO Moive?    \nTITLE_BASICS |&gt; \n  filter(primaryTitle == \"And the Band Played On\") |&gt; \n  select(titleType, primaryTitle, startYear)\n\n# How many television series are in IMDb? \nTITLE_BASICS |&gt; \n  filter(titleType == \"tvSeries\") |&gt;\n  count()\n\n# How many individual episodes are collected? \nTITLE_EPISODES |&gt;\n  nrow()\n\n# What are the different title types in IMDb  \ntitle_type_counts &lt;- TITLE_BASICS |&gt; \n  group_by(titleType) |&gt; \n  summarize(count = n())\n\n# Let's visualize the breakdown of all the different title types\nggplot(title_type_counts, aes(x = \"\", y = count, fill = titleType)) + \n  geom_bar(stat = \"identity\", width = 0.7) +\n  labs(title = \"IMDb Media Types and Their Counts\", x = NULL, y = \"Count\") +\n  scale_y_continuous(labels = label_number(scale_cut = cut_short_scale())) +\n  scale_fill_brewer(palette = \"Paired\")\n  theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())  \n\n\n\n\n110 Years Old You Reach, Look as Good You Will Not\nIMBb is a unrivaled resource for assessing film history. And by history, there is actually some capital “H” history in IMDb.\nIMDb counts 4 as the oldest birthYear for any individual in its dataset. And not just 4, there are also birthYear values for 46, 69, 70, 163, 254. As far as we know, film production is a ~150 year old technology.\nWhat is going on?\nWho was born in year 4? Year 46? Year 69?\n\nClassics behind the camera\n\n\nPrimary Name\n\n\n\n\nFlavius Josephus\n\n\nPublius Vergilius Maro\n\n\nOvid\n\n\nTitus Maccius Plautus\n\n\nLucio Anneo Seneca\n\n\nCassius Dio\n\n\nPlutarch\n\n\nSuetonius\n\n\n\nAre you entertained? A fascinating quirk of IMDb database is that it credits classical writers and historians for modern film production, again, proving IMDb is if nothing else an historical resource and begs the important question?\nDoes Zach Snyder share 300 points with Plutarch?\nBut how about someone we know or can identify? Who is eldest creator still alive in the IMDb database? A seemingly easy way to identify “oldest creator in IMDb” would be to seek out creators with an NA for deathYear.\nUnfortunately there are quite a few people IMDb considers living in their sunset years. IMDb idetifies 2,514 “supercentarians” - individuals 110 years of age or older - who at one time worked the film industry.\nThe Gerontology Research Group rigorously counts “supercentarians” around the world. A supercentarian is an individual equal-to, or older-than, the age of 110. At current count, there are approximately ~310 supercentarians in the world.\nClearly there is an issue with the IMDb dataset identifying 2,514 supercentarians in the film industry. There obviously are a multitude of deaths unreported in this data.\nBut, just because you’re old and you possibly “one-time-maybe did something in the film industry”, should anyone care? There are millions of people who throughout their lives have no-doubt been involved in at least 1 movie production in their lives. Does “old person who once worked on a forgotten independent movie no-one-saw” really communicate anything to us?\nI posit that anyone who did anything significant in the film industry would have their deathYear duly reported. Therefore, let’s re-start our search and see if we can arrive at a collection of individuals “significant enough in the film industry” to warrant our interest and attention.\nLet’s first try to identify “significant film productions” in our data.\nI’m going to use the measure of: “if this film had a lot of people working on it, it no doubt cost a lot of money and was of notable interest to some studio or production company.” So I’m going to count the number of crew on a film and look for a threshold for top produciton.\nHere are the percentiles for the crew counts:\n10%  20%  30%  40%  50%  60%  70%  80%  90% 100% \n10   14   16   18   19   20   21   22   24   65 \n90% of all productions have 24+ or more crew numbers working on them. I’m going to identify any person “significant” in the films industry as someone who has worked on 20+ such productions. Sorted on number_of_big_productions worked on, sure enough this yields useful information:\n\nVoice actors, unfortunately a dying breed in Hollywood \n\n\n\n\n\n\n\n\n\nName\nBirth Year\nNumber of Big Productions\nAge\nDeath Year\n\n\n\n\nSeth MacFarlane\n1973\n2505\n51\n0\n\n\nDee Bradley Baker\n1962\n2311\n62\n0\n\n\nDan Castellaneta\n1957\n2242\n67\n0\n\n\nHank Azaria\n1964\n2191\n60\n0\n\n\nHarry Shearer\n1943\n2162\n81\n0\n\n\nEric Stuart\n1967\n2043\n57\n0\n\n\n\nThese names are all identifiable as prominent voice actors. So with this collection of notable individuals, let’s idenfity the oldest individual in this data set:\n\nWhat a great find!\n\n\n\n\n\n\n\n\n\nPrimary Name\nBirth Year\nNumber of Big Productions\nAge\nDeath Year\n\n\n\n\nMel Brooks\n1926\n37\n98\n0\n\n\n\nMel Brooks is a singular lion of comedy history responsible for some of the greatest comedic films over the past 40 - 50 years. He also experienced a noteworthy second act as a Broadway producer with his early 2000s theatrical production of The Producers a timely film of his that lampoons how dark attidues on fascism never seem to fall out of faver. Mel Brooks is a fitting talent to identify as the dataset’s oldest talent.\n\n\n&gt; show the code\n\n# Who is the oldest individual in IMDb?\nmin(NAME_BASICS$birthYear, na.rm=TRUE)\n\n# A birthyear of '4'! Is this a mistake? \nsort(unique(NAME_BASICS$birthYear))\n\n# Who are these individuals? \nNAME_BASICS |&gt; \n  filter(\n    birthYear == 4 | \n    birthYear ==  37 |\n    birthYear ==  43 | \n    birthYear == 46 | \n    birthYear == 69 | \n    birthYear == 70 |\n    birthYear == 163 | \n    birthYear == 254\n    ) |&gt; \n  select(primaryName)\n  \n# Are there really that many 110 year-olds in this database? \nNAME_BASICS |&gt;\n  filter(birthYear &lt;= 1914 & is.na(deathYear)) |&gt;\n  nrow()\n\n# Let's count the amont of crew working for a poduction \ncrew_counts_for_title &lt;- TITLE_PRINCIPALS |&gt; \n  group_by(tconst) |&gt; \n  summarize(crew_members = n()) \n\n# Can we identify the threshold for 'big production' by crew count?\nquantile(crew_counts_for_title$crew_members, probs = seq(0.1, 1, by=.1))\n\n# Top 90% of productions have 24 crew members, so let's use that threshold\nbig_productions &lt;- crew_counts_for_title |&gt; \n  filter(crew_members &gt;= 24)\n\n# Using 24 crew members as a citeria for \"big production\", this\n# identifies all of the individuals who have worked on 20 or more \n# such productions, creating the criteria we're using for \"significant \n# individuals in film and television\"\nname_ids_in_many_big_productions &lt;- big_productions |&gt; \n  inner_join(TITLE_PRINCIPALS, by=\"tconst\") |&gt;\n  group_by(nconst) |&gt; \n  summarize(number_of_big_productions = n()) |&gt; \n  filter(number_of_big_productions &gt; 20) |&gt; \n  arrange(desc(number_of_big_productions))\n\n# Mathching up these ids with names \nnames_in_many_big_productions &lt;- name_ids_in_many_big_productions |&gt;\n  inner_join(NAME_BASICS, join_by(nconst == nconst)) |&gt;\n  mutate(deathYear = ifelse(is.na(deathYear), 0, deathYear)) |&gt; \n  mutate(age = ifelse(deathYear == 0, 2024 - birthYear, deathYear - birthYear)) |&gt; \n  select(primaryName, birthYear, number_of_big_productions, age, deathYear, nconst)\n\n# Who is the oldest individual in this data set?\nnames_in_many_big_productions |&gt; \n  filter(deathYear == 0) |&gt;\n  arrange(desc(age)) |&gt;\n  slice(1)\n\n\n\n\nStar Wars and Mark Hamill\nWith over $10.3 billion in box office across all 9 of it’s main, episodic features, there arguable is no franchise that has loomed larger over the recent history of film than Star Wars. For some, Star Wars represents the critical turning point when movies forever became major cultural events, meant to wow, awe and captivate the film-going audience. With its fantastical promotion of technologically innovative special effects, edge-of-your-seat action both grounded in dramatic, escapist storytelling, Star Wars effectively created the template for the modern summer blockbuster.\nDespite its release more than 40 years ago, Star Wars continues to loom large over the popular imagination as current rights holder Disney maintains ambitious plans to push its stories and its characters into galaxies far, far away.\nDid the hero of Star Wars break free from the monumental legacy of such an iconic franchise, or has he forever been bound to the role of Luke Skywalker, overshadowing the rest of his career?\nVoice acting and Corvette Summer (1978) notwitstanding, it looks like Hamill will always be known as Luke Skywalker:\n\nData for Mark Hamill’s Star Wars Movies\n\n\n\n\n\n\n\nPrimary Name\nPrimary Title\nStart Year\n\n\n\n\nMark Hamill\nStar Wars: Episode IV - A New Hope\n1977\n\n\nMark Hamill\nStar Wars: Episode V - The Empire Strikes Back\n1980\n\n\nMark Hamill\nStar Wars: Episode VI - Return of the Jedi\n1983\n\n\nMark Hamill\nStar Wars: Episode VIII - The Last Jedi\n2017\n\n\n\n\n\n&gt; show the code\n\nmark_hamil_popular_works_IDs &lt;- NAME_BASICS |&gt;\n  filter(primaryName == \"Mark Hamill\") |&gt;\n  separate_rows(knownForTitles, sep =\",\")\n  \nmark_hamil_popular_works_IDs |&gt; \n  inner_join(TITLE_BASICS, by = c(\"knownForTitles\" = \"tconst\")) |&gt; \n  select(primaryName, primaryTitle, startYear) |&gt;\n  arrange(startYear)\n\n\n\nWhat Television Show with at least 12 episodes has the highest average rating?\nSwtiching galaxies to Television, suppose we wanted to identify popular television series? Say, a series with at least 12 episodes?\nThis is really unsatisfactory:\n\nData for TV Series and Their Average Ratings\n\n\n\n\n\n\n\nparentTconst\nPrimary Title\nAverage Rating For Series\n\n\n\n\ntt0409579\nMade\n10\n\n\ntt11289784\nUnus Annus\n10\n\n\ntt11363282\nThe Real Housewives of Salt Lake City\n10\n\n\ntt21278628\nCowboys of Thunder\n10\n\n\ntt0060008\nThe Milton Berle Show\n9.9\n\n\ntt0168358\nParkinson\n9.9\n\n\ntt0372654\nDe película\n9.9\n\n\ntt0491739\nIn the Nick of Time\n9.9\n\n\ntt14117438\nTough Love with Hilary Farr\n9.9\n\n\ntt31806594\nWar of Faith\n9.9\n\n\n\nLet’s investigate the quantiles for number of votes:\n\nDiscounting the disotrting effect of few people voting on a television program, we’ll settle on the the top 10% most popular shows, Admittedly this may miss out on underrecognized, cult programs.\n\nThe Internet loves Anime. \n\n\nparentTconst\nPrimary Title\nAverage Rating for Series\n\n\n\n\ntt2560140\nAttack on Titan\n9.02\n\n\ntt0903747\nBreaking Bad\n8.96\n\n\ntt5753856\nDark\n8.89\n\n\ntt4158110\nMr. Robot\n8.89\n\n\ntt3322312\nDaredevil\n8.84\n\n\ntt1839578\nPerson of Interest\n8.80\n\n\ntt3032476\nBetter Call Saul\n8.80\n\n\ntt7660850\nSuccession\n8.75\n\n\ntt0944947\nGame of Thrones\n8.75\n\n\ntt3581920\nThe Last of Us\n8.73\n\n\n\n\n\n&gt; show the code\n\n\n# Group television shows by their parents\ntv_show_12_episodes &lt;- \n  TITLE_EPISODES |&gt; \n  group_by(parentTconst) |&gt;\n  mutate(numberOfEpisodes = n()) |&gt;  \n  filter(numberOfEpisodes &gt; 12) |&gt;\n  arrange(desc(numberOfEpisodes))\n\n# Identify the popular series by averaging the ratings of all episodes\ntv_show_12_episodes_high_rating_ID &lt;- \n  tv_show_12_episodes |&gt; \n  inner_join(TITLE_RATINGS, by = \"tconst\") |&gt; \n  select(-seasonNumber, -episodeNumber, -tconst) |&gt;\n  group_by(parentTconst) |&gt; \n  mutate(average_rating_for_series = mean(averageRating), total_votes = sum(numVotes))\n\n# Join our working list with the master Title list to identify the series\ntv_show_12_episodes_high_rating_ID |&gt; \n  inner_join(TITLE_BASICS, join_by(parentTconst == tconst)) \n  \n# Investigate the name of the most popular shows\ntv_show_12_episodes_high_rating_titles &lt;- \n  tv_show_12_episodes_high_rating_ID |&gt; \n  inner_join(TITLE_BASICS, join_by(parentTconst == tconst)) |&gt;\n  group_by(parentTconst, primaryTitle) |&gt;  \n  summarize(average_rating_for_series = first(average_rating_for_series), .groups = 'drop') |&gt;\n  arrange(desc(average_rating_for_series))  \ntv_show_12_episodes_high_rating_titles\n\n# This yielded unsatisfactory, unidentifiable series, let's try to limit by quantile\nquantile(tv_show_12_episodes_high_rating_ID$total_votes, prob = seq(0,1,.1))\n\n# Graph used to visualize the quantiles\nggplot(quantile_data, aes(x = quantile, y = votes, fill = quantile)) + \n  geom_col() + \n  scale_fill_brewer(palette = \"Set3\") +  \n  labs(title = \"Quantile Breakdown of Number of Votes\", \n       x = \"Percentage of Shows Receiving Votes\", \n       y = \"Number of Votes\") +\n   scale_y_continuous(labels = label_number(scale_cut = cut_short_scale())) +\n  theme_minimal() +\n  theme(legend.position = \"none\",  plot.title = element_text(hjust = 0.5))  \n\n# Investegating the top 10% of shows \ntv_show_12_episodes_high_rating_titles &lt;- \n  tv_show_12_episodes_high_rating_ID |&gt; \n  inner_join(TITLE_BASICS, join_by(parentTconst == tconst)) |&gt;\n  filter(total_votes &gt; 327732) |&gt;\n  group_by(parentTconst, primaryTitle) |&gt;  \n  summarize(average_rating_for_series = first(average_rating_for_series), .groups = 'drop') |&gt;\n  arrange(desc(average_rating_for_series)) |&gt;\n  slice_max(order_by = average_rating_for_series, n = 10)\n\n\n\nSingular TV Episode rated highly\nOne of the unfortunate legacies of Star Wars is that many films have become risk adverse, bottom-line motivated entities that will only pursue formulaic, blockbuster-by-numbers despite audiences still wanting innovative stories, strong performances and bold filmmaking. A big segment of this movie going audience exhausted by “blockbuster or bust” entertainment has shifted their attention back to smaller screens.\nIn the last 20 years with the rise of “prestige television” a good number of our greatest film creatives, who previously would’ve exclusively made movies, have turned their attention to television. In may ways, due to the inert, IP-focused model for modern movie development, a lot of the innovation we now see on screen happens in episodic television series.\nFew shows have capitalized on this change in the zeitgeist and cast as large of a cultural shadow as Breaking Bad, Vince Gilligan’s storied show documenting the transformation of an ailing, beleagured chemistry teacher into the methamphetamine king of the American southwest.\nWhile Breaking Bad consistently met audience expectations, it achieved the enviable feat of building both critical and fan-approved momentum right through its final episodes. Yet no episode captured this phenomenon better than the show’s antepenultimate installment, Ozymandias and both the reviews and sentiment in the IMDb database reflect this:\n\nHank!\n\n\nSeries Title\nEpisode Title\nYear\n\n\n\n\nBreaking Bad\nOzymandias\n2013\n\n\n\n\n\n&gt; show the code\n\ntop_episodes &lt;- TITLE_RATINGS |&gt;\n  filter(averageRating == 10 & numVotes &gt;= 200000)\n\nepisode_details &lt;- top_episodes |&gt;\n  inner_join(TITLE_BASICS, by = \"tconst\") |&gt;\n  inner_join(TITLE_EPISODES, by = \"tconst\")\n  \nepisode_details |&gt;\n  inner_join(TITLE_BASICS, join_by(\"parentTconst\" == \"tconst\")) |&gt;\n  select(series_title = primaryTitle.y, episode_title = primaryTitle.x, year = startYear.x)\n\n\n\nJump the Shark with Happy Days\nUnfortunately not all shows can go out on top like Breaking Bad.\nMany shows build an audience but eventually the creative well runs dry and end up disappointing fans. This common phenomenon of a show growing in stature and adulation, but eventually reaching a peak of popularity that ultimately turns into a downswing of audience disappointment. That is, the moment when a show’s popularity peaks, and then dramaitically wanes as audiences lose interest after a shows’ writers cross a line with a ridiculous gimmick, plot contrivance or unbelievable absurdity.\nThis pivotal moment in a show’s trajectory has been identified as “jumping the shark” and it’s named after a famous episode of the 1950s nostalgia sitcom Happy Days when its iconic character “The Fonze” waterski-jumped over an actual shark.\nHappy Days is now arguably known for this meta-moment in pop culture than its many years of success. But is this fair? Did Happy Days “jump the shark”? Does this silly episode in fact represent the famed turning point for Happy Days fortunes as the culture now believes?\nWikipedia suggests the famous “jumping the shark” episode from Happy Days happened episode 3 season 5.\nAfter we identify all the episdoes of Happy Days in our IMDb data we create two sets of data filtered around the pivot point of season 5 episode 3 : before shark and after shark.\nPerforming calculations on these two sets we see:\n&gt; mean(happy_days_episodes_ratings_before_shark$averageRating)\n[1] 7.484404\n\n&gt; mean(happy_days_episodes_after_shark$averageRating)\n[1] 6.878571\nIt look like “yes” Happy Days did, in fact, jump its own proverbial shark.\n\n\n&gt; show the code\n\n# Identifying the IMDb ID for television series \"Happy Days\"\nTITLE_BASICS |&gt; \n  filter(titleType == \"tvSeries\" & primaryTitle == \"Happy Days\") \n\n# Singling out all \"Happy Days\" epsidoes in our titles dataset \nhappy_days_episodes &lt;- TITLE_EPISODES |&gt; \n  filter(parentTconst == \"tt0070992\")\n\n# Joining our \"Happy Days\" episodes with their ratings\nhappy_days_episodes_ratings &lt;- happy_days_episodes |&gt; \n  inner_join(TITLE_RATINGS, by = \"tconst\")\n\n# Filtering on all episodes before the infamous \"shark jump\" episode of \n# Episode 3, Season 5\nhappy_days_episodes_ratings_before_shark &lt;- happy_days_episodes_ratings |&gt; \n  filter((seasonNumber &lt; 5) | (seasonNumber == 5 & episodeNumber &lt; 3)) \n\n# With our \"before shark\" episodes, using a filter join to create a data set\n# for \"after shark\" \nhappy_days_episodes_after_shark &lt;- happy_days_episodes_ratings |&gt;\n  anti_join(happy_days_episodes_ratings_before_shark, by = \"tconst\") \n\n# With \"before shark\" and \"after shark\" data sets, we can perform our calculations\nmean(happy_days_episodes_ratings_before_shark$averageRating)\nmean(happy_days_episodes_after_shark$averageRating)"
  },
  {
    "objectID": "mp02.html#beyond-the-spotlight",
    "href": "mp02.html#beyond-the-spotlight",
    "title": "IMDb and Me",
    "section": "Beyond the Spotlight",
    "text": "Beyond the Spotlight\nWe’re going to use ratings in IMDb to create a measure to document the significant, successful films. IMDb ratings are crowdsources from its users. Films with more votes are going to have more stable rating and there is a left skew to the distribution of films and the number of individuals who have rated the film:\n     0%     10%     20%     30%     40%     50%     60%     70%     80%     90% \n    100     120     148     187     246     332     473     738    1332    3355\nI’m going to filter out the top ~20% of rated films.\nIn an attempt to single out noteworthy remaining films, I created a statistical quantification of a movie’s positioning by evaluating both its IMDb rating and the number of IMDb users who voted on the film. This approach aims to capture both the quality (via the rating) and the popularity (via the number of votes) of the film.\nTo achieve this, I calculated Z-scores for both the film’s rating and its number of votes, which measure how far each value deviates from the mean in terms of standard deviations. I then transformed these Z-scores into cumulative probabilities using the pnorm() function, which maps the Z-scores to probabilities between 0 and 1, effectively scaling the values from 1 to 100. To emphasize quality, I assigned a weight of 2 to the film’s rating in the final combined score.\n\\[\n\\text{Total Score} = 2 \\cdot \\Phi(\\text{rating score}) + \\Phi(\\text{votes score})\n\\]\nHere are the results for the top films:\n\nTable: Top 10 Movies by Film Score\n\n\n\n\n\n\n\nPrimary Title\nStart Year\nFilm Score\n\n\n\n\nThe Shawshank Redemption\n1994\n99.97593\n\n\nThe Godfather\n1972\n99.97335\n\n\nThe Godfather Part II\n1974\n99.96597\n\n\nSchindler’s List\n1993\n99.96597\n\n\nThe Lord of the Rings: The Return of the King\n2003\n99.96597\n\n\nThe Dark Knight\n2008\n99.96597\n\n\n12 Angry Men\n1957\n99.96597\n\n\nPulp Fiction\n1994\n99.96070\n\n\nThe Lord of the Rings: The Fellowship of the Ring\n2001\n99.96070\n\n\nForrest Gump\n1994\n99.95391\n\n\n\nHere are the results for the bottom films:\n\nTable: Movies with Low Film Scores\n\n\n\n\n\n\n\nPrimary Title\nStart Year\nFilm Score\n\n\n\n\nTrack of the Moon Beast\n1976\n6.580106\n\n\nBoggy Creek II: And the Legend Continues\n1983\n6.577407\n\n\nAnne B. Real\n2003\n6.576749\n\n\nKayhan\n2018\n6.576689\n\n\nOrgy of the Dead\n1965\n6.576307\n\n\nAmazing China\n2018\n6.575677\n\n\nDarling Nikki\n2019\n6.573956\n\n\nAlien Warfare\n2019\n6.572054\n\n\nAnus Magillicutty\n2003\n6.569317\n\n\nHole in One\n2009\n6.564986\n\n\n\nMovie Box Office is reported in several popular, widely available media outlets and box office data is the type of low-stakes, hobby-friendly metrics that Internet-curated resources like Kaggle are uniquely suited for. To check the box office returns of the Total Score calculation, the Kaggle Movies Dataset was used for box office under the variable revenue.\nHowever, films can span several decades and box office figures are not as useless unless the numbers are controlled in constant dollars. To correct for this the following variable was added to our data:\n\\(\\text{Box Office Adjusted in 2024 Dollars} = \\text{Box Office} \\times \\frac{\\text{Consumer Price Index 2024}}{\\text{Consumer Price Index Historical Year}}\\)\nIt’s always interesting to view films ranked by adjusted box office figures :\n\nTable: Top 10 Movies by Adjusted Box Office in 2024 Dollars\n\n\n\n\n\n\n\nPrimary Title\nStart Year\nAdjusted Box Office\n\n\n\n\nGone with the Wind\n1939\n$8,815,801,640\n\n\nAlice in Wonderland\n1951\n$6,945,453,701\n\n\nBambi\n1942\n$5,253,837,431\n\n\nStar Wars: Episode IV - A New Hope\n1977\n$4,087,964,566\n\n\nAvatar\n2009\n$4,072,386,147\n\n\nSnow White and the Seven Dwarfs\n1937\n$4,044,976,143\n\n\nTitanic\n1997\n$3,576,617,908\n\n\nCinderella\n1950\n$3,459,407,380\n\n\nThe Exorcist\n1973\n$3,194,983,975\n\n\nThe Sound of Music\n1965\n$2,829,274,085\n\n\n\nHere now is our data with our box office figures. This table suggests Film Score identifies financially successful films:\n\nTable: Top 10 Movies by Film Score and Adjusted Box Office\n\n\n\n\n\n\n\n\nPrimary Title\nStart Year\nFilm Score\nAdjusted Box Office\n\n\n\n\nThe Shawshank Redemption\n1994\n99.97593\n$59,787,899\n\n\nThe Godfather\n1972\n99.97335\n$1,838,993,851\n\n\nThe Godfather Part II\n1974\n99.96597\n$314,657,090\n\n\nSchindler’s List\n1993\n99.96597\n$695,053,325\n\n\nThe Lord of the Rings: The Return of the King\n2003\n99.96597\n$1,899,198,581\n\n\nThe Dark Knight\n2008\n99.96597\n$1,467,798,473\n\n\n12 Angry Men\n1957\n99.96597\n$11,174,529\n\n\nPulp Fiction\n1994\n99.96070\n$451,294,576\n\n\nThe Lord of the Rings: The Fellowship of the Ring\n2001\n99.96070\n$1,534,807,634\n\n\nForrest Gump\n1994\n99.95391\n$1,430,163,380\n\n\n\nWhile The Shawshank Redemption looks like a “failure” here, it famously more than made up for its lackluster Box Office returns in DVD sales, cable television licensing and streaming agreements:\n\n“It’s an incredible moneymaking asset that continues to resonate with viewers,” said Jeff Baker, the former executive vice president and general manager of Warner Bros. Home Entertainment theatrical catalog, in that Wall Street Journal piece. “Shawshank” is one of the best performers in the studio’s library, in no small part thanks to strong DVD/Blu-ray sales, not to mention streaming\n\nDoes film_score work in reverse? Does it correctly identify “bad” movies?\nFiltering for films that are in the top 80% of movies voted on, and sorting on film_score yields some truly terrible films:\n\nTable: Movies with Moderate Film Scores and Adjusted Box Office\n\n\n\n\n\n\n\n\nPrimary Title\nStart Year\nFilm Score\nAdjusted Box Office\n\n\n\n\nThe Starfighters\n1964\n6.541835\n$0\n\n\nFinal Justice\n1984\n6.547430\n$0\n\n\nTime Chasers\n1994\n6.552881\n$0\n\n\nMega Shark vs. Mecha Shark\n2014\n6.553869\n$0\n\n\nOrgy of the Dead\n1965\n6.576307\n$0\n\n\nBoggy Creek II: And the Legend Continues\n1983\n6.577407\n$0\n\n\nTrack of the Moon Beast\n1976\n6.580106\n$0\n\n\nLevottomat 3 - kun mikään ei riitä\n2004\n6.581920\n$0\n\n\nThe Blade Master\n1983\n6.583010\n$0\n\n\nGirl in Gold Boots\n1968\n6.585128\n$0\n\n\n\nHow about examining a prominent director? Is there any direcor more prominent than Steven Spielberg? Querying for film_score, we find Steven Spielberg’s films score :\n[1] 88.5889\nEven including Indiana Jones and the Kingdom of the Crystal Skull (2008), The BFG (2016), and Always (1989), Steven Spielberg films collectively average in the top 89% of all films. film_score correctly identifies the most prominent talent in the industry.\nHow does another director compare to Steven Spielberg?\nDirecor Uwe Boll is famous for being a critically reviled filmmaker. He’s actually known as “The Worst Director in the World”.\nDoes film_score correctly identify Uwe Boll’s filmography as not-Spielbergian?\nIt certainly does. Here is the collective film_score rating of all Uwe Boll films:\n[1] 14.53452\nTo identify a film_score cut-off, I exported the data into a spread sheet for ease of viewing. I scrolled through the films assessing the quality of the neighboring films until I started to identify a good number of forgettable films. I used the entirely scientific process of scanning this list until I reached the point of “I really don’t see many good films below this number.” I found a fitting threshold with Indiana Jones and the Kingdom of the Crystal Skull (2008).\nI’m going to settle on 77.46 as the film_score threshold dividing “good movie” from “bad movie”:\n\n\n\n&gt; show the code\n\n# Surveying the distriubtion of films by number of votes\nquantile(TITLE_RATINGS$numVotes, probs=seq(0,1,0.05))\n\n# Filtering those films accordingly \nfiltered_title_ratings &lt;- TITLE_RATINGS |&gt; \n  filter(numVotes &gt; 3335)\n\n# Finding the standard deviations and mean for ratings and votes\nSD_RATING &lt;- sd(filtered_title_ratings$averageRating)\nMEAN_RATING &lt;- mean(filtered_title_ratings$averageRating)\nSD_VOTES &lt;- sd(filtered_title_ratings$numVotes)\nMEAN_VOTES &lt;-mean(filtered_title_ratings$numVotes)\n\n# Calculating the cumulative probabilities for ratings and votes \n# and created total_score metric\nfilms_scores &lt;- filtered_title_ratings |&gt; \n  inner_join(TITLE_BASICS, by = \"tconst\") |&gt; \n  filter(titleType == \"movie\") |&gt;\n  mutate(\n    rating_score = pnorm((averageRating - MEAN_RATING) / SD_RATING),\n    votes_score = pnorm((numVotes - MEAN_VOTES) / SD_VOTES)\n  ) |&gt;\n  mutate(total_score = 2 * rating_score + votes_score) |&gt;\n  arrange(desc(total_score)) \n\n# Re-calculating the standard deviations for total_score\nSD_SCORE &lt;- sd(films_scores$total_score)\nMEAN_SCORE &lt;- mean(films_scores$total_score)\n\n# Converting total_score to film_score via cumulative probabilities\nfilms_scores &lt;- films_scores |&gt; \n  mutate(film_score = pnorm((total_score - MEAN_SCORE) / SD_SCORE) * 100) |&gt; \n  arrange(desc(film_score)) \n\n# Checking if film_score identifies good films\nfilms_scores |&gt; \n  head(films_scores, 10) |&gt;\n  select(primaryTitle, startYear, film_score)\n\n# Checking if film_score identifies bad films\nfilms_scores |&gt; \n  tail(films_scores, 10) |&gt;\n  select(primaryTitle, startYear, film_score)\n\n##### CONSUMER PRICE INDEX CALCULATIONS #####\n\n# Reading the historical CPI figure for each year\nHISTORICAL_CPI &lt;- read.csv(\"data/mp02/HISTORICAL_CPI.csv\") |&gt;\n   mutate(year = substring(DATE,1,4))\n\n# Create a named vector for CPI figures for each year\ncpi_named_vector &lt;- setNames(HISTORICAL_CPI$CPIAUCNS, HISTORICAL_CPI$year)\n\n# Function for calculating a dollar figure by 2024 dollars\nget_dollar_adjusted_value &lt;- function(budget, year){\n  return (budget * cpi_named_vector[as.character(2024)]/cpi_named_vector[as.character(year)]) \n\n#############################################\n  \n# Add adjusted_box_office figure now with CPI calculation\nfilms_scores_box_office &lt;- films_scores |&gt;\n  inner_join(KAGGLE_DATA, join_by(tconst == imdb_id)) |&gt; \n  mutate(adjusted_box_office = get_dollar_adjusted_value(revenue, startYear))\n\n# Surveying how good film_score is at documenting box office successes\nfilms_scores_box_office |&gt; \n  select(primaryTitle, startYear, film_score, adjusted_box_office ) |&gt;\n  arrange(desc(film_score)) |&gt; \n  slice(1:10)\n\n# Surveying how good film_score is at documenting box office failures\nfilms_scores_box_office |&gt; \n  select(primaryTitle, startYear, film_score)\n  tail(films_scores, 10) |&gt;\n  \n# Finding Steven Spielberg\nss_id &lt;- NAME_BASICS |&gt; \n  filter(primaryName == \"Steven Spielberg\") |&gt; \n  pull(nconst)\n\n# Identifying all Steven Spielberg films\nss_films &lt;- TITLE_PRINCIPALS |&gt; \n  filter(nconst == ss_id[1] & category == \"director\") |&gt;\n  pull(tconst)\n\n# Calculating average score for all Steven Spielberg films\nfilms_scores_box_office |&gt;\n  filter(tconst %in% ss_films) |&gt;\n  summarize(average_film_score = mean(film_score, na.rm = TRUE)) |&gt;\n  pull(average_film_score)\n\n# Finding Uwe Boll\nub_id &lt;- NAME_BASICS |&gt; \n  filter(primaryName == \"Uwe Boll\") |&gt; \n  pull(nconst)\n\n# Identifying all Uwe Boll films\nub_films &lt;- TITLE_PRINCIPALS |&gt; \n  filter(nconst == ub_id[1] & category == \"director\") |&gt;\n  pull(tconst)\n\n# Calculating the average score for all Uwe Boll films\nfilms_scores_box_office |&gt;\n  filter(tconst %in% ub_films) |&gt;\n  summarize(average_film_score = mean(film_score, na.rm = TRUE)) |&gt;\n  pull(average_film_score)\n\n# Data Frame exported for analysis \ndf_csv &lt;- films_scores_box_office |&gt;\n  select(primaryTitle, startYear, film_score, adjusted_box_office)\n\n# Export a .csv for viewing\nwrite.csv(df_csv, \"films_scores_box_office.csv\", row.names = FALSE)"
  },
  {
    "objectID": "mp02.html#best-in-decade",
    "href": "mp02.html#best-in-decade",
    "title": "IMDb and Me",
    "section": "Best in Decade",
    "text": "Best in Decade\nThey say every picture tells a story. These charts scream the narrative loud and clear.\nExploring the popularity of film genres across decades reveals fascinating insights into culture and how it inevitably reflects culture.\n\nLook no futher than Western indeed being a forgotten genre, falling out of favor by the time of the 1970s and 1980s. Same with War, likely a reflection of the fading legacy of America’s triumphant relationship with World War II.\nAnd for the horniest segment of this project, this chart documents the famed Adult Entertainment Film Production Heyday of the 1970s and 1980s.\nThis graphic is a little crowded by existence of Comedy and Drama both of which occupy a steady, unflappable positioning this data (suggesting the enduring audience appetite for both genres). What if we were to?:\n\nRemove all Comedy and Drama films\nRemove all independent or films that did not gross any revenue\n\n\nThis yields an more satisfying chart as it visably identifies the rise and fall of genre trends - with the understanding Comedy and Drama are longstanding genres that are unlikely to fall out of favor anytime soon.\nAnother historical observation: was the retreat of the Action genre in the 2000s initiated by a post 9/11 public less-tolerant of the fanciful absurdities of 80s and 90s action films?\nIs the rise in the Thriller genre in recent years commenting at all on our collective psychologies? Does is speak to a rising anxiety among us?\nBut while the popularity of Thrillers are not in doubt, what has become of the Romance movie?\nConsidering the recent box office succes Anyone But You (2023) is Hollywood narrow-mindedly avoiding romance movies and with it, is Hollywood neglecting women audiences?\nIf you were to survey wage trends from the Bureau of Labor Statistics, there exists an unmistakable upward trend in women’s wages that does not appear likely to receed. What’s more, over a few decades time, women’s wages continue to make inroads in narrowing the stubborn income gap with men.\n\n\n\nBureau of Labor Statistics\n\n\nIs Hollywood leaving money on the table? Is there opportunity to market to a consistently neglected segment of the film-going audience?\nIs there a chance to innovate? A chance to develop a film that is at once, a part of genre that serves an underrepresented demographic, while also captializing on a genre that contintues to demonstrate growth and consistent popularity?\n\nThe big pitch idea:\nCan we develop a romance thriller?\n\n\n&gt; show the code\n\n\n# Narrow down titles and filter out televsion \nslim_title_basics &lt;- TITLE_BASICS |&gt; \n  filter(startYear &gt; 1940 & titleType == \"movie\") |&gt; \n  select(tconst, primaryTitle, startYear, genres, titleType) |&gt; \n  separate_rows(genres, sep = \",\") |&gt; \n    filter(!(genres %in% c(\"Music\",\"Musical\", \"Reality-TV\", \"News\",\"\\\\N\", \"Talk-Show\", \"Film-Noir\",\"Game-Show\",  \"History\",\"Biography\", \"Crime\", \"Sport\"))) |&gt;\n  mutate(startYear = as.numeric(startYear), \n         decade = floor(startYear / 10) * 10,\n         decade = factor(decade, levels = sort(unique(floor(as.numeric(startYear) / 10) * 10))))\n\n# Identify gentre counts by the decades from 1940+\ngenre_count_by_decade &lt;- slim_title_basics |&gt;\n  group_by(decade, genres) |&gt;\n  summarize(genre_count = n(), .groups = 'drop')\n\n# Create an chart with our findings\nggplot(genre_count_by_decade, aes(x = decade, y = genre_count, fill = genres)) +\n  geom_bar(stat = \"identity\", position = \"fill\", color = \"black\") +\n  scale_y_continuous(labels = scales::percent) +  # Makes the y-axis percentages\n  labs(y = \"Percentage\", x = \"Decade\", fill = \"Genres\", title = \"Genre Popularity by Decade\",\n  subtitle = \"With Independent Films\") +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5),           \n        plot.subtitle = element_text(hjust = 0.5))\n\n# Re-create our data but this time without Drama and Comedy\nslim_title_no_comedy_no_drama &lt;- films_scores |&gt; \n  filter(startYear &gt; 1940 & titleType == \"movie\") |&gt; \n  select(tconst, primaryTitle, startYear, genres, titleType) |&gt; \n  separate_rows(genres, sep = \",\") |&gt; \n    filter(!(genres %in% c(\"Music\",\"Musical\",\"Comedy\", \"Drama\", \"Reality-TV\", \"News\",\"\\\\N\", \"Talk-Show\", \"Film-Noir\",\"Game-Show\",  \"History\",\"Biography\", \"Crime\", \"Sport\"))) |&gt;\n  mutate(startYear = as.numeric(startYear), \n         decade = floor(startYear / 10) * 10,\n         decade = factor(decade, levels = sort(unique(floor(as.numeric(startYear) / 10) * 10))))\n\n# Re-count our findings\ngenre_count_by_decade_no_comedy &lt;- slim_title_no_comedy_no_drama |&gt;\n  group_by(decade, genres) |&gt;\n  summarize(genre_count = n(), .groups = 'drop')\n\n# Re-plot \nggplot(genre_count_by_decade_no_comedy, aes(x = decade, y = genre_count, fill = genres)) +\n  geom_bar(stat = \"identity\", position = \"fill\", color = \"black\") +\n  scale_y_continuous(labels = scales::percent) + \n  labs(y = \"Percentage\", x = \"Decade\", fill = \"Genres\", title = \"Genre Popularity by Decade\", subtitle = \"Without Independent films or Comedy or Drama\") +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5),           \n        plot.subtitle = element_text(hjust = 0.5))\n\n# Load our wage data       \nwages &lt;- read.csv(\"data/mp02/wages.csv\")\nwages$Men &lt;- as.numeric(gsub(\",\", \"\", wages$Men))\nwages$Women &lt;- as.numeric(gsub(\",\", \"\", wages$Women))\nwages &lt;- wages[-nrow(wages), ]\n\n# Plot the distinction between men's and women's wages\nggplot(wages, aes(x=X)) +\n  geom_line(aes(y = Women, color = \"Women\"), size = 1.2) +\n  geom_line(aes(y = Men, color = \"Men\"), linetype = \"twodash\", size = 1.2) +\n  geom_smooth(aes(y = Women), method = \"lm\", se = FALSE, color=\"black\", linetype = \"dashed\", size = .2) +\n  geom_smooth(aes(y = Men), method = \"lm\", se = FALSE, color=\"black\", linetype = \"dashed\", size = .2) +\n  labs(y = \"Weekly Wages\", x = \"Decade\", title = \"40 Year Trend in Wages by Gender\", color=\"Gender\") +\n  scale_y_continuous(labels = dollar_format()) + \n  theme_bw() +\n  theme(plot.title = element_text(hjust = 0.5))"
  },
  {
    "objectID": "mp02.html#section",
    "href": "mp02.html#section",
    "title": "IMDb and Me",
    "section": "",
    "text": "polarizing_films &lt;- movie_lens_and_IMDb |&gt; group_by(IMDbId, primaryTitle, startYear, genres) |&gt; summarise(mean_rating = mean(rating), sd_rating = sd(rating), num_ratings = n()) |&gt; arrange(desc(sd_rating)) |&gt; select(-IMDbId)\npolarizing_films\npolarizing_films &lt;- movie_lens_and_IMDb |&gt; group_by(movieId, primaryTitle, startYear, genres) |&gt; summarise(mean_rating = mean(rating), iqr_rating = IQR(rating), num_ratings = n()) |&gt; arrange(desc(iqr_rating))\npolarizing_films &lt;- movie_lens_and_IMDb |&gt; group_by(movieId, primaryTitle, startYear, genres) |&gt; summarise(mean_rating = mean(rating), var_rating = var(rating), num_ratings = n()) |&gt; arrange(desc(var_rating))\n\nmovie_lens_and_IMDb_and_kaggle &lt;- movie_lens_and_IMDb |&gt; inner_join(KAGGLE_DATA, join_by(tconst == IMDb_id))\nmovie_lens_and_IMDb_and_kaggle\nget_dollar_adjusted_value &lt;- function(budget, year){ return (budget * cpi_named_vector[as.character(2024)]/cpi_named_vector[as.character(year)]) }\nvotes_budget &lt;- movie_lens_and_IMDb_and_kaggle |&gt; group_by(IMDbId, primaryTitle, budget, startYear, revenue) |&gt; summarize(num_votes = n()) |&gt; mutate(adjusted_budget = get_dollar_adjusted_value(budget, startYear), adjusted_profit = get_dollar_adjusted_value(revenue, startYear) - get_dollar_adjusted_value(budget, startYear) )\nmodel_profit &lt;- lm(votes_budget\\(num_votes ~  votes_budget\\)adjusted_profit)\nreg_line &lt;- function(x_val, model){ return(coef(model)[1] + coef(model)[2] * x_val) }\nvotes_budget_profit &lt;- votes_budget |&gt; mutate(popularity_over_profit = num_votes - reg_line(adjusted_profit, model_profit)) |&gt; arrange(desc(popularity_over_profit))\n\nggplot(data = votes_budget_profit, aes(x = adjusted_profit, y = num_votes )) + geom_point(alpha = 0.1) + geom_smooth(method=“lm”, se=FALSE)\nmodel_budget &lt;- lm(votes_budget\\(num_votes ~  votes_budget\\)adjusted_budget)\nvotes_budget_budget &lt;- votes_budget |&gt; mutate(popularity_over_budget = num_votes - reg_line(adjusted_budget, model_profit)) |&gt; arrange(desc(popularity_over_budget))\nprint(votes_budget_budget, n =100)\n\nvotes_budget |&gt; arrange(desc(adjusted_budget)) |&gt; print(n = 100)\ntop_500_polarizing_films &lt;- head(polarizing_films, 500)\ntop_500_polarizing_films_w_budget &lt;- top_500_polarizing_films |&gt; inner_join(KAGGLE_DATA, join_by(IMDbId == IMDb_id))\ntop_500_polarizing_films_w_budget"
  },
  {
    "objectID": "mp02.html#can-we-develop-a-romance-thriller",
    "href": "mp02.html#can-we-develop-a-romance-thriller",
    "title": "IMDb and Me",
    "section": "Can we develop a romance thriller?",
    "text": "Can we develop a romance thriller?\n\n\n&gt; show the code\n\nslim_title_basics &lt;- TITLE_BASICS |&gt; \n  filter(startYear &gt; 1940 & titleType == \"movie\") |&gt; \n  select(tconst, primaryTitle, startYear, genres, titleType) |&gt; \n  separate_rows(genres, sep = \",\") |&gt; \n    filter(!(genres %in% c(\"Music\",\"Musical\", \"Reality-TV\", \"News\",\"\\\\N\", \"Talk-Show\", \"Film-Noir\",\"Game-Show\",  \"History\",\"Biography\", \"Crime\", \"Sport\"))) |&gt;\n  mutate(startYear = as.numeric(startYear), \n         decade = floor(startYear / 10) * 10,\n         decade = factor(decade, levels = sort(unique(floor(as.numeric(startYear) / 10) * 10))))\n\ngenre_count_by_decade &lt;- slim_title_basics |&gt;\n  group_by(decade, genres) |&gt;\n  summarize(genre_count = n(), .groups = 'drop')\n\nggplot(genre_count_by_decade, aes(x = decade, y = genre_count, fill = genres)) +\n  geom_bar(stat = \"identity\", position = \"fill\", color = \"black\") +\n  scale_y_continuous(labels = scales::percent) +  # Makes the y-axis percentages\n  labs(y = \"Percentage\", x = \"Decade\", fill = \"Genres\", title = \"Genre Popularity by Decade\",\n  subtitle = \"With Independent Films\") +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5),           \n        plot.subtitle = element_text(hjust = 0.5))\n\nslim_title &lt;- films_scores |&gt; \n  filter(startYear &gt; 1940 & titleType == \"movie\") |&gt; \n  select(tconst, primaryTitle, startYear, genres, titleType) |&gt; \n  separate_rows(genres, sep = \",\") |&gt; \n    filter(!(genres %in% c(\"Music\",\"Musical\", \"Reality-TV\", \"News\",\"\\\\N\", \"Talk-Show\", \"Film-Noir\",\"Game-Show\",  \"History\",\"Biography\", \"Crime\", \"Sport\"))) |&gt;\n  mutate(startYear = as.numeric(startYear), \n         decade = floor(startYear / 10) * 10,\n         decade = factor(decade, levels = sort(unique(floor(as.numeric(startYear) / 10) * 10))))\n\ngenre_count_by_decade &lt;- slim_title |&gt;\n  group_by(decade, genres) |&gt;\n  summarize(genre_count = n(), .groups = 'drop')\n\nggplot(genre_count_by_decade, aes(x = decade, y = genre_count, fill = genres)) +\n  geom_bar(stat = \"identity\", position = \"fill\", color = \"black\") +\n  scale_y_continuous(labels = scales::percent) +  # Makes the y-axis percentages\n  labs(y = \"Percentage\", x = \"Decade\", fill = \"Genres\", title = \"Genre Popularity by Decade\",\n  subtitle = \"Without Independent Films\") +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5),           \n        plot.subtitle = element_text(hjust = 0.5))\n  \nslim_title_no_comedy_no_drama &lt;- films_scores |&gt; \n  filter(startYear &gt; 1940 & titleType == \"movie\") |&gt; \n  select(tconst, primaryTitle, startYear, genres, titleType) |&gt; \n  separate_rows(genres, sep = \",\") |&gt; \n    filter(!(genres %in% c(\"Music\",\"Musical\",\"Comedy\", \"Drama\", \"Reality-TV\", \"News\",\"\\\\N\", \"Talk-Show\", \"Film-Noir\",\"Game-Show\",  \"History\",\"Biography\", \"Crime\", \"Sport\"))) |&gt;\n  mutate(startYear = as.numeric(startYear), \n         decade = floor(startYear / 10) * 10,\n         decade = factor(decade, levels = sort(unique(floor(as.numeric(startYear) / 10) * 10))))\n\ngenre_count_by_decade_no_comedy &lt;- slim_title_no_comedy_no_drama |&gt;\n  group_by(decade, genres) |&gt;\n  summarize(genre_count = n(), .groups = 'drop')\n\nggplot(genre_count_by_decade_no_comedy, aes(x = decade, y = genre_count, fill = genres)) +\n  geom_bar(stat = \"identity\", position = \"fill\", color = \"black\") +\n  scale_y_continuous(labels = scales::percent) + \n  labs(y = \"Percentage\", x = \"Decade\", fill = \"Genres\", title = \"Genre Popularity by Decade\", subtitle = \"Without Independent films or Comedy or Drama\") +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5),           \n        plot.subtitle = element_text(hjust = 0.5))\n        \nwages &lt;- read.csv(\"data/mp02/wages.csv\")\nwages$Men &lt;- as.numeric(gsub(\",\", \"\", wages$Men))\nwages$Women &lt;- as.numeric(gsub(\",\", \"\", wages$Women))\nwages &lt;- wages[-nrow(wages), ]\n\nggplot(wages, aes(x=X)) +\n  geom_line(aes(y = Women, color = \"Women\"), size = 1.2) +\n  geom_line(aes(y = Men, color = \"Men\"), linetype = \"twodash\", size = 1.2) +\n  geom_smooth(aes(y = Women), method = \"lm\", se = FALSE, color=\"black\", linetype = \"dashed\", size = .2) +\n  geom_smooth(aes(y = Men), method = \"lm\", se = FALSE, color=\"black\", linetype = \"dashed\", size = .2) +\n  labs(y = \"Weekly Wages\", x = \"Decade\", title = \"40 Year Trend in Wages by Gender\", color=\"Gender\") +\n  scale_y_continuous(labels = dollar_format()) + \n  theme_bw() +\n  theme(plot.title = element_text(hjust = 0.5)) \n\n\n&lt;!-- genre_count_by_decade_no_comedy |&gt; finish for romance trend --&gt;\n  \n\nHere is an image detailing gender disparities in Hollywood.\n\nHere is me looking for actors who have been in prominent films. The top 2 look like a great choice!\n\nTable: Actors and Actresses by Age and Movie Count\n\n\nPrimary Name\nCategory\nAge\nMovie Count\n\n\n\n\nScarlett Johansson\nActress\n40\n35\n\n\nJake Gyllenhaal\nActor\n44\n23\n\n\nChris Evans\nActor\n43\n20\n\n\nSeth Rogen\nActor\n42\n17\n\n\nChris Hemsworth\nActor\n41\n16\n\n\nEmma Stone\nActress\n36\n16\n\n\nNatalie Portman\nActress\n43\n15\n\n\nChris Pratt\nActor\n45\n15\n\n\nRajkummar Rao\nActor\n40\n15\n\n\nKirsten Dunst\nActress\n42\n14\n\n\n\nTop Women Directors:\n\nTable: Top Women Directors by Movie Count\n\n\nPrimary Name\nCategory\nAge\nMovie Count\n\n\n\n\nLilly Wachowski\nDirector\n57\n5\n\n\nLana Wachowski\nDirector\n59\n5\n\n\nZoya Akhtar\nDirector\n52\n2\n\n\nJoan Chen\nDirector\n63\n1\n\n\nGail Mancuso\nDirector\n66\n1\n\n\nMary Elizabeth McGlynn\nDirector\n58\n1\n\n\nJessie Nelson\nDirector\nNA\n1\n\n\nMaria Schrader\nDirector\n59\n1\n\n\nReema Kagti\nDirector\nNA\n1\n\n\nOlivia Wilde\nDirector\n40\n1\n\n\n\nJordan Peele looks like a great choice…\n\nTable: Directors by Age and Movie Count\n\n\nPrimary Name\nCategory\nAge\nMovie Count\n\n\n\n\nBenny Safdie\nDirector\n38\n2\n\n\nJohn Francis Daley\nDirector\n39\n2\n\n\nOlivia Wilde\nDirector\n40\n1\n\n\nSeth Rogen\nDirector\n42\n2\n\n\nEvan Goldberg\nDirector\n42\n2\n\n\nJoseph Gordon-Levitt\nDirector\n43\n1\n\n\nFran Kranz\nDirector\n43\n1\n\n\nJordan Peele\nDirector\n45\n3\n\n\nJohn Krasinski\nDirector\n45\n2\n\n\nMert Baykal\nDirector\n45\n1\n\n\n\n\n\n&gt; show the code\n\ntop_movies &lt;- films_scores |&gt;\n  filter(film_score &gt; 77.46)\n\n\n\ntalent &lt;- TITLE_PRINCIPALS |&gt;\n  filter(tconst %in% top_movies$tconst, category %in% c(\"actor\", \"actress\", \"director\")) |&gt;\n  inner_join(names_in_many_big_productions, by = \"nconst\") |&gt;\n  inner_join(films_scores, by = \"tconst\") |&gt;\n  group_by(nconst, primaryName, category, age) |&gt;\n  summarize(movie_count = n()) |&gt;\n  arrange(desc(movie_count))\n\ntalent_again &lt;- TITLE_PRINCIPALS |&gt;\n  filter(tconst %in% top_movies$tconst, category %in% c(\"actor\", \"actress\", \"director\")) |&gt;\n  inner_join(names_in_many_big_productions, by = \"nconst\") |&gt;\n  inner_join(films_scores, by = \"tconst\") |&gt;\n  group_by(nconst, primaryName, category, age) |&gt;\n  summarize(movie_count = n(), mean_film_score = mean(film_score, na.rm = TRUE)) |&gt;\n  arrange(desc(movie_count))\n\n\ntop_actors &lt;- talent_again |&gt;\n  filter(category %in% c(\"actor\", \"actress\"), age &gt;= 20 & age &lt;= 45 & movie_count &gt; 4) |&gt;\n  arrange(desc(mean_film_score))\n\nactors_summary &lt;- top_actors |&gt; \n  group_by(category) |&gt; \n  summarize(total_movie = sum(movie_count), number_of_performers = n(), score = mean(mean_film_score))\n\nglimpse(top_actors)\n\nggplot(top_actors, aes(x = mean_film_score, fill = category)) +\n  geom_density(alpha = 0.6) +\n  labs(title = \"Density of Mean Film Scores by Gender\", x = \"Mean Film Score\", y = \"Density\") +\n  theme_minimal()\n  \nggplot(top_actors, aes(x = movie_count, y = mean_film_score, color = category)) +\n  geom_point(alpha = 0.5, size = 3) +\n  labs(title = \"Movie Count vs. Mean Film Score by Gender\", x = \"Movie Count\", y = \"Mean Film Score\", color = NULL) +  \n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5)) \n\ntop_directors &lt;- talent |&gt; \n  filter(category == \"director\") \n\ntop_directors |&gt; \n  arrange(age, desc(movie_count)) |&gt;\n  head(20)\n\nWitness jumps out at me here :\n\nTable: Films by Year and Film Score\n\n\nTitle\nYear\nFilm Score\n\n\n\n\nVertigo\n1958\n99.68\n\n\nThe Handmaiden\n2016\n99.20\n\n\nMatch Point\n2005\n97.93\n\n\nRoja\n1992\n92.96\n\n\nWitness\n1985\n92.05\n\n\nThe Wind\n1928\n91.02\n\n\nSpark: L.I.F.E.\n2023\n90.81\n\n\nA Story from Chikamatsu\n1954\n90.76\n\n\nTo Catch a Thief\n1955\n89.51\n\n\nVaalee\n1999\n89.06\n\n\n\nCast Lukas Haas as the villain.\n\n\n\n&gt; show me the code\n\n# Searching for all Romance Thrillers\nromance_thrillers &lt;- TITLE_BASICS |&gt;\n  filter(titleType == \"movie\") |&gt;  \n  filter(grepl(\"Romance\", genres) & grepl(\"Thriller\", genres)) |&gt;\n  inner_join(films_scores, by = \"tconst\") |&gt;\n  filter(film_score &gt; 77.46) |&gt;\n  select(primaryTitle.x, startYear.x, film_score) |&gt;\n  arrange(desc(film_score))\n  \n# This yields 19 films, lets investigate them\nhead(romance_thrillers, 19)\n\n# Has Witness been remade? \nwitness_films &lt;- TITLE_BASICS |&gt; \n  filter(titleType == \"movie\" & primaryTitle == \"Witness\" ) \n  \n# There is another Witness in the dataset, but it's an unrelated film from India\nhead(witness_films) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n–&gt;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n–&gt;\n\n\n\n\n\n\n\n\n\n\n–&gt;"
  },
  {
    "objectID": "mp02.html#staring-who-directed-by",
    "href": "mp02.html#staring-who-directed-by",
    "title": "IMDb and Me",
    "section": "Staring Who? Directed By?",
    "text": "Staring Who? Directed By?\nLet’s try to identify two romantic, nervy leads to star in our film.\nThe top 2 look like a great choice! Can you believe they’ve never worked together!\n\nTable: Actors and Actresses by Age and Movie Count\n\n\nPrimary Name\nCategory\nAge\nMovie Count\n\n\n\n\nScarlett Johansson\nActress\n40\n35\n\n\nJake Gyllenhaal\nActor\n44\n23\n\n\nChris Evans\nActor\n43\n20\n\n\nSeth Rogen\nActor\n42\n17\n\n\nChris Hemsworth\nActor\n41\n16\n\n\nEmma Stone\nActress\n36\n16\n\n\nNatalie Portman\nActress\n43\n15\n\n\nChris Pratt\nActor\n45\n15\n\n\nRajkummar Rao\nActor\n40\n15\n\n\nKirsten Dunst\nActress\n42\n14\n\n\n\nCan we identify a top woman director to helm our production?\n\nDirectors and Their Awards Count\n\n\nID\nName\nProfession\nAge\nAwards\n\n\n\n\nnm0000229\nSteven Spielberg\ndirector\n78\n28\n\n\nnm0001054\nJoel Coen\ndirector\n70\n15\n\n\nnm0000165\nRon Howard\ndirector\n70\n14\n\n\nnm0000318\nTim Burton\ndirector\n66\n13\n\n\nnm0000709\nRobert Zemeckis\ndirector\n72\n13\n\n\nnm0001392\nPeter Jackson\ndirector\n63\n12\n\n\nnm0005363\nGuy Ritchie\ndirector\n56\n11\n\n\nnm0000231\nOliver Stone\ndirector\n78\n10\n\n\nnm0868219\nGuillermo del Toro\ndirector\n60\n9\n\n\nnm0000116\nJames Cameron\ndirector\n70\n8\n\n\nnm0000600\nSam Raimi\ndirector\n65\n8\n\n\nnm0000881\nMichael Bay\ndirector\n59\n7\n\n\nnm0001675\nRobert Rodriguez\ndirector\n56\n7\n\n\nnm0080220\nSanjay Leela Bhansali\ndirector\n61\n7\n\n\nnm0570912\nAdam McKay\ndirector\n56\n7\n\n\nnm0000416\nTerry Gilliam\ndirector\n84\n6\n\n\nnm0000568\nFrank Oz\ndirector\n80\n6\n\n\nnm0000916\nPeter Berg\ndirector\n60\n6\n\n\nnm0001053\nEthan Coen\ndirector\n67\n6\n\n\nnm0094435\nBong Joon Ho\ndirector\n55\n6\n\n\n\n(…it goes on like this)\nOk, exaclty who are the women in our top directors table?\nTop Women Directors:\n\nTable: Top Women Directors by Movie Count\n\n\nPrimary Name\nCategory\nAge\nMovie Count\n\n\n\n\nLilly Wachowski\nDirector\n57\n5\n\n\nLana Wachowski\nDirector\n59\n5\n\n\nZoya Akhtar\nDirector\n52\n2\n\n\nJoan Chen\nDirector\n63\n1\n\n\nGail Mancuso\nDirector\n66\n1\n\n\nMary Elizabeth McGlynn\nDirector\n58\n1\n\n\nJessie Nelson\nDirector\nNA\n1\n\n\nMaria Schrader\nDirector\n59\n1\n\n\nReema Kagti\nDirector\nNA\n1\n\n\nOlivia Wilde\nDirector\n40\n1\n\n\n\nHm.\nIt’s arguably a bold choice to get the Wachowski’s to direct our project.\n…once we pick a film we’ll decide if they’re appropriate or not, but what is going on with the gender disparities in Hollywood?!?!\nBy my film_score metric, men are noticeably more represented than women.\nI believe this is a market inefficiency and we should seek to develop more women-centered entertainment…\n\n\n\n&gt; show the code\n\n\n# Filter on all films that meet my 77.46 film score threshold\ntop_movies &lt;- films_scores |&gt;\n  filter(film_score &gt; 77.46)\n\n# Find actors, actresses and directors and sum the films they've done that are strong\n# film_score scorers\ntalent_again &lt;- TITLE_PRINCIPALS |&gt;\n  filter(tconst %in% top_movies$tconst, category %in% c(\"actor\", \"actress\", \"director\")) |&gt;\n  inner_join(names_in_many_big_productions, by = \"nconst\") |&gt;\n  inner_join(films_scores, by = \"tconst\") |&gt;\n  group_by(nconst, primaryName, category, age) |&gt;\n  summarize(movie_count = n(), mean_film_score = mean(film_score, na.rm = TRUE)) |&gt;\n  arrange(desc(movie_count))\n\n# Look for younger performers\ntop_actors &lt;- talent_again |&gt;\n  filter(category %in% c(\"actor\", \"actress\"), age &gt;= 20 & age &lt;= 45 & movie_count &gt; 4) |&gt;\n  arrange(desc(mean_film_score))\n\n# Count their inclusions\nactors_summary &lt;- top_actors |&gt; \n  group_by(category) |&gt; \n  summarize(total_movie = sum(movie_count), number_of_performers = n(), score = mean(mean_film_score))\n\n# Plot top actors that are high film score participants\nggplot(top_actors, aes(x = mean_film_score, fill = category)) +\n  geom_density(alpha = 0.6) +\n  labs(title = \"Density of Mean Film Scores by Gender\", x = \"Mean Film Score\", y = \"Density\") +\n  theme_minimal()\n \n# Plot top actresses that are high film score participants\nggplot(top_actors, aes(x = movie_count, y = mean_film_score, color = category)) +\n  geom_point(alpha = 0.5, size = 3) +\n  labs(title = \"Movie Count vs. Mean Film Score by Gender\", x = \"Movie Count\", y = \"Mean Film Score\", color = NULL) +  \n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5)) \n\n# Identify directors\ntop_directors &lt;- talent |&gt; \n  filter(category == \"director\") \n  \n# Single out the top 20\ntop_directors |&gt; \n  arrange(age, desc(movie_count)) |&gt;\n  head(20)"
  },
  {
    "objectID": "mp02.html#witness-2024",
    "href": "mp02.html#witness-2024",
    "title": "IMDb and Me",
    "section": "Witness (2024)",
    "text": "Witness (2024)\nIn an attempt to cash in on the ongoing popularity of Thrillers mixed with the underexplored opportunity in Romance film productions, can we identify a Romantic Thriller to remake? Can we convince a studio to finance our project by resting on existing, tested IP?\nSearching for films identified as both Romance and Thriller and a fantastic candidate jumps off the screen:\n\nTable: Films by Year and Film Score\n\n\nTitle\nYear\nFilm Score\n\n\n\n\nVertigo\n1958\n99.68\n\n\nThe Handmaiden\n2016\n99.20\n\n\nMatch Point\n2005\n97.93\n\n\nRoja\n1992\n92.96\n\n\nWitness\n1985\n92.05\n\n\nThe Wind\n1928\n91.02\n\n\nSpark: L.I.F.E.\n2023\n90.81\n\n\nA Story from Chikamatsu\n1954\n90.76\n\n\nTo Catch a Thief\n1955\n89.51\n\n\nVaalee\n1999\n89.06\n\n\n\nWitness (1985)!\nWitness’ core themes of cultural clash, love, and justice are forever relevant. Exploring the tension between the modern world and an insular community like the Amish, especially in a world driven by technology and changing social norms, a Witness remake could resonate with contemporary audiences.\nOur new Witness can also offer new insights by exploring evolving dynamics between urban and rural life, highlighting current issues like surveillance, policing, or cultural identity.\nSince *Witness** continues to have a strong cult following, a remake could introduce the story to a younger generation, giving them a chance to experience its narrative through a modern lens.\nThe Wachowskis would be perfect directors for this film as the clash between the modern world and the isolated Amish offers rich potential for the Wachowskis’ thematic exploration of duality and identity. The original Witness garnered significant Oscar attention and a modern remake could finally position The Wachowskis for over-due awards-season recognition.\nJake Gyllenhaal and Scarlett Johansson would be perfect leads for a Witness remake due to their range and potential for chemistry. With Gyllenhaal’s intensity and emotional depth he would no doubt thrive in the role of John Book. Scarlett Johansson versatility and strong presence would bring nuance and vulnerability to Rachel. It’s strong pairing for sure.\nIn an appeal to fan service, we can re-cast Lukas Haas, he of the memorable child performance in the 1985 original, into the film’s villain…\nFrom the visionary directors who brought you The Matrix and Cloud Atlas…\nAnd starring Jake Gyllenhaal, the beloved star of Nightcrawler…\nAlongside Scarlett Johansson, Hollywood icon of action and drama…\nComes a reimagining of a timeless classic…\nWitness. A story of secrets, survival, and sacrifice.\nComing soon to a theater near you!\n\n\n\n&gt; show the code\n\n# Searching for all Romance Thrillers\nromance_thrillers &lt;- TITLE_BASICS |&gt;\n  filter(titleType == \"movie\") |&gt;  \n  filter(grepl(\"Romance\", genres) & grepl(\"Thriller\", genres)) |&gt;\n  inner_join(films_scores, by = \"tconst\") |&gt;\n  filter(film_score &gt; 77.46) |&gt;\n  select(primaryTitle.x, startYear.x, film_score) |&gt;\n  arrange(desc(film_score))\n  \n# This yields 19 films, lets investigate them\nhead(romance_thrillers, 19)\n\n# Has Witness been remade? \nwitness_films &lt;- TITLE_BASICS |&gt; \n  filter(titleType == \"movie\" & primaryTitle == \"Witness\" ) \n  \n# There is another Witness in the dataset, but it's an unrelated film from India\nhead(witness_films)"
  },
  {
    "objectID": "mp03.html",
    "href": "mp03.html",
    "title": "The Electoral College Dilemma: Tradition, Tension, and the Future of American Democracy",
    "section": "",
    "text": "by Jason Amey\nThe Electoral College is one of the most misunderstood components of the American political system. Rooted in the Constitutional principle of federalism, the Electoral College is designed to balance power by ensuring that both individual states and the overall population have a voice in electing the nation’s leader.\nThis approach emphasizes the importance of state sovereignty, reflecting the framers’ intent to respect the rights and influence of each state within a diverse and expansive union. This system requires presidential candidates to seek support across a wide geographic range, ensuring that the voices of smaller or less populous states are not dominated by larger population centers.\nRecently the Electoral College has become an increasingly contentious, particularly as modern elections have seen candidates win the presidency without winning the popular vote. This disconnect in recent years has raised questions about the system’s fairness and the extent to which it reflects the will of the people.\nFor many American voters, it remains unjust that a candidate who secures the majority of votes nationally can still lose the presidency. This reality has engendered disenfranchisement among voters who feel their voices are increasingly insignificant in choosing a President.\nA segment of this disenchantment stems from the difficulty in changing our constitutional system. Changing the Electoral College is a complex task, not only because it would require a constitutional amendment, but also because many constituencies currently benefit from this arrangement. States that hold a disproportionate influence under the Electoral College system are unlikely to support a departure from the Electoral College beacuse it would reduce their electoral power and political significance.\nAmending the Constitution demands broad consensus—a nearly impossible level of national agreement that is exceedingly rare in today’s polarized political climate. Thus, while many Americans express a desire to reform or eliminate the Electoral College, the practical and political barriers to doing so are aguably insurmountable.\nThe ongoing use of the Electoral College, despite its oft-misalignment with the popular vote, presents a significant challenge to the perceived responsiveness of elected leaders to the public’s democratic wishes. When candidates who do not enjoy the majority’s support are elevated to the presidency, it can strain the public’s trust in our political system. This tension between majority rule and the structure of the Electoral College poses serious questions for the future of American democracy, as it risks diminishing the public’s faith in the electoral process and the legitimacy of its political leaders.\n\nTo explore the dynamics of the Electoral College, a data analysis was conducted using electoral data from the MIT Election Data and Science Lab, which provides detailed voting records across U.S. House elections from 1976 to 2022.1 This dataset offers insights into historical voting patterns and party performance at the district level, essential for understanding shifts in electoral influence over time. This data was with congressional shapefiles from UCLA’s PoliSci Mapping Center2 and the U.S. Census Bureau’s TIGER/Line files.3 These resources enable a comprehensive analysis of the Electoral College system, highlighting shifts in population and the impact districting commands over electoral outcomes.\nThis project uses packages readr, dplyr, tidy, ggplot2, sf, stringr, statebins, scales,maps\n\n\n&gt; show the code for data preparation\n\nlibrary(readr)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(ggplot2)\nlibrary(sf)\nlibrary(stringr)\nlibrary(statebins)\nlibrary(scales)\nlibrary(maps)\n\n# Sourced data\nELECTION_DATA_HOUSE &lt;- read_csv(\"data/mp03/dataversefiles/1976-2022-house.csv\")\nELECTION_DATA_HOUSE &lt;- ELECTION_DATA_HOUSE |&gt; \n  filter(!is.na(party))\n\nELECTION_DATA_PRESIDENT &lt;- read_csv(\"data/mp03/dataversefiles/1976-2020-president.csv\")\nELECTION_DATA_PRESIDENT &lt;- ELECTION_DATA_PRESIDENT |&gt; \n  filter(!is.na(candidate) & !is.na(party_detailed))\n\n# Function to download shapefiles UCLA’s PoliSci Mapping Center, 95 to \n# 112 representsrelevant Congressional Sessions\ncongress_shapefiles_ucla &lt;- function(start = 95, end = 112) {\n  BASE_URL &lt;- \"https://cdmaps.polisci.ucla.edu/shp/districts\"\n  \n  if (!dir.exists(\"data/mp03/congress_shapefiles\")) {\n    dir.create(\"data/mp03/congress_shapefiles\", recursive = TRUE)\n  }\n  \n  for (congress in start:end) {\n    # Requires leading zeros\n    congress_str &lt;- sprintf(\"%03d\", congress)\n    file_url &lt;- paste0(BASE_URL, congress_str, \".zip\")\n    dest_file &lt;- paste0(\"data/mp03/congress_shapefiles/congress_\", congress_str, \"_shapefile.zip\")\n    \n     # Prevent re-downloading\n    if (!file.exists(dest_file)) {\n      tryCatch({\n        download.file(file_url, destfile = dest_file, mode = \"wb\")\n        message(\"Downloaded shapefile for Congress \", congress_str)\n      }, error = function(e) {\n        message(\"Failed to download for Congress \", congress_str, \": \", e)\n      })\n    } else {\n      message(\"File for Congress \", congress_str, \" already exists. Skipping download.\")\n    }\n  }\n}\n\n# Run function\ncongress_shapefiles_ucla()\n\n# Function to download shapefiles from the U.S. Census Bureau’s TIGER/Line Shapefiles \ncongress_shapefiles_census &lt;- function(start_year = 2013, end_year = 2023) {\n  BASE_URL &lt;- \"https://www2.census.gov/geo/tiger/TIGER\"\n  \n  # Create the download directory if it doesn’t exist\n  if (!dir.exists(\"data/mp03/census_congress_shapefiles\")) {\n    dir.create(\"data/census_congress_shapefiles\", recursive = TRUE)\n  }\n  \n  # Determine Congress numbers based on years\n  congress_numbers &lt;- seq(113, 113 + (end_year - start_year) / 2, by = 1)\n  years &lt;- seq(start_year, end_year, by = 2) \n\n  for (i in seq_along(years)) {\n    year &lt;- years[i]\n    congress &lt;- congress_numbers[i]\n    # Format as 'cd113', 'cd114', etc.\n    congress_str &lt;- sprintf(\"cd%d\", congress)  \n    file_url &lt;- paste0(BASE_URL, year, \"/CD/tl_\", year, \"_us_\", congress_str, \".zip\")\n    dest_file &lt;- paste0(\"data/mp03/census_congress_shapefiles/tl_\", year, \"_us_\", congress_str, \".zip\")\n    \n    #Prevent re-downloading\n    if (!file.exists(dest_file)) {\n      tryCatch({\n        download.file(file_url, destfile = dest_file, mode = \"wb\")\n        print(\"Downloaded shapefile for \", congress_str, \" (Year \", year, \")\")\n      }, error = function(e) {\n        print(\"Failed to download for \", congress_str, \" (Year \", year, \"): \", e)\n      })\n    } else {\n      message(\"File for \", congress_str, \" (Year \", year, \") already exists. Skipping download.\")\n    }\n  }\n}\n\n#Run function\ncongress_shapefiles_census()\n\n\n\nThe past 40 years have seen dramatic demographic and economic shifts in the United States, with the “Sunbelt” region experiencing significant population growth. Factors such as warm climates, a lower cost of living and growing job opportunities have all contributed to this population transformation. Cities like Phoenix, Dallas, Houston, and Atlanta have expanded rapidly, becoming economic powerhouses that attract internal migration.4 This trend has boosted the political influence of the Sunbelt states, particularly in presidential elections, as their share of the Electoral College votes has grown in proportion to their population increases.\nIn contrast, the Northeast and Rust Belt states have faced steady population declines. The Rust Belt continues to grapple with the economic fallout from the decline in manufacturing5. The Northeast, once a densely populated region driving much of the nation’s political power, has also seen a slower growth rate due to higher costs of living and an unwelcome, cooler climate. States like New York, Ohio, Pennsylvania, and Michigan have all lost congressional seats6—and, by extension, Electoral College votes—in the face of a southward shift in national demographics.\nThe impact on the Electoral College reflects these changes, as the Sunbelt’s increasing population has translated into greater political clout. Every ten years, the U.S. Census triggers a reapportionment of congressional seats, redistributing the 435 seats in the House of Representatives—and thus Electoral College votes—based on population changes.\nThis dynamic remains topical as commentary last-week immediately following Donald Trump’s significant electoral victory led a popular Conservative commentator to remark on the conintued diminished influence of both the Rust Belt and the American North East, and its traditional bases of power among the Democratic Party7:\n\n\nWhat are the states to lose the most Electoral College votes since 1976?\n\nElectoral Vote Losses By State (1976 vs. 2022) \n\n\nState\n1976\n2022\nChange\n\n\n\n\nNew York\n41\n28\n-13\n\n\nOhio\n25\n17\n-8\n\n\nPennsylvania\n27\n19\n-8\n\n\nIllinois\n26\n19\n-7\n\n\nMichigan\n21\n15\n-6\n\n\n\n  What are the states to gain the most Electoral College votes since 1976?\n\nElectoral Vote Growth By State (1976 vs. 2022) \n\n\nState\n1976\n2022\nChange\n\n\n\n\nTexas\n26\n40\n14\n\n\nFlorida\n17\n30\n13\n\n\nCalifornia\n45\n54\n9\n\n\nArizona\n6\n11\n5\n\n\nGeorgia\n12\n16\n4\n\n\n\n  Despite the Sunbelt’s rising population and the corresponding increase in Electoral College votes, a paradox exists: many of these rapidly growing Sunbelt states lack the political clout associated with “swing states.”8\nIn the Electoral College, political influence often hinges not only on a state’s population, but on its competitiveness in presidential elections. States like Texas and Florida, though gaining in electoral votes, are often reliably partisan (both are heavily Republican), which can diminish the attention they receive compared to smaller yet more unpredictable states like Pennsylvania or Wisconsin.\nThis “swing state” phenomenon means that candidates prioritize states with narrower margins, where votes are likelier to tip the election, giving smaller, competitive states a unique power in the electoral process that even populous states in the Sunbelt do not always share.\n\n\n&gt;show the code\n\n\n# Get data for 1976 and 2022\nelectoral_votes_76_22 &lt;- ELECTION_DATA_HOUSE |&gt; \n  filter(year == 1976 | year == 2022 ) |&gt;\n  group_by(year, state) |&gt;\n  summarize(votes = n_distinct(district) + 2) |&gt; \n  pivot_wider(names_from = year, values_from = votes) |&gt;\n  mutate(change = `2022` - `1976`)\n\n# View states that have lost the most seats\nvote_data &lt;- electoral_votes_76_22 |&gt; \n  arrange(change)\n  \n# View states that have gained the most seats\nelectoral_votes_76_22 |&gt; \n  arrange(desc(change))\n  \n# Prepare map data and convert state names to match your data\nus_states &lt;- map_data(\"state\") |&gt;\n  mutate(region = toupper(region))\n\n# Join map data with your data on state names\nmap_data_combined &lt;- us_states |&gt;\n  left_join(vote_data, by = c(\"region\" = \"state\"))\n\n# Plot the heatmap\nggplot(map_data_combined, aes(long, lat, group = group, fill = change)) +\n  geom_polygon(color = \"white\") + \n  scale_fill_gradient2(low = \"blue\", mid = \"gray\", high = \"red\", midpoint = 0, \n                       name = \"Change in Seats\") +\n  coord_fixed(1.3) +\n  labs(title = \"Change in Congressional Seats (1976 to 2022)\", \n       subtitle = \"Positive values indicate gain in seats; negative values indicate loss\") +\n  theme_minimal() +\n  theme(\n    axis.text = element_blank(),\n    axis.title = element_blank(),   \n    axis.ticks = element_blank(),\n    panel.grid = element_blank(),\n    panel.background = element_blank()\n  )\n\n\n\n\nFusion voting, also known as cross-endorsement, is an electoral practice that allows a candidate to appear on the ballot under multiple party lines, thereby consolidating votes from different political bases. This approach enables third parties to endorse a major-party candidate, allowing voters to support a candidate’s platform through the values or policies associated with a smaller, often more ideologically-focused party. In practice, fusion voting can increase a candidate’s visibility while empowering smaller parties to influence major-party agendas.9\nIn New York City, fusion voting originally began in the 1930’s as a strategy to challenge Tammany Hall. Since then, many fusion-enabled parties have become important fixtures in New York area politics. For one, The Working Families Party has frequently endorsed progressive Democratic candidates while giving voters an alternative way to support candidates who align with specific labor and social equity issues. Likewise, The Conservative Party line gives voters a direct voice to amplify their commitment to limited government and social conservatism. All told, the fusion approach has been unique in New York City’s local elections, shaping policy conversations and reinforcing the presence of alternative political values within a largely two-party system.10\n\nFusion Findings for NY Elections\n\n\n\n\n\n\n\n\n\n\n\n\nYear\nState\nDistrict\nWinner\nParty\nLoser\nParty\nHighest %\n\n\n\n\n1980\nNY\n3\nGregory W Carman\nConservative, Republican\nJerome A Ambro Jr\nDemocrat, Right To Life\n0.429\n\n\n1980\nNY\n6\nJohn LeBoutillier\nConservative, Republican, Right To Life\nLester L Wolff\nDemocrat, Liberal\n0.437\n\n\n1986\nNY\n27\nGeorge C Wortley\nConservative, Republican\nRosemary S Pooler\nDemocrat, Effective Congress\n0.483\n\n\n1994\nNY\n1\nMichael P Forbes\nConservative, Republican, Right To Life\nGeorge J Hochbrueckner\nDemocrat, Long Island First\n0.428\n\n\n1996\nNY\n1\nMichael P Forbes\nConservative, Independence, Republican, Right To Life\nNora L Bredes\nDemocrat, Save Medicare\n0.398\n\n\n1996\nNY\n30\nJack Quinn\nConservative, Freedom, Independence, Republican\nFrancis J Pordum\nDemocrat, Protect Seniors\n0.405\n\n\n2006\nNY\n25\nJames T Walsh\nConservative, Independence, Republican\nDan Maffei\nDemocrat, Working Families\n0.443\n\n\n2006\nNY\n29\nJohn R “Randy” Kuhl Jr\nConservative, Independence, Republican\nEric J Massa\nDemocrat, Working Families\n0.436\n\n\n2012\nNY\n27\nChris Collins\nConservative, Republican\nKathleen C Hochul\nDemocrat, Working Families\n0.425\n\n\n2018\nNY\n1\nLee M Zeldin\nConservative, Independence, Reform, Republican\nPerry Gershon\nDemocrat, Working Families\n0.460\n\n\n2018\nNY\n24\nJohn M Katko\nConservative, Independence, Reform, Republican\nDana Balter\nDemocrat, Women’s Equality, Working Families\n0.445\n\n\n2018\nNY\n27\nChris Collins\nConservative, Independence, Republican\nNathan D McMurray\nDemocrat, Women’s Equality, Working Families\n0.449\n\n\n2022\nNY\n4\nAnthony P D’Esposito\nRepublican, Conservative\nLaura A Gillen\nDemocrat\n0.470\n\n\n2022\nNY\n17\nMichael V Lawler\nRepublican, Conservative\nSean Patrick Maloney\nDemocrat, Working Families\n0.458\n\n\n2022\nNY\n22\nBrandon M Williams\nRepublican, Conservative\nFrancis Conole\nDemocrat\n0.485\n\n\n\n\n\n&gt; show the code\n\n\n# Filter House election data for fusion elections, calculate percentages and create unique ID\nfusion_elections &lt;- ELECTION_DATA_HOUSE |&gt; \n  filter(fusion_ticket == TRUE) |&gt; \n  mutate(percentage = candidatevotes / totalvotes, race_id = paste0(state_po, year, district))\n\n# Calculate total winnine percentage\nwinner_percentage &lt;- fusion_elections |&gt;\n  group_by(race_id, candidate) |&gt;\n  summarize(total_vote = sum(percentage)) |&gt;\n  ungroup()\n\n# Count races for a given ID and filter out only competitve races\nwinner_percentage &lt;- winner_percentage |&gt;\n  add_count(race_id, name = \"race_count\") |&gt;  \n  filter(race_count &gt; 1) |&gt;  \n  select(-race_count)\n  \n# Create boolean for variable name `winner`  \nwinners_added &lt;- winner_percentage |&gt; \n  group_by(race_id) |&gt; \n  mutate(winner = (total_vote == max(total_vote))) |&gt;\n  ungroup()\n\n# Join datasets\nfusion_elections &lt;- fusion_elections |&gt; \n  inner_join(winners_added, by=c(\"race_id\", \"candidate\")) |&gt;\n  select(year, state, state_po, district, candidate, party, percentage, race_id, total_vote, winner)\n\n# Identify individuals who recieved the highest single percentage, but lost race\nfusion_election_IDs &lt;- fusion_elections |&gt; \n  group_by(race_id) |&gt; \n  arrange(desc(percentage)) |&gt; \n  slice(1) |&gt;\n  filter(winner == FALSE) |&gt;\n  pull(race_id)\n\n# Recreate dataset with just unique elections with fusion winners (losers)\nfinal_data &lt;- fusion_elections |&gt; \n  filter(race_id %in% fusion_election_IDs & !is.na(party)) \n\n# Identify all the candidates and their parties in these unique fusion instances\nresult &lt;- final_data |&gt;\n  group_by(year, state, district) |&gt;\n  summarise(\n    winning_candidate = candidate[winner == TRUE],\n    winning_party = paste(unique(party[winner == TRUE]), collapse = \", \"),\n    losing_candidate = candidate[which.max((!winner) * percentage)],\n    losing_party = paste(unique(party[winner == FALSE]), collapse = \", \"),\n    highest_losing_percentage = max(percentage[winner == FALSE], na.rm = TRUE),\n    .groups = 'drop'\n  )\n\n# Print output for table formatting\nprint(result, n = 100)\n\n\n\n\n\nThese scores represent the standardized differences in voter support between Democratic and Republican candidates in House versus Presidential elections for each election year. This examination represents whether in a given state and year a party’s House candidates received a higher or lower percentage of votes than the party’s Presidential candidate, indicating voter preferences that may diverge between congressional and national races. The standardized score highlights years with especially strong or weak alignment between House and Presidential support. Positive scores indicate years when House candidates outperformed Presidential candidates, while negative scores suggest the opposite.\n\n\n\nThe Democratic Party shows substantial positive discrepancies in years like 1984, 1980, and 1992, suggesting that Democratic House candidates outperformed the Democratic Presidential candidate by a notable margin in these years. 1980 and 1984 reflect the transformative political strength of Ronald Reagan, arguably one of the most consequential Presidential figures of the last 50 years.11 In 1992, a strong third-party showing by Ross Perot may have influenced voting patterns, with many voters possibly splitting their votes between Perot and their local Democratic House Representatives.\n\n\n\nIn 1988, 1984, and 1976, Republicans have significant negative scores, suggesting that in these years, Republican House candidates underperformed relative to the Presidential candidate. This might indicate that the Presidential candidate was particularly appealing, drawing votes that House candidates could not capture as effectively.\nThis trend suggests that in certain election years, voters may have been inclined toward a Republican President but were more mixed in their support for Republicans in the House, as was the case in 1988 and 1984 years when the GOP ran strong candidates atop their tickets. The 1976 results are likely a reflection of broader voter disenchantment with the Republican Party post-Watergate in the ensuing years and the need to re-build their national stature among voters.\n\n\n\nYears like 2004 (Democrat), 2000 (Republican), and 2012 (Republican) have scores close to zero, indicating minimal discrepancies between the public’s preference for President and the House within those years. In such years, voter alignment between Presidential and House races was more consistent, reflecting lower levels of split-ticket voting or greater alignment in perceived candidate appeal and party policies across both levels. These years most likely signaled the rise of growing polarization of the American electorate as seen in recent elections.\n\n\n\nIn recent years, such as 2008, 2016, and 2020, both parties show relatively low scores, suggesting less discrepancy in voter preferences between the House and Presidential candidates. This trend reflects growing political polarization, with fewer voters splitting their votes across parties. The increased partisan consistency among voters has led to a decline in split-ticket voting, a phenomenon that has been well-documented in studies on electoral polarization.12\n\n\n&gt; show the code\n\n\n# Remove 3rd party candidates from presidential data\nelection_president_r_d &lt;- ELECTION_DATA_PRESIDENT |&gt; \n  filter(party_detailed == \"REPUBLICAN\" | party_detailed == \"DEMOCRAT\" )\n  \n# Calculate total votes a presidential candidate received, total vote in race and create unique ID\nsum_president_votes_r_d &lt;- election_president_r_d |&gt;\n  group_by(year, state, state_po, party_detailed, candidate) |&gt;\n  summarize(\n    candidate_votes = sum(candidatevotes, na.rm = TRUE),\n    total_votes = max(totalvotes, na.rm = TRUE)  \n  ) |&gt;\n  ungroup() |&gt;\n  mutate(id = paste(year, state_po, party_detailed, sep = \"_\"), pres_percentage = candidate_votes / total_votes) |&gt;\n  rename(\n        pres_candidate_votes = candidate_votes, \n        pres_total_votes = total_votes\n        )\n\n# Vector for presidential election years\nPRESIDENTIAL_YEARS &lt;- seq(1976, 2020, by = 4)\n\n# Isolate house races that occured in presidential years and count votes for each state\ntotal_votes_per_state &lt;- ELECTION_DATA_HOUSE |&gt;\n  filter(year %in% PRESIDENTIAL_YEARS & (party == \"REPUBLICAN\" | party == \"DEMOCRAT\")) |&gt;\n  group_by(year, state, state_po) |&gt;\n  summarize(total_votes = unique(totalvotes, na.rm = TRUE) |&gt; sum()) |&gt;\n  ungroup()\n\n# Sum candidate votes, join total_votes_per_state and calculate percentage from total votes\nsum_house_votes_r_d &lt;- ELECTION_DATA_HOUSE |&gt;\n  filter(party %in% c(\"DEMOCRAT\", \"REPUBLICAN\") & year %in% PRESIDENTIAL_YEARS) |&gt;\n  group_by(year, state, state_po, party) |&gt;\n  summarize(candidate_votes = sum(candidatevotes, na.rm = TRUE)) |&gt;\n  ungroup() |&gt;\n  left_join(total_votes_per_state, by = c(\"year\", \"state\", \"state_po\")) |&gt;\n  mutate(\n    id = paste(year, state_po, party, sep = \"_\"), \n    house_percentage = candidate_votes / total_votes\n  ) |&gt;\n  rename(\n    house_candidate_votes = candidate_votes,\n    house_total_votes = total_votes\n  ) |&gt;\n  select(id, house_candidate_votes, house_total_votes, house_percentage)\n\n# Calculate differences from house races percentages and presidential races \nstate_vote_counts &lt;- sum_president_votes_r_d |&gt;\n  left_join(sum_house_votes_r_d, by = \"id\") |&gt;\n  mutate(dif = house_percentage - pres_percentage)\n\n# Group these differences by state\nstate_vote_diff_state_score &lt;- state_vote_counts |&gt; \n  group_by(state, party_detailed) |&gt; \n  summarize(state_dif = mean(dif, na.rm = TRUE))\n\n# Calculate differences by party\nstate_vote_diff_pres_house &lt;- state_vote_counts |&gt; \n  group_by(year, party_detailed) |&gt; \n  summarize(avg_dif = mean(dif, na.rm = TRUE))\n\n# Generate standardize numbers for comparisons\nSD &lt;- sd(state_vote_diff_pres_house$avg_dif)\nMEAN &lt;- mean(state_vote_diff_pres_house$avg_dif)\n\n# Create a score metric\nstate_vote_diff_total_score &lt;- state_vote_diff_pres_house |&gt; \n  mutate(score = (avg_dif - MEAN) / SD) |&gt; \n  arrange(desc(score))\n\n\n# Prepare data for plot\ndata &lt;- state_vote_diff_total_score |&gt;\n  select(Year = year, Party = party_detailed, Score = score) |&gt;\n  mutate(\n    Party = ifelse(Party == \"DEMOCRAT\", \"Democrat\", \"Republican\")\n  )\n\n# Chart differences in House vote vs. Presidental vote from 1976 - 2020\nggplot(data, aes(x = factor(Year), y = Score, fill = Party)) +\n  geom_bar(stat = \"identity\", position = \"dodge\", width = 0.7) +\n  scale_fill_manual(values = c(\"Democrat\" = \"blue\", \"Republican\" = \"red\")) +\n  labs(\n    title = \"Party Score by Year (1976 - 2020)\",\n    x = \"Year\",\n    y = \"Score\",\n    fill = \"Party\"\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    legend.position = \"top\"\n  )\n\n \n\n\n\n\nWhat follows are the re-adjustment of our data and inclusion of shapefiles to map out conclusions about our electoral data.\n\n\n&gt; show code for .shp files\n\n# Identify main directory\nDIRECTORY &lt;- paste(getwd(),\"data\", sep=\"/\")\n\n# Create function for extracting files from .zip files\nshp_from_zip &lt;- function(file_name, directory = DIRECTORY){\n  dir &lt;- paste(directory, file_name, sep=\"/\")\n  td &lt;- tempdir(); \n  zip_contents &lt;- unzip(dir, \n                        exdir = td)\n  fname_shp &lt;- zip_contents[grepl(\"shp$\", zip_contents)]\n  return(read_sf(fname_shp))\n}\n\n# Test function\nfile &lt;- shp_from_zip(\"/mp03/congress_shapefiles/congress_095_shapefile.zip\")\n\n\n\n\nHere is the map for the fateful 2000 Presidential Election, the election that re-centered the Electoral College back into the national spotlight.\n\n\n\n&gt; show the code\n\n#### CHLOROPLETH FOR 2000 ELECTION ####\n\n# Calculate winner for each state for 2000 election and create winning_party field\npres_vote_2000 &lt;- ELECTION_DATA_PRESIDENT |&gt;\n  filter(year == 2000) |&gt;                             \n  group_by(state, candidate) |&gt;                       \n  summarise(total_votes = sum(candidatevotes, na.rm = TRUE)) |&gt;  \n  arrange(state, desc(total_votes)) |&gt;                 \n  slice_max(total_votes, n = 1, with_ties = FALSE) |&gt;\n  mutate(winning_party = ifelse(candidate == \"GORE, AL\", \"D\", \"R\"))\n\n# Load shapefile from 106th Congress - relevant for 2000 election\n&lt;!-- pres_shp_2000 &lt;- shp_from_zip(\"/mp03/congress_shapefiles/congress_106_shapefile.zip\") --&gt;\n\n\n# Load .shp file for congressional districts for 2000 \npres_shp_2000 &lt;- read_sf(\"data/mp03/congress_shapefiles/districtShapes/districts105.shp\")\n\n# Make sure STATENAME is clean and able to join\npres_shp_2000 &lt;- pres_shp_2000 |&gt;\n  mutate(STATENAME = str_to_upper(str_trim(STATENAME)))\n\n# Make sure state is clean and able to join\npres_vote_2000 &lt;- pres_vote_2000 |&gt;\n  mutate(state = str_to_upper(str_trim(state)))\n\n# Join data\npres_map_vote_2000_data &lt;- pres_shp_2000 |&gt;\n  left_join(pres_vote_2000, by = c(\"STATENAME\" = \"state\"))\n\n# Make geometries valid\npres_map_vote_2000_data_g &lt;- pres_map_vote_2000_data |&gt;\n  mutate(geometry = st_make_valid(geometry))\n\n# Create state boundaries\nstate_boundaries &lt;- pres_map_vote_2000_data_g |&gt;\n  group_by(STATENAME, winning_party) |&gt;\n  summarise(\n    geometry = st_union(geometry),\n    total_votes = sum(total_votes, na.rm = TRUE)\n  ) |&gt;\n  ungroup()\n\n# Find electoral college vote totals\nelectoral_votes_00 &lt;- ELECTION_DATA_HOUSE |&gt; \n  filter(year == 2000) |&gt;\n  group_by(year, state) |&gt;\n  summarize(votes = n_distinct(district) + 2) |&gt; \n  pivot_wider(names_from = year, values_from = votes)\n\n# Join electoral college votes\nstate_boundaries  &lt;-  state_boundaries |&gt;\n  left_join(electoral_votes_00, by = c(\"STATENAME\" = \"state\"))\n\n# Handle DC's NA\nstate_boundaries$`2000`[state_boundaries$STATENAME == \"DISTRICT OF COLUMBIA\" & is.na(state_boundaries$`2000`)] &lt;- 2\n \n# Remove NA values\ncleaned_data &lt;- state_boundaries |&gt;\n  filter(!is.na(geometry), !is.na(winning_party))\n\n# Define dc_location and assign geometry if needed\ndc_location &lt;- state_boundaries |&gt;\n  filter(STATENAME == \"DISTRICT OF COLUMBIA\")\n\n# Check if geometry exists and is not empty\nif (nrow(dc_location) == 0 || st_is_empty(dc_location$geometry)) {\n  # Manually assign coordinates if geometry is missing or empty\n  dc_location &lt;- st_sf(\n    STATENAME = \"DISTRICT OF COLUMBIA\",\n    winning_party = \"D\",\n    geometry = st_sfc(st_point(c(-77.0369, 38.9072)), crs = st_crs(state_boundaries))\n  )\n} else {\n  # Calculate centroid if geometry is available\n  dc_location &lt;- st_centroid(dc_location)\n}\n\n# Calculate centroids using st_point_on_surface to ensure within geometry\nstate_centroids &lt;- state_boundaries |&gt;\n  st_point_on_surface()\n\n# Ensure all layers have the same CRS\nstate_boundaries &lt;- st_transform(state_boundaries, crs = st_crs(pres_shp_2000))\nstate_centroids &lt;- st_transform(state_centroids, crs = st_crs(state_boundaries))\ndc_location &lt;- st_transform(dc_location, crs = st_crs(state_boundaries))\n\n# Plot the data\nggplot() +\n  geom_sf(data = cleaned_data, aes(fill = winning_party), color = NA) +\n  geom_sf_text(data = state_centroids, aes(label = `2000`), size = 3, color = \"black\") +\n  geom_sf(data = dc_location, shape = 8, size = 5, color = \"gold\") +  # Overlay star for DC\n  scale_fill_manual(values = c(\"D\" =  alpha(\"blue\", .7), \"R\" =  alpha(\"red\", .7))) + \n  coord_sf(xlim = c(-130, -60), ylim = c(24, 50)) +\n  labs(fill = \"Winning Party\") +\n  theme_minimal() +\n  theme(\n    legend.position = \"bottom\",\n    panel.background = element_blank(),    \n    axis.text = element_blank(),           \n    axis.ticks = element_blank(),\n    axis.title = element_blank(), \n    panel.grid.major = element_blank(),    \n    panel.grid.minor = element_blank()     \n  )\n\n#### FACETED HISTORY OF RECENT ELECTORAL COLLEGE COUNTS ####\n\n#### DOES NOT RENDER. CRASHES COMPUTER. ITS NOT IN PROJECT :-( ####\n\n# Clean up all gemoetries\ncleaned_data &lt;- pres_shp_2000 |&gt;\n  mutate(geometry = st_make_valid(geometry)) |&gt;\n  group_by(STATENAME) |&gt;\n  summarize(geometry = st_union(geometry), .groups = \"drop\")\n\n# Union geometries into states\nstates_shapes_2000 &lt;- cleaned_data |&gt;\n  select(STATENAME,geometry)|&gt;\n  group_by(STATENAME)|&gt;\n  summarize(geometry = st_union(geometry))|&gt;\n  filter(!is.na(geometry))\n\n# Cast geometries into a polygon\nus_states_sf &lt;- states_shapes_2000 |&gt;\n  filter(!is.na(geometry)) |&gt;\n  st_make_valid() |&gt; \n  st_cast(\"MULTIPOLYGON\") \n\n# Group by year and state and identify entry with most votes\npresidential_winners_by_state &lt;- ELECTION_DATA_PRESIDENT |&gt;\n  select(year, state, candidatevotes, candidate, party_simplified) |&gt;\n  group_by(year, state) |&gt;\n  slice_max(candidatevotes)\n\n# Join data\npresidentials_winners_combined_sf &lt;- presidential_winners_by_state |&gt;\n  select(year, state, party_simplified) |&gt;\n  left_join(us_states_sf|&gt;\n  select(STATENAME, geometry) |&gt;\n  mutate(STATENAME=toupper(STATENAME)),by=c(\"state\"=\"STATENAME\"))\n\n# Reduced Geometries\npresidentials_winners_combined_sf_t &lt;- presidentials_winners_combined_sf %&gt;%\n  mutate(geometry = st_simplify(geometry, dTolerance = 0.05))\n\n# Try without DC \npresidentials_winners_combined_sf_t &lt;- presidentials_winners_combined_sf_t |&gt;\n  filter(state != \"DISTRICT OF COLUMBIA\")\n\n# Plot Data (doesn't work)\nggplot(presidentials_winners_combined_sf_t |&gt; filter(year %in% c(1976, 1980))) +\n  geom_sf(aes(geometry = geometry, fill = party_simplified), color = \"white\") +\n  scale_fill_manual(values = c(\"DEMOCRAT\" = \"blue\", \"REPUBLICAN\" = \"red\")) +\n  coord_sf(xlim = c(-130, -60), ylim = c(24, 50)) +\n  labs(fill = \"Winning Party\") +\n  theme_minimal() +\n  theme(legend.position = \"bottom\") +\n  facet_wrap(~year)\nprint(\"ending\")\n\n\n\n\nThe Electoral College has long been debated for its undemocratic nature as it can allow a candidate to win the presidency without securing the popular vote. In doing so, the Electoral College effectively amplifies the influence of smaller or swing states over larger, non-competitive states. This occurs due to the State-Wide Winner-Take-All method, where the candidate who wins the majority of votes in a state receives all of that state’s electoral votes, making individual votes in less competitive states less influential.\nBut states are not compelled to use the State-Wide Winner-Take-All method as the United States Constitution allows states to decide for themselves how they allocate their electoral votes.\nWhat follows is a brief overview of the different electoral vote allocation strategies and their political implications…\nState-Wide Winner-Take-All:\nCurrently used by most states, this approach awards all electoral votes to the candidate with the most votes in a state. While it simplifies outcomes, it can marginalize voters in states where one party has a strong majority, as votes for the minority party have no impact on the Electoral College outcome. This strategy focuses campaign efforts on swing states, leaving “safe” states largely ignored.\nDistrict-Wide Winner-Take-All + State-Wide “At Large” Votes:\nThis approach allocates one electoral vote per congressional district, awarded to the candidate who wins the district, with two additional votes (representing the Senate seats) awarded to the statewide winner. Adopted by Maine and Nebraska, it reflects more local preferences but may amplify the impact of gerrymandered districts, which can skew results within a state.\nState-Wide Proportional:\nIn this model, electoral votes are allocated proportionally based on the statewide vote. This approach provides a more representative outcome for each state, as candidates receive electoral votes in line with their actual support.\nNational Proportional:\nHere, electoral votes are allocated based on the candidates’ national popular vote percentages. This model reflects the popular vote while maintaining the structure of the Electoral College.\n\n\n\nThe 2000 and 2016 elections offer compelling cases for examining competing methods of distributing electoral votes. In both instances, the Electoral College outcome diverged from the popular vote, with the presidential candidates who secured the majority of electoral votes not winning the national popular vote. These elections highlight the potential discrepancies within the Electoral College system and can shed light on whether alternative approaches might better align electoral outcomes with the popular will.\nAnalyzing these elections arguably offers the best insight into how different allocation methods could impact future presidential races and the broader democratic process.\n\n\n\nThe 2000 presidential election served as a stark reminder of the Electoral College’s pivotal role in determining the presidency, a mechanism many Americans were unfamiliar with until then. The race between George W. Bush and Al Gore hinged on a razor-thin vote margin in Florida, leading to a weeks-long recount and intense media scrutiny of obscure ballot-counting procedures introducing the country to the infamous “hanging chad.”\nUltimately the Supreme Court intervened in the recount, issuing a decision in Bush v. Gore that halted the Florida recount and awarded the state’s electoral votes to Bush. In a break from jurisprudence tradition, the Court explicitly declared that its ruling was intended solely for this case and was not meant to set legal precedent.\nWhile this contentious election spurred calls to reform or abolish the Electoral College no significant changes materialized, and the system remained unchanged.\n\n\n\n\nelectoral vote: 271\n\n\npopular vote: 50,456,002\n\n\npercentage: 47.9%\n\n\n\n\n\nelectoral vote: 266\n\n\npopular vote: 50,999,897\n\n\npercentage: 48.4%\n\n\n\n How would the election of 2000 played out under differing strategies of allocating electoral votes? \n\n  \n\n\n\nThe 2016 election is regarded as one of the most consequential in recent memory. Its impact on American politics and society is still felt today. Widely expected to end in an easy victory for Hillary Clinton, the election shocked political experts and the nation at large when Donald Trump defied predictions and won.\nTrump’s unconventional, “gonzo” approach to politics upended traditional campaign norms and is seen as ushering in a new brand of political conservatism—one that marked a significant departure from the policies and style of traditional, staid Republican politics. This shift has shaped the direction of the Republican Party and redefined the political landscape, solidifying the 2016 election as an undeniably transformative moment in U.S. History.\nDonald Trump’s confrontational and unorthodox style as president only intensified public scrutiny of the Electoral College as he had won in 2016 despite losing the popular vote. His tumultuous administration brought scrutiny upon the U.S. Constitution and renewed calls for reform or even abolition of the Electoral College.\nHowever, despite this heightened debate surrounding the Trump Presidency, there was no meaningful progress toward changing the Electoral College. Consequently, the Electoral College remains unchanged even as public criticism reached new heights during the Trump Aministration.\n\n\n\n\nelectoral vote: 304\n\n\npopular vote: 62,984,828\n\n\npercentage: 46.1%\n\n\n\n\n\nelectoral vote: 227\n\n\npopular vote: 65,853,514\n\n\npercentage: 48.2%\n\n\n\n How would the election of 2016 played out under differing strategies of allocating electoral votes? \n   \n\n\n&gt; show the code\n\n#### STATE WIDE WINNER TAKE ALL ####\n\n# Create popular vote tabulations\npopular_vote_summary &lt;- ELECTION_DATA_PRESIDENT |&gt;\n  group_by(year, candidate) |&gt;\n  summarise(\n    popular_vote_count = sum(candidatevotes, na.rm = TRUE),           \n    total_votes_year = sum(totalvotes, na.rm = TRUE)                 \n  ) |&gt;\n  ungroup() |&gt;\n  mutate(\n    popular_vote_percentage = (popular_vote_count / total_votes_year) * 100   \n  ) |&gt;\n  select(year, candidate, popular_vote_count, popular_vote_percentage, total_votes_year) |&gt;\n  filter(popular_vote_percentage &gt; 4.9) |&gt;\n  arrange(year, desc(popular_vote_count))\n\n# Create electoral vote counts for each state in each presidential election\nelectoral_vote_counts &lt;- ELECTION_DATA_HOUSE |&gt;\n  filter(year %in% seq(1976, 2020, by = 4)) |&gt; \n  group_by(year, state) |&gt;\n  summarize(votes = n_distinct(district) + 2, .groups = \"drop\") \n\n# Create vector of years\nyears &lt;- unique(electoral_vote_counts$year)\n\n# Ensure Washington DC has 3 votes for each year\nelectoral_vote_counts &lt;- electoral_vote_counts |&gt;\n  bind_rows(\n    tibble(\n      year = years[!years %in% electoral_vote_counts$year[electoral_vote_counts$state == \"DISTRICT OF COLUMBIA\"]],\n      state = \"DISTRICT OF COLUMBIA\",\n      votes = 3\n    )\n  ) |&gt;\n  mutate(votes = ifelse(state == \"DISTRICT OF COLUMBIA\", 3, votes)) |&gt;\n  arrange(year, state)\n\n# Identify total votes, winning candidate and winning party\nstate_winner_take_all &lt;- ELECTION_DATA_PRESIDENT |&gt;  # \n  group_by(year, state) |&gt;             \n  filter(!is.na(candidate)) |&gt;        \n  summarise(\n    total_votes = sum(candidatevotes, na.rm = TRUE),\n    winner_candidate = candidate[which.max(candidatevotes)],\n    winner_party = party_detailed[which.max(candidatevotes)],\n    .groups = \"drop\"\n  )\n\n# Join the electoral vote counts to the state winner data\nstate_winner_with_votes &lt;- state_winner_take_all |&gt;\n  left_join(electoral_vote_counts, by = c(\"year\", \"state\"))\n\n# Handle Washington DC \nstate_winner_with_votes &lt;- state_winner_with_votes |&gt;\n  mutate(\n    state_abbr = ifelse(\n      state == \"District Of Columbia\", \"DC\",  \n      state.abb[match(state, state.name)]     \n    )\n  )\n\n# Function to Title Case and reformat names\nreformat_candidate_name &lt;- function(winner_candidate) {\n  name_parts &lt;- str_split(winner_candidate, \",\\\\s*\")[[1]]\n  formatted_name &lt;- str_to_title(paste(name_parts[2], name_parts[1]))\n  return(formatted_name)\n}\n\n# Reformat names\nstate_winner_with_votes &lt;- state_winner_with_votes |&gt;\n  mutate(\n    proper_name = sapply(winner_candidate, reformat_candidate_name), \n    winner_party = str_replace(winner_party, \"DEMOCRATIC\", \"DEMOCRAT\")\n    )\n\n# Re-do state abbreviations\nstate_winner_with_votes &lt;- state_winner_with_votes |&gt;\n  mutate(\n    state_cleaned = str_trim(str_to_title(state)), \n    state_abbr = ifelse(\n      state_cleaned == \"District Of Columbia\", \"DC\",  \n      state.abb[match(state_cleaned, state.name)]\n    )\n  ) |&gt;\n  select(-state_cleaned)  \n\n \n# Summarize electoral vote totals\ncalculate_ec_vote_totals &lt;- function(electoral_college_data, election_year) {\n  # Filter for the specific election year to avoid aggregating across years\n  df_year_requested &lt;- electoral_college_data |&gt;\n    filter(year == election_year)\n\n# Summarize total popular and electoral votes by candidate's proper name and party\nvote_summary &lt;- df_year_requested |&gt;\n  group_by(proper_name, winner_party) |&gt;\n  summarise(\n      ec_vote = sum(votes),\n      .groups = \"drop\"\n    )\n\n# Arrange by ec_vote in descending order to get the winners first\nvote_summary &lt;- vote_summary |&gt;\n  arrange(desc(ec_vote))\n\n  # Return the results as two named lists for first and second place candidates\n  list(\n    first_place = list(\n      candidate = vote_summary$proper_name[1],\n      party = vote_summary$winner_party[1],\n      ec_vote = vote_summary$ec_vote[1]\n    ),\n    second_place = list(\n      candidate = vote_summary$proper_name[2],\n      party = vote_summary$winner_party[2],\n      ec_vote = vote_summary$ec_vote[2]\n    )\n  )\n}\n\n# Summarize popular vote totals\ncalculate_popular_vote_totals &lt;- function(popular_vote_data, election_year) {\n  # Filter for the specified election year\n  df_year_requested &lt;- popular_vote_data |&gt;\n    filter(year == election_year)\n\n  # Summarize popular vote counts and percentages by candidate and party\n  vote_summary &lt;- df_year_requested |&gt;\n    group_by(candidate) |&gt;\n    summarise(\n      popular_vote_count = sum(popular_vote_count, na.rm = TRUE),\n      popular_vote_percentage = mean(popular_vote_percentage, na.rm = TRUE),\n      .groups = \"drop\"\n    ) |&gt;\n    arrange(desc(popular_vote_count))\n\n  # Return the results as a list with each candidate's information\n  list(\n    first_place = list(\n      candidate = vote_summary$candidate[1],\n      popular_vote_count = vote_summary$popular_vote_count[1],\n      popular_vote_percentage = vote_summary$popular_vote_percentage[1]\n    ),\n    second_place = list(\n      candidate = vote_summary$candidate[2],\n      popular_vote_count = vote_summary$popular_vote_count[2],\n      popular_vote_percentage = vote_summary$popular_vote_percentage[2]\n    )\n  )\n}\n\n# Function for winner take all report\nstate_winner_take_all &lt;- function(data_set, election_year, ec_summary_data) {\n  # Filter data for the requested election year\n  df_year_requested &lt;- data_set |&gt; \n    filter(year == election_year)\n  \n  # Extract information from the ec_summary_data\n  proper_name1 &lt;- ec_summary_data$first_place$candidate\n  party1 &lt;- ec_summary_data$first_place$party\n  ec_vote1 &lt;- ec_summary_data$first_place$ec_vote\n  \n  proper_name2 &lt;- ec_summary_data$second_place$candidate\n  party2 &lt;- ec_summary_data$second_place$party\n  ec_vote2 &lt;- ec_summary_data$second_place$ec_vote\n  \n  # Create custom legend text with candidate names, parties, popular votes, and electoral votes\n  legend_text &lt;- paste0(\n    toupper(proper_name1), \" (\", substr(party1, 1, 1), \")\\n\",\n    \"Electoral Votes: \", ec_vote1, \"\\n\",\n    toupper(proper_name2), \" (\", substr(party2, 1, 1), \")\\n\",\n    \"Electoral Votes: \", ec_vote2\n  )\n  \n  # Create the plot\n  ggplot(df_year_requested, aes(state = state_abbr, fill = winner_party)) +\n    statebins::geom_statebins(radius = grid::unit(0.1, \"cm\")) +\n    scale_fill_manual(values = c(\"DEMOCRAT\" = \"blue\", \"REPUBLICAN\" = \"red\"), name = \"Winner\") +\n    labs(\n      title = paste(\"US Electoral College Votes by State-Wide Winner-Take-All (\", election_year, \")\", sep = \"\"),\n      subtitle = legend_text\n    ) +\n    theme_minimal() +\n    theme(\n      legend.position = \"none\",\n      panel.background = element_blank(),\n      axis.text = element_blank(),\n      axis.ticks = element_blank(),\n      panel.grid = element_blank(),\n      plot.subtitle = element_text(color = \"black\")\n    )\n}\n\n# Call functions for plotting\nec_summary &lt;- calculate_ec_vote_totals(state_winner_with_votes, 2000)\npop_summary &lt;- calculate_popular_vote_totals(popular_vote_summary, 2000)\nstate_winner_take_all(state_winner_with_votes, 2000, ec_summary)\n\nec_summary &lt;- calculate_ec_vote_totals(state_winner_with_votes, 2000)\npop_summary &lt;- calculate_popular_vote_totals(popular_vote_summary, 2000)\nstate_winner_take_all(state_winner_with_votes, 2000, ec_summary)\n\n\n#### DISTRICT WIDE WINNTER TAKE ALL & STATE WIDE AT LARGE VOTES ####\n\n# Calculate district winners and add an at_large seat\ncalculate_district_winners_with_at_large &lt;- function(data) {\n  # Calculate district-level winners\n  district_winners &lt;- data |&gt;\n    group_by(year, state, state_po, district) |&gt;\n    filter(candidatevotes == max(candidatevotes)) |&gt;\n    summarise(\n      party = first(party),\n      candidate = first(candidate),\n      .groups = \"drop\"\n    ) |&gt;\n    mutate(district = as.character(district)) |&gt;\n    select(year, state, state_po, district, party)\n  \n  # Calculate at-large seats (2 votes) based on majority party in each state per year\n  at_large_winners &lt;- district_winners |&gt;\n    group_by(year, state, state_po) |&gt;\n    count(party, name = \"district_count\") |&gt;\n    slice_max(district_count, n = 1, with_ties = FALSE) |&gt;\n    mutate(\n      district = \"at_large\",\n      party = party\n    ) |&gt;\n    select(year, state, state_po, district, party)\n\n  # Combine district winners and at-large results\n  bind_rows(district_winners, at_large_winners)\n}\n\n# Sum all votes and percentages for each party for each year and each state\ncalculate_vote_totals_at_large &lt;- function(data) {\n  data |&gt;\n    mutate(votes = if_else(district == \"at_large\", 2, 1)) |&gt;\n    group_by(year, state, state_po, party) |&gt;\n    summarise(total_votes = sum(votes), .groups = \"drop\") |&gt;\n    group_by(year, state, state_po) |&gt;\n    mutate(total_state_votes = sum(total_votes)) |&gt;\n    mutate(win_percent = round((total_votes / total_state_votes), 4)) |&gt;\n    select(-total_state_votes) |&gt;\n    arrange(year, state, party) |&gt; \n    mutate(color = ifelse(party == \"DEMOCRAT\", alpha(\"blue\", win_percent), alpha(\"red\", win_percent)))\n}\n\n\n# First find winners for each district and the at large winner\ndistrict_winners_with_at_large &lt;- calculate_district_winners_with_at_large(ELECTION_DATA_HOUSE)\nec_total_at_large &lt;- calculate_vote_totals_at_large(district_winners_with_at_large) \n\n# Identify all the unique presidential winners\nunique_winners_al &lt;- state_winner_with_votes |&gt;\n  distinct(year, winner_party, proper_name) |&gt;\n  rename(\"party\" = \"winner_party\")\n\n# Add proper names to EC totals\nec_total_at_large &lt;- ec_total_at_large |&gt;\n  left_join(unique_winners_al, by = c(\"year\", \"party\")) \n\ntotal_votes_check &lt;- ec_total_at_large |&gt;\n  filter(year == 2016) |&gt; \n  summarise(total_electoral_votes = sum(total_votes))\n\n\nplot_electoral_votes &lt;- function(data, election_year) {\n  df_year_filtered &lt;- data |&gt;\n    filter(year == election_year) |&gt;\n    group_by(state, state_po) |&gt;\n    ungroup()\n  \n  total_votes_summary &lt;- df_year_filtered |&gt;\n    group_by(proper_name, party) |&gt;\n    summarise(total_votes = sum(total_votes), .groups = \"drop\") |&gt;\n    arrange(desc(total_votes))\n  print(total_votes_summary)\n  total_votes_list &lt;- split(total_votes_summary, seq(nrow(total_votes_summary)))\n  \n  # Manually referencing each element in total_votes_list\n  proper_name1 &lt;- total_votes_list[[1]]$proper_name\n  winner_party1 &lt;- total_votes_list[[1]]$party\n  total_votes1 &lt;- total_votes_list[[1]]$total_votes\n  \n  proper_name2 &lt;- total_votes_list[[2]]$proper_name\n  winner_party2 &lt;- total_votes_list[[2]]$party\n  total_votes2 &lt;- total_votes_list[[2]]$total_votes + 3\n  \n  # Format party abbreviations\n  party1 &lt;- ifelse(winner_party1 == \"DEMOCRAT\", \"(D)\", \"(R)\")\n  party2 &lt;- ifelse(winner_party2 == \"DEMOCRAT\", \"(D)\", \"(R)\")\n  \n  # Construct the formatted string using paste and the variables\n  output_string &lt;- paste(\n    toupper(proper_name1), party1, \"\\nElectoral Votes:\", total_votes1, \"\\n\",\n    toupper(proper_name2), party2, \"\\nElectoral Votes:\", total_votes2\n  )\n   output_string &lt;- sprintf(\n    \"%s %s\\nElectoral Votes: %d\\n%s %s\\nElectoral Votes: %d\",\n    toupper(proper_name1), party1, total_votes1,\n    toupper(proper_name2), party2, total_votes2\n    )\n    \n  # Create the plot\n  ggplot(df_year_filtered, aes(state = state_po, fill = color)) +\n    statebins::geom_statebins(radius = grid::unit(0.1, \"cm\")) +\n     scale_fill_identity() +\n    labs(\n      title = paste(\"US District-Wide Winner-Take-All + State-Wide “At Large” Votes (\", election_year, \")\", sep = \"\"),\n      subtitle = paste(\"Color intensity represents share of Electoral College Votes\\n\\n\",output_string, sep=\"\\n\")\n    ) +\n    theme_minimal() +\n    theme(\n      legend.position = \"right\",\n      panel.background = element_blank(),\n      axis.text = element_blank(),\n      axis.ticks = element_blank(),\n      panel.grid = element_blank(),\n      plot.subtitle = element_text(color = \"black\")\n    )\n}\n\n# Run plot\nplot_electoral_votes(ec_total_at_large, 2000)\n\n#### STATE WIDE PROPORTIONAL ####\n\nelecton_data_president_p &lt;- ELECTION_DATA_PRESIDENT |&gt; \n    mutate(party_detailed = if_else(party_detailed == \"DEMOCRATIC-FARMER-LABOR\", \"DEMOCRAT\", party_detailed)) |&gt;\n    filter(party_detailed == \"DEMOCRAT\" | party_detailed == \"REPUBLICAN\")\n\n# Get electoral votes for each state for each year\nelectoral_votes_by_state_p &lt;- ELECTION_DATA_HOUSE |&gt; \n  group_by(year, state, state_po) |&gt;\n  summarize(votes = n_distinct(district) + 2)\n\n# Calculate percentages \nstate_percentages_p &lt;- electon_data_president_p |&gt;\n  group_by(year, state, state_po, party_detailed) |&gt;\n  summarise(\n    candidate = first(candidate),\n    total_candidate_votes = sum(candidatevotes),\n    total_state_votes = first(totalvotes), \n    percentage = total_candidate_votes / total_state_votes\n  ) |&gt;\n  ungroup() |&gt;\n  select(year, state, state_po, candidate, party_detailed, percentage) |&gt;\n  group_by(year, state, state_po) |&gt;\n  mutate(winner = percentage == max(percentage)) |&gt;\n  ungroup()\n\n# Join percentages with votes\nstate_percentages_w_votes_p &lt;- state_percentages_p |&gt;\n  right_join(electoral_votes_by_state_p, by = c(\"year\", \"state\", \"state_po\")) |&gt;\n  rename(electoral_votes = votes)\n \n# Break up electoral votes won by percentages  \nstate_electoral_votes_p &lt;- state_percentages_w_votes_p |&gt;\n  group_by(year, state, state_po) |&gt;\n  mutate(\n    # Calculate electoral votes won by the winner (round up)\n    electoral_votes_won = ifelse(\n      winner,\n      ceiling(percentage * electoral_votes),\n      electoral_votes - ceiling(percentage[winner == TRUE] * electoral_votes)\n    )\n  ) |&gt;\n  mutate(percent_electoral_votes = round(electoral_votes_won / electoral_votes, 2)) |&gt;\n  mutate(color = ifelse(party_detailed == \"DEMOCRAT\", alpha(\"blue\", percent_electoral_votes), alpha(\"red\",             percent_electoral_votes))) |&gt;\n  ungroup()\n\n# Join proper names\nstate_electoral_votes_p &lt;- state_electoral_votes_p |&gt;\n  left_join(unique_winners_n, by = c(\"year\", \"party_detailed\")) \n  \nplot_electoral_votes &lt;- function(data, election_year) {\n  df_year_filtered &lt;- data |&gt;\n    filter(year == election_year) \n  \n  summary &lt;- df_year_filtered |&gt;\n    group_by(party_detailed, proper_name) |&gt;\n    summarise(total_electoral_votes_won = sum(electoral_votes_won, na.rm = TRUE)) |&gt;\n    ungroup()\n  print(summary)\n  total_votes_list &lt;- split(summary, seq(nrow(summary)))\n  print(total_votes_list)\n  proper_name1 &lt;- total_votes_list[[1]]$proper_name\n  winner_party1 &lt;- total_votes_list[[1]]$party_detailed\n  total_votes1 &lt;- total_votes_list[[1]]$total_electoral_votes_won + 3\n  \n  proper_name2 &lt;- total_votes_list[[2]]$proper_name\n  winner_party2 &lt;- total_votes_list[[2]]$party_detailed\n  total_votes2 &lt;- total_votes_list[[2]]$total_electoral_votes_won\n  \n  # Format party abbreviations\n  party1 &lt;- ifelse(winner_party1 == \"DEMOCRAT\", \"(D)\", \"(R)\")\n  party2 &lt;- ifelse(winner_party2 == \"DEMOCRAT\", \"(D)\", \"(R)\")\n  \n  # Construct the formatted string using paste and the variables\n  output_string &lt;- sprintf(\n  \"%s %s\\nElectoral Votes: %d\\n%s %s\\nElectoral Votes: %d\",\n  toupper(proper_name1), party1, total_votes1,\n  toupper(proper_name2), party2, total_votes2\n)\n  df_year_filtered &lt;- df_year_filtered |&gt; \n    filter(winner == TRUE)\n  # Create the plot\n  ggplot(df_year_filtered, aes(state = state_po, fill = color)) +\n    statebins::geom_statebins(radius = grid::unit(0.1, \"cm\")) +\n     scale_fill_identity() +\n    labs(\n      title = paste(\"United States Electoral College Votes by State-Wide Proportional (\", election_year, \")\", sep = \"\"),\n      subtitle = paste(\"Color intensity represents share of Electoral College Votes\\n\\n\", output_string, sep=\"\\n\")\n    ) +\n    theme_minimal() +\n    theme(\n      legend.position = \"right\",\n      panel.background = element_blank(),\n      axis.text = element_blank(),\n      axis.ticks = element_blank(),\n      panel.grid = element_blank(),\n      plot.subtitle = element_text(color = \"black\")\n    )\n}\n\n# Plot the data\nplot_electoral_votes(state_electoral_votes_p, 2000)\n\n#### NATIONAL VOTE PROPORTION ####\n\nelection_data_president_n &lt;- ELECTION_DATA_PRESIDENT |&gt; \n    mutate(party_detailed = if_else(party_detailed == \"DEMOCRATIC-FARMER-LABOR\", \"DEMOCRAT\", party_detailed)) |&gt;\n    filter(party_detailed == \"DEMOCRAT\" | party_detailed == \"REPUBLICAN\")\n\n# Get electoral votes for each state for each year\nelectoral_votes_by_state_n &lt;- ELECTION_DATA_HOUSE |&gt; \n  group_by(year, state, state_po) |&gt;\n  summarize(votes = n_distinct(district) + 2)\n\nstate_percentages_n &lt;- election_data_president_n |&gt;\n  group_by(year, party_detailed, candidate) |&gt;\n  summarise(\n    total_candidate_votes = sum(candidatevotes, na.rm = TRUE), # Total votes for the candidate across all states\n    total_year_votes = sum(totalvotes, na.rm = TRUE) # Total votes for the year across all states\n  ) |&gt;\n  ungroup() |&gt;\n  mutate(\n    percentage = total_candidate_votes / total_year_votes # Calculate percentage for the candidate across all states\n  ) |&gt;\n  select(year, candidate, party_detailed, total_candidate_votes, percentage) |&gt;\n  arrange(year, desc(percentage)) \n\n# Calculate the winner for each year\nstate_percentages_n &lt;- state_percentages_n |&gt;\n  group_by(year) |&gt;\n  mutate(winner = percentage == max(percentage)) |&gt;\n  ungroup()\n\nexpanded_data_n &lt;- state_percentages_n |&gt;\n  inner_join(\n    electoral_votes_by_state_n,\n    by = \"year\",\n    relationship = \"many-to-many\"\n  ) \n\nstate_electoral_votes_n &lt;- expanded_data_n |&gt;\n  group_by(year, state, state_po) |&gt;\n  mutate(\n  winner_votes = ceiling(percentage[winner == TRUE] * votes),\n  # Calculate electoral votes won by the winner (round up)\n  electoral_votes_won = ifelse(\n    winner,\n    winner_votes,\n    votes - winner_votes\n  )\n)\n \n# Identify all the unique presidential winners\nunique_winners_n &lt;- state_winner_with_votes |&gt;\n  distinct(year, winner_party, proper_name) |&gt; \n  rename(party_detailed = winner_party)\n\n# Add proper names\nstate_electoral_votes_n &lt;- state_electoral_votes_n |&gt;\n  left_join(unique_winners_n, by = c(\"year\", \"party_detailed\")) \n\n# Add colors\nstate_electoral_votes_n &lt;- state_electoral_votes_n |&gt;\n   mutate(color = ifelse(party_detailed == \"DEMOCRAT\", alpha(\"blue\", percentage), alpha(\"red\",             percentage)))\n\nplot_national_proportion &lt;- function(data, election_year) {\n  # Filter data for the specified election year\n  df_year_filtered &lt;- data |&gt;\n    filter(year == election_year)\n  print(df_year_filtered)\n  # Get summary for EC vote counts  \n  summary &lt;- df_year_filtered |&gt;\n    group_by(party_detailed, proper_name) |&gt;\n    summarise(total_electoral_votes_won = sum(electoral_votes_won, na.rm = TRUE)) |&gt;\n    ungroup()\n\n  # Break out into list for display\n  total_votes_list &lt;- split(summary, seq(nrow(summary)))\n\n  proper_name1 &lt;- total_votes_list[[1]]$proper_name\n  winner_party1 &lt;- total_votes_list[[1]]$party_detailed\n  total_votes1 &lt;- total_votes_list[[1]]$total_electoral_votes_won + 3\n  \n  proper_name2 &lt;- total_votes_list[[2]]$proper_name\n  winner_party2 &lt;- total_votes_list[[2]]$party_detailed\n  total_votes2 &lt;- total_votes_list[[2]]$total_electoral_votes_won\n  \n  # Format party abbreviations\n  party1 &lt;- ifelse(winner_party1 == \"DEMOCRAT\", \"(D)\", \"(R)\")\n  party2 &lt;- ifelse(winner_party2 == \"DEMOCRAT\", \"(D)\", \"(R)\")\n  \n  # Construct the formatted string using paste and the variables\n  output_string &lt;- sprintf(\n    \"%s %s\\nElectoral Votes: %d\\n%s %s\\nElectoral Votes: %d\",\n    toupper(proper_name1), party1, total_votes1,\n    toupper(proper_name2), party2, total_votes2\n    )\n  \n  # Create the plot\n  ggplot(df_year_filtered, aes(state = state_po, fill = color)) +\n    statebins::geom_statebins(radius = grid::unit(0.1, \"cm\")) +\n    scale_fill_identity() +\n    labs(\n      title = paste(\"United States Electoral College Votes by National Proportion (\", election_year, \")\", sep = \"\"),\n      subtitle = paste(\"Color intensity represents share of Electoral College Votes\\n\\n\", output_string,sep=\"\\n\")\n    ) +\n    theme_minimal() +\n    theme(\n      legend.position = \"right\",\n      panel.background = element_blank(),\n      axis.text = element_blank(),\n      axis.ticks = element_blank(),\n      panel.grid = element_blank(),\n      plot.subtitle = element_text(color = \"black\")\n    )\n}\n\n# Plot the data\nplot_national_proportion(state_electoral_votes_n, 2000)\n\n\ndata &lt;- data.frame(\n  system = c(\"State Winner Take All\", \"District Winner + At Large\", \"State Wide Proportional\", \"National Proportional\"),\n  percentage = c(0.4962, 0.4665, 0.4869, 0.52)\n)\n\n# Plot\nggplot(data, aes(x = system, y = percentage)) +\n  geom_point(shape = 21, color = \"black\", fill = \"dodgerblue\", size=8) +\n  geom_hline(yintercept = 0.5, linetype = \"dashed\", color = \"red\") +\n  scale_y_continuous(limits = c(0.42, 0.53), breaks = seq(0.42, 0.55, by = 0.01)) +\n  labs(\n    title = \"Do any Electoral Systems Exceed 50% for the 2000 Election?\",\n    x = \"Electoral System\",\n    y = \"Percentage\",\n    size = \"Distance from 50%\"\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    legend.position = \"right\"\n  )\n\n\n\n\nThe Electoral College system inherently disadvantages densely concentrated urban populations due to geographic sorting, where large numbers of voters in cities are “wasted” under the current allocation methods. This effect is especially pronounced in the State-Wide Winner-Take-All and District-Wide Winner-Take-All + At-Large systems, where urban votes are overshadowed by more spread-out rural and suburban voters. Even with a State-Wide Proportional approach, the dispersed nature of electoral votes dilutes the power of high-population centers.13\nThis dynamic reflects the original pastoral leanings of certain Founding Fathers, who were wary of urban centers and their concentrated political influence. Many founders idealized a nation of independent, rural landowners and saw the Electoral College as a mechanism to balance the interests of these pastoral areas against growing urban centers.14 Consequently, modern calls for Electoral College reform often stem from this persistent tension between rural and urban representation.\nCritics of the Electoral College, such as historian George C. Edwards III, argue that this system inevitably introduces a significant “democratic deficit” by allowing a candidate to win the presidency without securing the popular vote. Edwards suggests that this mechanism distorts democratic representation, disproportionately empowering certain states and demographic groups at the expense of others, and thus subverting the principle of equal representation.15\nThese findings are in line with the thoughts of Robert A. Dahl, widely regarded as one of the United States’ preeminent authoritie on democratic theory and the American Constitution.\nIn How Democratic Is the American Constitution? Dahl critically examines the Electoral College and its democratic shortcomings. He too recounts the 2000 election, where a candidate with fewer popular votes won, and traces this anomaly to the original confusion and compromises of the Framers. They established the Electoral College out of desperation after rejecting other methods, prioritizing insulation from popular choice and concern over “cabal and corruption.”16\nAs such, the Electoral College is deeply rooted in an anti-democratic framework. Built to balance regional influence rather than to represent the popular will, the Electoral College was again, crafted with significant limitations to prevent it from reflecting a true “one person, one vote” standard. Its mission makes it impossible to align with the democratic values most champion today.\nIn contrast, modern American political culture is firmly grounded in the principle of equal representation, where each vote should carry equal weight. Most Americans believe strongly in “one person, one vote” and would find it jarring, even offensive, for any politician to openly assert that some votes should count more than others.\nYet by supporting the Electoral College, we tacitly accept this inequality, promoting the illusion that it’s anything other than an outdated system that distorts minority political power.\nThere exists a deep disatisfaction with the Electoral College among the American public17: \nAs such, strong public support exists for centering “one person, one vote” into the U.S. Political System and its methods for selecting the President.\nIf we summarize our findings, there’s one system that consistly rewards the Popular Vote Winner the 50% electoral college vote threshold needed to win the presidency:\n\n Given these findings, the it’s the purple shading on the National Proportional maps above that best reflect the most equitable spirit of “one person, one vote,” highlighting how popular will could be represented more faithfully. If the Electoral College must be preserved, such a proportional approach would align more closely with our democratic values and national political culture, offering a way forward that respects the ideal of equal voter influence.\nAs such, if were to keep the Electoral College, we should adopt the National Proportion method for allocating electoral votes and the delegates who chose our nation’s chief executive, The President of the United States."
  },
  {
    "objectID": "data/mp03/dataversefiles/codebook-us-house-1976–2020.html",
    "href": "data/mp03/dataversefiles/codebook-us-house-1976–2020.html",
    "title": "STA 9750 Fall 2024 - Jason Amey",
    "section": "",
    "text": "#Codebook for U.S. House Returns 1976–2020\nThe data file 1976-2020-house contains constituency (district) returns for elections to the U.S. House of Representatives from 1976 to 2020. The data source is the document “Statistics of the Congressional Election,” published biennially by the Clerk of the U.S. House of Representatives. 2018 data comes from official state election websites, and for Kansas, come from Stephen Pettigrew and the Kansas Secretary of State office (in some cases, they are marked as unofficial, and will be updated at a later time).\nAll string variables are in upper case.\n##Variables The variables are listed as they appear in the data file.\n###year - Description: year in which election was held\n\n###state - Description: state name\n\n###state_po - Description: U.S. postal code state abbreviation\n\n###state_fips - Description: State FIPS code\n\n###state_cen - Description: U.S. Census state code\n\n\nstate_ic\n\nDescription: ICPSR state code\n\n\n###office - Description: U.S. House (constant)\n\n\n\ndistrict\n\nDescription: district number\n****Note****: At-large districts are coded as 0 (zero).\n\n\n\n\nstage\n\nDescription: electoral stage\nCoding:\n\n\n\n\ncode\ndefinition\n\n\n\n\n“gen”\ngeneral elections\n\n\n“pri”\nprimary elections\n\n\n\n\nNote: Only appears in special cases. Consult original House Clerk report for these cases.\n\n\n\n\nspecial\n\nDescription: special election\nCoding\n\n\n\n\ncode\ndefinition\n\n\n\n\n“TRUE”\nspecial elections\n\n\n“FALSE”\nregular elections\n\n\n\n\n\n\ncandidate\n\nDescription: name of the candidate\nNote: The name is as it appears in the House Clerk report.\n\n\n\n\nparty\n\nDescription: party of the candidate (always entirely lowercase)\n\nNote: Parties are as they appear in the House Clerk report. In states that allow candidates to appear on multiple party lines, separate vote totals are indicated for each party. Therefore, for analysis that involves candidate totals, it will be necessary to aggregate across all party lines within a district. For analysis that focuses on two-party vote totals, it will be necessary to account for major party candidates who receive votes under multiple party labels. Minnesota party labels are given as they appear on the Minnesota ballots. Future versions of this file will include codes for candidates who are endorsed by major parties, regardless of the party label under which they receive votes.\n\n\n\n\n\nwritein\n\nDescription: vote totals associated with write-in candidates\nCoding:\n\n\n\n\ncode\ndefinition\n\n\n\n\n“TRUE”\nwrite-in candidates\n\n\n“FALSE”\nnon-write-in candidates\n\n\n\n\n\n\nmode\n\nDescription: mode of voting; states with data that doesn’t break down returns by mode are marked as “total”\n\n\n\n\ncandidatevotes\n\nDescription: votes received by this candidate for this particular party\n\n\n\n\ntotalvotes\n\nDescription: total number of votes cast for this election\n\n\n\n\nfusion_ticket\n\nDescription: A TRUE/FALSE indicator as to whether the given candidate is running on a fusion party ticket, which will in turn mean that a candidate will appear multiple times, but by different parties, for a given election. States with fusion tickets include Connecticut, New Jersey, New York, and South Carolina.\n\n\n\n\n\n\n\n## unofficial Description: TRUE/FALSE indicator for unofficial result (to be updated later); this appears only for 2018 data in some cases\n\n\n\n\n\nversion\n\nDescription: date when this dataset was finalized\n\n##NOTES:\ncandidatevotes: for uncontested races, value is set to 1 in FL. Should user want to set a higher value for analysis purposes, consider setting the value as the maximum for a given state-year. The code in R would be the following: df &lt;- read.csv(“1976-2018-house.csv”, stringsAsFactors = FALSE) df &lt;- df %&gt;% group_by(state_po,district) %&gt;% mutate(max_st_year_vote = max(candidatevotes, na.rm=T)\nThe following code should be used if the user would like to assume that uncontested candidates would have recieved as many votes as the best contested candidate.\ndistrict: district is set to 0 for single member states.\nparty and candidate: candidate - party combinations are recorded as they were on the state elections website. This means that for states where the same candidate might appear on multiple parties, like in NY, they are recorded as such. Therefore, for users interested in finding the primary party, run the following code:\ndf &lt;- read.csv(“1976-2020-house.csv”, stringsAsFactors = FALSE) df\\(district &lt;- str_pad(df\\)district, width=2, pad=“0”, side=“left) df\\(state_fips &lt;- str_pad(df\\)state_fips, width=2, pad=”0”, side=“left) df\\(GEOID &lt;- paste(df\\)state_fips, df$district, sep=”“) df_max &lt;- df %&gt;% group_by(candidate, GEOID, year) %&gt;% slice(which.max(candidatevotes) df_sum &lt;- df %&gt;% group_by(candidate, GEOID, year) %&gt;% aggregate(candvotes_sum = sum(candvotes))"
  },
  {
    "objectID": "final_project.html",
    "href": "final_project.html",
    "title": "STA 9750 Fall 2024 - Jason Amey",
    "section": "",
    "text": "library(readr)\nBBL &lt;- read_csv(“data/final_project/finance/avroll.csv”)\nfinance_data_2010_residential &lt;- finance_data_2010 |&gt; filter(TAXCLASS != “4” & TAXCLASS != “3” & B == 3)\ndata &lt;- finance_data_2010 |&gt; filter(B == 3 & BLOCK == 1068 & LOT == 37)\nglimpse(data)\n\npark_corner &lt;- finance_data_2010_residential |&gt; filter(BLOCK == 1068 & LOT == 37)\npark_corner$FULLVAL\nglimpse(finance_data_2010_residential)\nfile_path_sample &lt;- “data/final_project/fy24_sample.txt”\ntext_lines &lt;- readLines(file_path_sample)\nrecords &lt;- strsplit(text_lines,“”)\nparsed_records &lt;- lapply(records, function(record) strsplit(record, “))\nfile_path &lt;- “data/final_project/finance/fy24_tc234.txt”\ntext_lines &lt;- readLines(file_path)\nrecords &lt;- strsplit(text_lines,“”)\nparsed_records &lt;- lapply(records, function(record) strsplit(record, “))\nfiltered_records &lt;- lapply(parsed_records, function(record) { if (record[[1]][[2]] == “3”) { return(record) } else { return(NULL) # Return NULL to indicate exclusion } })\nfiltered_records &lt;- filtered_records[!sapply(filtered_records, is.null)]\n\n\ncleaned_records &lt;- lapply(filtered_records, function(record) { sapply(record, trimws) })\ndf &lt;- do.call(cbind, cleaned_records) df &lt;- as.data.frame(t(df))\nproperty &lt;- df |&gt; filter(V3 == “01068” & V4 == “0037”)\nglimpse(property)\nwrite.csv(df,“data/final_project/sampled/fy24_tc234_sampled.csv”, row.names = FALSE)\n\n```r\n# Import real estate valuations from NYC Department of Finance \nfinance_data_2010 &lt;- read_csv(\"data/final_project/finance/avroll.csv\")\n\n# Import all finance data for tax classes 2, 3 and 4\nfinance_data_class_234 &lt;- read_csv(\"data/final_project/finance/tc234_2010.csv\") |&gt;\n\n# Limit to Brooklyn and the residential tax class of 2, and the \nbk_finance_data_class_2_2010 &lt;- finance_data_class_234 |&gt;\n  filter(BORO == 3 & TXCL == 2)\n\nbk_finance_data_class_2_2010\n\n# Import all finance data for tax classes 2, 3 and 4\nfinance_data_class_1 &lt;- read_csv(\"data/final_project/finance/tc1_2010.csv\") \n\n# Limit to Brooklyn:\nbk_finance_data_class_1_2010 &lt;- finance_data_class_1 |&gt;\n  filter(BORO == 3)\n  \nbk_finance_data_class_1_2010 &lt;- bk_finance_data_class_1_2010 |&gt; \n  select()\n  \nView(bk_finance_data_class_1_2010)\n  \n# Convert EASE column to consistent data types for row binding\nbk_finance_data_class_1_2010 &lt;- bk_finance_data_class_1_2010 %&gt;% mutate(EASE = as.character(EASE))\nbk_finance_data_class_2_2010 &lt;- bk_finance_data_class_2_2010 %&gt;% mutate(EASE = as.character(EASE))\n\n\n\nbk_finance_data_2010 &lt;- bind_rows(bk_finance_data_class_1_2010, bk_finance_data_class_2_2010)\n\nbk_finance_data_2010\n\n#Re-create dataset with just Brooklyn data, borough 3 \nbrooklyn_2010 &lt;- finance_data_2010 |&gt;\n  filter(B == 3)\n\n#Save new dataset to csv\nwrite_csv(brooklyn_2010, \"data/final_project/brooklyn_2010.csv\")\n\n#Import Borough, Block, Lot info for PPW from The NYC Department of Planning\nBBL &lt;- read_csv(\"data/final_project/planning/lot_selector_PPW_PLUTO.csv\")\n\nView(BBL)"
  },
  {
    "objectID": "mp03.html#data-prep",
    "href": "mp03.html#data-prep",
    "title": "STA 9750 Fall 2024 - Jason Amey",
    "section": "Data Prep",
    "text": "Data Prep\n\n\n&gt; show the code\n\n#data download\n\nELECTION_DATA &lt;- read_csv(\"data/mp03/dataversefiles/1976-2022-house.csv\")\n\n\ncongress_shapefiles_ucla &lt;- function(start = 95, end = 112) {\n  BASE_URL &lt;- \"https://cdmaps.polisci.ucla.edu/shp/districts\"\n  \n  # Create directory if it doesn't exist\n  if (!dir.exists(\"data/mp03/congress_shapefiles\")) {\n    dir.create(\"data/mp03/congress_shapefiles\", recursive = TRUE)\n  }\n  \n  for (congress in start:end) {\n    # Format congress number with leading zeros\n    congress_str &lt;- sprintf(\"%03d\", congress)\n    \n    # Construct URL and destination path\n    file_url &lt;- paste0(BASE_URL, congress_str, \".zip\")\n    dest_file &lt;- paste0(\"data/mp03/congress_shapefiles/congress_\", congress_str, \"_shapefile.zip\")\n    \n    if (!file.exists(dest_file)) {\n      # Download file and check for success\n      tryCatch({\n        download.file(file_url, destfile = dest_file, mode = \"wb\")\n        message(\"Downloaded shapefile for Congress \", congress_str)\n      }, error = function(e) {\n        message(\"Failed to download for Congress \", congress_str, \": \", e)\n      })\n    } else {\n      message(\"File for Congress \", congress_str, \" already exists. Skipping download.\")\n    }\n  }\n}\n\n# Run function\ncongress_shapefiles_ucla(95, 98)\n\n#####\n\ncongress_shapefiles_census &lt;- function(start_year = 2013, end_year = 2023) {\n  BASE_URL &lt;- \"https://www2.census.gov/geo/tiger/TIGER\"\n  \n  # Create the download directory if it doesn’t exist\n  if (!dir.exists(\"data/mp03/census_congress_shapefiles\")) {\n    dir.create(\"data/census_congress_shapefiles\", recursive = TRUE)\n  }\n  \n  # Determine Congress numbers based on years\n  congress_numbers &lt;- seq(113, 113 + (end_year - start_year) / 2, by = 1)\n  years &lt;- seq(start_year, end_year, by = 2)  # Only even years\n\n  # Loop over the years and corresponding congress numbers\n  for (i in seq_along(years)) {\n    year &lt;- years[i]\n    congress &lt;- congress_numbers[i]\n    congress_str &lt;- sprintf(\"cd%d\", congress)  # Format as 'cd113', 'cd114', etc.\n    \n    # Construct URL and destination path\n    file_url &lt;- paste0(BASE_URL, year, \"/CD/tl_\", year, \"_us_\", congress_str, \".zip\")\n    dest_file &lt;- paste0(\"data/mp03/census_congress_shapefiles/tl_\", year, \"_us_\", congress_str, \".zip\")\n    \n    # Check if file already exists to avoid re-downloading\n    if (!file.exists(dest_file)) {\n      # try catch for for successful downloading\n      tryCatch({\n        download.file(file_url, destfile = dest_file, mode = \"wb\")\n        print(\"Downloaded shapefile for \", congress_str, \" (Year \", year, \")\")\n      }, error = function(e) {\n        print(\"Failed to download for \", congress_str, \" (Year \", year, \"): \", e)\n      })\n    } else {\n      message(\"File for \", congress_str, \" (Year \", year, \") already exists. Skipping download.\")\n    }\n  }\n}\n\n#Run function\ncongress_shapefiles_census(2013, 2023)"
  },
  {
    "objectID": "mp03.html#data-prep-readjust",
    "href": "mp03.html#data-prep-readjust",
    "title": "The Electoral College Dilemma: Tradition, Tension, and the Future of American Democracy",
    "section": "",
    "text": "&gt; show code for .shp files\n\n# Identify main directory\nDIRECTORY &lt;- paste(getwd(),\"data\", sep=\"/\")\n\n# Create function for extracting files from .zip files\nshp_from_zip &lt;- function(file_name, directory = DIRECTORY){\n  dir &lt;- paste(directory, file_name, sep=\"/\")\n  td &lt;- tempdir(); \n  zip_contents &lt;- unzip(dir, \n                        exdir = td)\n  fname_shp &lt;- zip_contents[grepl(\"shp$\", zip_contents)]\n  return(read_sf(fname_shp))\n}\n\n# Test function\nfile &lt;- shp_from_zip(\"/mp03/congress_shapefiles/congress_095_shapefile.zip\")"
  },
  {
    "objectID": "final_project_presentation_check_in.html#thesis-to-explore",
    "href": "final_project_presentation_check_in.html#thesis-to-explore",
    "title": "STA 9750 Final Project Presentation Check In",
    "section": "Thesis to explore:",
    "text": "Thesis to explore:"
  },
  {
    "objectID": "final_project_presentation_check_in.html#has-this-topic-been-studied-in-new-york-city",
    "href": "final_project_presentation_check_in.html#has-this-topic-been-studied-in-new-york-city",
    "title": "STA 9750 Final Project Presentation Check In",
    "section": "Has this topic been studied? In New York City?:",
    "text": "Has this topic been studied? In New York City?:"
  },
  {
    "objectID": "final_project_presentation_check_in.html#we-have-re-scoped-our-projects-ambitions",
    "href": "final_project_presentation_check_in.html#we-have-re-scoped-our-projects-ambitions",
    "title": "STA 9750 Final Project Presentation Check In",
    "section": "We have re-scoped our project’s ambitions",
    "text": "We have re-scoped our project’s ambitions"
  },
  {
    "objectID": "final_project_presentation_check_in.html#prospect-park-west-bike-lane-brooklyn-ny",
    "href": "final_project_presentation_check_in.html#prospect-park-west-bike-lane-brooklyn-ny",
    "title": "STA 9750 Final Project Presentation Check In",
    "section": "2010 Prospect Park West Bike Lane, Brooklyn NY",
    "text": "2010 Prospect Park West Bike Lane, Brooklyn NY"
  },
  {
    "objectID": "final_project_presentation_check_in.html#this-project-received-significant-media-attention",
    "href": "final_project_presentation_check_in.html#this-project-received-significant-media-attention",
    "title": "STA 9750 Final Project Presentation Check In",
    "section": "This project received significant media attention",
    "text": "This project received significant media attention"
  },
  {
    "objectID": "final_project_presentation_check_in.html#by-safety-metrics-this-project-has-been-a-success",
    "href": "final_project_presentation_check_in.html#by-safety-metrics-this-project-has-been-a-success",
    "title": "STA 9750 Final Project Presentation Check In",
    "section": "By safety metrics this project has been a success",
    "text": "By safety metrics this project has been a success"
  },
  {
    "objectID": "final_project_presentation_check_in.html#did-the-prospect-park-west-traffic-calming-project-impact-property-values-on-ppw",
    "href": "final_project_presentation_check_in.html#did-the-prospect-park-west-traffic-calming-project-impact-property-values-on-ppw",
    "title": "STA 9750 Final Project Presentation Check In",
    "section": "Did the Prospect Park West traffic calming project impact property values on PPW?",
    "text": "Did the Prospect Park West traffic calming project impact property values on PPW?"
  },
  {
    "objectID": "final_project_presentation_check_in.html#the-department-of-finance-tax-assessment-archives",
    "href": "final_project_presentation_check_in.html#the-department-of-finance-tax-assessment-archives",
    "title": "STA 9750 Final Project Presentation Check In",
    "section": "The Department of Finance Tax Assessment Archives",
    "text": "The Department of Finance Tax Assessment Archives"
  },
  {
    "objectID": "final_project_presentation_check_in.html#fields-for-data-definitions",
    "href": "final_project_presentation_check_in.html#fields-for-data-definitions",
    "title": "STA 9750 Final Project Presentation Check In",
    "section": "~130 fields for data definitions",
    "text": "~130 fields for data definitions"
  },
  {
    "objectID": "final_project_presentation_check_in.html#this-department-of-finance-tool-documents-increasing-property-values-under-total-value",
    "href": "final_project_presentation_check_in.html#this-department-of-finance-tool-documents-increasing-property-values-under-total-value",
    "title": "STA 9750 Final Project Presentation Check In",
    "section": "This Department of Finance tool documents increasing property values under Total Value",
    "text": "This Department of Finance tool documents increasing property values under Total Value"
  },
  {
    "objectID": "final_project_presentation_check_in.html#transformation-of-tax-assessment-data-into-r-data-frame",
    "href": "final_project_presentation_check_in.html#transformation-of-tax-assessment-data-into-r-data-frame",
    "title": "STA 9750 Final Project Presentation Check In",
    "section": "Transformation of tax assessment data into R data frame",
    "text": "Transformation of tax assessment data into R data frame"
  },
  {
    "objectID": "final_project_presentation_check_in.html#identify-field-that-corresponds-to-total-value",
    "href": "final_project_presentation_check_in.html#identify-field-that-corresponds-to-total-value",
    "title": "STA 9750 Final Project Presentation Check In",
    "section": "Identify field that corresponds to Total Value",
    "text": "Identify field that corresponds to Total Value"
  },
  {
    "objectID": "final_project_presentation_check_in.html#now-need-to-look-look-up-all-relevant-property-values",
    "href": "final_project_presentation_check_in.html#now-need-to-look-look-up-all-relevant-property-values",
    "title": "STA 9750 Final Project Presentation Check In",
    "section": "Now need to look look up all relevant property values",
    "text": "Now need to look look up all relevant property values"
  },
  {
    "objectID": "final_project_presentation_check_in.html#challenges-with-pre-2014-tax-assessment-data",
    "href": "final_project_presentation_check_in.html#challenges-with-pre-2014-tax-assessment-data",
    "title": "STA 9750 Final Project Presentation Check In",
    "section": "Challenges with pre-2014 tax assessment data",
    "text": "Challenges with pre-2014 tax assessment data"
  },
  {
    "objectID": "final_project_presentation_check_in.html#skeleton",
    "href": "final_project_presentation_check_in.html#skeleton",
    "title": "STA 9750 Final Project Presentation Check In",
    "section": "SKELETON",
    "text": "SKELETON"
  },
  {
    "objectID": "final_project_presentation_check_in.html#the-department-of-finance-tax-assessment-archives-1",
    "href": "final_project_presentation_check_in.html#the-department-of-finance-tax-assessment-archives-1",
    "title": "STA 9750 Final Project Presentation Check In",
    "section": "The Department of Finance Tax Assessment Archives",
    "text": "The Department of Finance Tax Assessment Archives"
  },
  {
    "objectID": "final_project_presentation_check_in.html#thank-you-clinta-and-jason--",
    "href": "final_project_presentation_check_in.html#thank-you-clinta-and-jason--",
    "title": "STA 9750 Final Project Presentation Check In",
    "section": "Thank you, Clinta and Jason :-)",
    "text": "Thank you, Clinta and Jason :-)"
  },
  {
    "objectID": "mp03.html#fun-time-for-fusion",
    "href": "mp03.html#fun-time-for-fusion",
    "title": "STA 9750 Fall 2024 - Jason Amey",
    "section": "fun time for fusion",
    "text": "fun time for fusion\n\nData for NY Elections, Title Case\n\n\n\n\n\n\n\n\n\n\n\n\nYear\nState\nDistrict\nWinner\nParty\nLoser\nParty\nHighest %\n\n\n\n\n1980\nNY\n3\nGregory W Carman\nConservative, Republican\nJerome A Ambro Jr\nDemocrat, Right To Life\n0.429\n\n\n1980\nNY\n6\nJohn LeBoutillier\nConservative, Republican, Right To Life\nLester L Wolff\nDemocrat, Liberal\n0.437\n\n\n1986\nNY\n27\nGeorge C Wortley\nConservative, Republican\nRosemary S Pooler\nDemocrat, Effective Congress\n0.483\n\n\n1994\nNY\n1\nMichael P Forbes\nConservative, Republican, Right To Life\nGeorge J Hochbrueckner\nDemocrat, Long Island First\n0.428\n\n\n1996\nNY\n1\nMichael P Forbes\nConservative, Independence, Republican, Right To Life\nNora L Bredes\nDemocrat, Save Medicare\n0.398\n\n\n1996\nNY\n30\nJack Quinn\nConservative, Freedom, Independence, Republican\nFrancis J Pordum\nDemocrat, Protect Seniors\n0.405\n\n\n2006\nNY\n25\nJames T Walsh\nConservative, Independence, Republican\nDan Maffei\nDemocrat, Working Families\n0.443\n\n\n2006\nNY\n29\nJohn R “Randy” Kuhl Jr\nConservative, Independence, Republican\nEric J Massa\nDemocrat, Working Families\n0.436\n\n\n2012\nNY\n27\nChris Collins\nConservative, Republican\nKathleen C Hochul\nDemocrat, Working Families\n0.425\n\n\n2018\nNY\n1\nLee M Zeldin\nConservative, Independence, Reform, Republican\nPerry Gershon\nDemocrat, Working Families\n0.460\n\n\n2018\nNY\n24\nJohn M Katko\nConservative, Independence, Reform, Republican\nDana Balter\nDemocrat, Women’s Equality, Working Families\n0.445\n\n\n2018\nNY\n27\nChris Collins\nConservative, Independence, Republican\nNathan D McMurray\nDemocrat, Women’s Equality, Working Families\n0.449\n\n\n2022\nNY\n4\nAnthony P D’Esposito\nRepublican, Conservative\nLaura A Gillen\nDemocrat\n0.470\n\n\n2022\nNY\n17\nMichael V Lawler\nRepublican, Conservative\nSean Patrick Maloney\nDemocrat, Working Families\n0.458\n\n\n2022\nNY\n22\nBrandon M Williams\nRepublican, Conservative\nFrancis Conole\nDemocrat\n0.485\n\n\n\n\n\n&gt; show the code\n\n\nfusion_elections &lt;- ELECTION_DATA_HOUSE |&gt; \n  filter(fusion_ticket == TRUE) |&gt; \n  mutate(percentage = candidatevotes / totalvotes, race_id = paste0(state_po, year, district))\n\nwinner_percentage &lt;- fusion_elections |&gt;\n  group_by(race_id, candidate) |&gt;\n  summarize(total_vote = sum(percentage)) |&gt;\n  ungroup()\n\nwinner_percentage &lt;- winner_percentage |&gt;\n  add_count(race_id, name = \"race_count\") |&gt;  \n  filter(race_count &gt; 1) |&gt;  \n  select(-race_count)\n  \nwinners_added &lt;- winner_percentage |&gt; \n  group_by(race_id) |&gt; \n  mutate(winner = (total_vote == max(total_vote))) |&gt;\n  ungroup()\n\nfusion_elections &lt;- fusion_elections |&gt; \n  inner_join(winners_added, by=c(\"race_id\", \"candidate\")) |&gt;\n  select(year, state, state_po, district, candidate, party, percentage, race_id, total_vote, winner)\n\nfusion_election_IDs &lt;- fusion_elections |&gt; \n  group_by(race_id) |&gt; \n  arrange(desc(percentage)) |&gt; \n  slice(1) |&gt;\n  filter(winner == FALSE) |&gt;\n  pull(race_id)\n\nfinal_data &lt;- fusion_elections |&gt; \n  filter(race_id %in% fusion_election_IDs & !is.na(party)) \n\nresult &lt;- final_data |&gt;\n  group_by(year, state, district) |&gt;\n  summarise(\n    winning_candidate = candidate[winner == TRUE],\n    winning_party = paste(unique(party[winner == TRUE]), collapse = \", \"),\n    losing_candidate = candidate[which.max((!winner) * percentage)],\n    losing_party = paste(unique(party[winner == FALSE]), collapse = \", \"),\n    highest_losing_percentage = max(percentage[winner == FALSE], na.rm = TRUE),\n    .groups = 'drop'\n  )\n\nresult &lt;- final_data |&gt;\n  group_by(year, state, district) |&gt;\n  summarise(\n    winning_candidate = unique(candidate[winner == TRUE]),\n    winning_party = paste(unique(party[winner == TRUE]), collapse = \", \"),\n    losing_candidate = unique(candidate[winner == FALSE]),\n    losing_party = paste(unique(party[winner == FALSE]), collapse = \", \"),\n    highest_losing_percentage = max(percentage[winner == FALSE], na.rm = TRUE),\n    .groups = 'drop'\n  )\n\nprint(result)"
  },
  {
    "objectID": "mp03.html#do-candidates-out-run-presidents",
    "href": "mp03.html#do-candidates-out-run-presidents",
    "title": "STA 9750 Fall 2024 - Jason Amey",
    "section": "Do candidates out run presidents?",
    "text": "Do candidates out run presidents?\n\n\n&gt; show the code\n\n\nelection_president_r_d &lt;- ELECTION_DATA_PRESIDENT |&gt; \n  filter(party_detailed == \"REPUBLICAN\" | party_detailed == \"DEMOCRAT\" )\n  \n\nsum_president_votes_r_d &lt;- election_president_r_d |&gt;\n  group_by(year, state, state_po, party_detailed, candidate) |&gt;\n  summarize(\n    candidate_votes = sum(candidatevotes, na.rm = TRUE),\n    total_votes = max(totalvotes, na.rm = TRUE)  # Assuming totalvotes is the same across rows for a state-year\n  ) |&gt;\n  ungroup() |&gt;\n  mutate(id = paste(year, state_po, party_detailed, sep = \"_\"), pres_percentage = candidate_votes / total_votes) |&gt;\n  rename(\n        pres_candidate_votes = candidate_votes, \n        pres_total_votes = total_votes\n        )\n\nhead(sum_president_votes_r_d)\n\nPRESIDENTIAL_YEARS &lt;- seq(1976, 2020, by = 4)\n\ntotal_votes_per_state &lt;- ELECTION_DATA_HOUSE |&gt;\n  filter(year %in% PRESIDENTIAL_YEARS & (party == \"REPUBLICAN\" | party == \"DEMOCRAT\")) |&gt;\n  group_by(year, state, state_po) |&gt;\n  summarize(total_votes = unique(totalvotes, na.rm = TRUE) |&gt; sum()) |&gt;\n  ungroup()\n\nsum_house_votes_r_d &lt;- ELECTION_DATA_HOUSE |&gt;\n  filter(party %in% c(\"DEMOCRAT\", \"REPUBLICAN\") & year %in% PRESIDENTIAL_YEARS) |&gt;\n  group_by(year, state, state_po, party) |&gt;\n  summarize(candidate_votes = sum(candidatevotes, na.rm = TRUE)) |&gt;\n  ungroup() |&gt;\n  left_join(total_votes_per_state, by = c(\"year\", \"state\", \"state_po\")) |&gt;\n  mutate(\n    id = paste(year, state_po, party, sep = \"_\"), \n    house_percentage = candidate_votes / total_votes\n  ) |&gt;\n  rename(\n    house_candidate_votes = candidate_votes,\n    house_total_votes = total_votes\n  ) |&gt;\n  select(id, house_candidate_votes, house_total_votes, house_percentage)\n\n\nstate_vote_counts &lt;- sum_president_votes_r_d |&gt;\n  left_join(sum_house_votes_r_d, by = \"id\") |&gt;\n  mutate(dif = house_percentage - pres_percentage)\n\n\n#vote diff between pres and house grouped by state\nstate_vote_diff_state_score &lt;- state_vote_counts |&gt; \n  group_by(state, party_detailed) |&gt; \n  summarize(state_dif = mean(dif, na.rm = TRUE))\n  \n\nView(state_vote_diff_state_score)\n\n#difference between parties for each election between house and president\nstate_vote_diff_pres_house &lt;- state_vote_counts |&gt; \n  group_by(year, party_detailed) |&gt; \n  summarize(avg_dif = mean(dif, na.rm = TRUE))\n\nView(state_vote_diff_pres_house)\n\nstate_vote_diff_pres\n\n\n\nSD &lt;- sd(state_vote_diff_pres_house$avg_dif)\nMEAN &lt;- mean(state_vote_diff_pres_house$avg_dif)\n\nstate_vote_diff_total_score &lt;- state_vote_diff_pres_house |&gt; \n  mutate(score = (avg_dif - MEAN) / SD) |&gt; \n  arrange(desc(score))\n\nView(state_vote_diff_total_score)"
  },
  {
    "objectID": "mp03.html#electoral-map",
    "href": "mp03.html#electoral-map",
    "title": "The Electoral College Dilemma: Tradition, Tension, and the Future of American Democracy",
    "section": "",
    "text": "Here is the map for the fateful 2000 Presidential Election. The election that inserted the Electoral College back into the national spotlight.\n\n\n\n&gt; show the code\n\n#### CHLOROPLETH FOR 2000 ELECTION ####\n\n# Calculate winner for each state for 2000 election and create winning_party field\npres_vote_2000 &lt;- ELECTION_DATA_PRESIDENT |&gt;\n  filter(year == 2000) |&gt;                             \n  group_by(state, candidate) |&gt;                       \n  summarise(total_votes = sum(candidatevotes, na.rm = TRUE)) |&gt;  \n  arrange(state, desc(total_votes)) |&gt;                 \n  slice_max(total_votes, n = 1, with_ties = FALSE) |&gt;\n  mutate(winning_party = ifelse(candidate == \"GORE, AL\", \"D\", \"R\"))\n\n# Load shapefile from 106th Congress - relevant for 2000 election\n&lt;!-- pres_shp_2000 &lt;- shp_from_zip(\"/mp03/congress_shapefiles/congress_106_shapefile.zip\") --&gt;\n\n\n# Load .shp file for congressional districts for 2000 \npres_shp_2000 &lt;- read_sf(\"data/mp03/congress_shapefiles/districtShapes/districts105.shp\")\n\n# Make sure STATENAME is clean and able to join\npres_shp_2000 &lt;- pres_shp_2000 |&gt;\n  mutate(STATENAME = str_to_upper(str_trim(STATENAME)))\n\n# Make sure state is clean and able to join\npres_vote_2000 &lt;- pres_vote_2000 |&gt;\n  mutate(state = str_to_upper(str_trim(state)))\n\n# Join data\npres_map_vote_2000_data &lt;- pres_shp_2000 |&gt;\n  left_join(pres_vote_2000, by = c(\"STATENAME\" = \"state\"))\n\n# Make geometries valid\npres_map_vote_2000_data_g &lt;- pres_map_vote_2000_data |&gt;\n  mutate(geometry = st_make_valid(geometry))\n\n# Create state boundaries\nstate_boundaries &lt;- pres_map_vote_2000_data_g |&gt;\n  group_by(STATENAME, winning_party) |&gt;\n  summarise(\n    geometry = st_union(geometry),\n    total_votes = sum(total_votes, na.rm = TRUE)\n  ) |&gt;\n  ungroup()\n\n# Find electoral college vote totals\nelectoral_votes_00 &lt;- ELECTION_DATA_HOUSE |&gt; \n  filter(year == 2000) |&gt;\n  group_by(year, state) |&gt;\n  summarize(votes = n_distinct(district) + 2) |&gt; \n  pivot_wider(names_from = year, values_from = votes)\n\n# Join electoral college votes\nstate_boundaries  &lt;-  state_boundaries |&gt;\n  left_join(electoral_votes_00, by = c(\"STATENAME\" = \"state\"))\n\n# Handle DC's NA\nstate_boundaries$`2000`[state_boundaries$STATENAME == \"DISTRICT OF COLUMBIA\" & is.na(state_boundaries$`2000`)] &lt;- 2\n \n# Remove NA values\ncleaned_data &lt;- state_boundaries |&gt;\n  filter(!is.na(geometry), !is.na(winning_party))\n\n# Define dc_location and assign geometry if needed\ndc_location &lt;- state_boundaries |&gt;\n  filter(STATENAME == \"DISTRICT OF COLUMBIA\")\n\n# Check if geometry exists and is not empty\nif (nrow(dc_location) == 0 || st_is_empty(dc_location$geometry)) {\n  # Manually assign coordinates if geometry is missing or empty\n  dc_location &lt;- st_sf(\n    STATENAME = \"DISTRICT OF COLUMBIA\",\n    winning_party = \"D\",\n    geometry = st_sfc(st_point(c(-77.0369, 38.9072)), crs = st_crs(state_boundaries))\n  )\n} else {\n  # Calculate centroid if geometry is available\n  dc_location &lt;- st_centroid(dc_location)\n}\n\n# Calculate centroids using st_point_on_surface to ensure within geometry\nstate_centroids &lt;- state_boundaries |&gt;\n  st_point_on_surface()\n\n# Ensure all layers have the same CRS\nstate_boundaries &lt;- st_transform(state_boundaries, crs = st_crs(pres_shp_2000))\nstate_centroids &lt;- st_transform(state_centroids, crs = st_crs(state_boundaries))\ndc_location &lt;- st_transform(dc_location, crs = st_crs(state_boundaries))\n\n# Plot the data\nggplot() +\n  geom_sf(data = cleaned_data, aes(fill = winning_party), color = NA) +\n  geom_sf_text(data = state_centroids, aes(label = `2000`), size = 3, color = \"black\") +\n  geom_sf(data = dc_location, shape = 8, size = 5, color = \"gold\") +  # Overlay star for DC\n  scale_fill_manual(values = c(\"D\" =  alpha(\"blue\", .7), \"R\" =  alpha(\"red\", .7))) + \n  coord_sf(xlim = c(-130, -60), ylim = c(24, 50)) +\n  labs(fill = \"Winning Party\") +\n  theme_minimal() +\n  theme(\n    legend.position = \"bottom\",\n    panel.background = element_blank(),    \n    axis.text = element_blank(),           \n    axis.ticks = element_blank(),\n    axis.title = element_blank(), \n    panel.grid.major = element_blank(),    \n    panel.grid.minor = element_blank()     \n  )\n\n#### FACETED HISTORY OF RECENT ELECTORAL COLLEGE COUNTS ####\n\n#### DOES NOT RENDER. CRASHES COMPUTER. ITS NOT IN PROJECT :-( ####\n\n# Clean up all gemoetries\ncleaned_data &lt;- pres_shp_2000 |&gt;\n  mutate(geometry = st_make_valid(geometry)) |&gt;\n  group_by(STATENAME) |&gt;\n  summarize(geometry = st_union(geometry), .groups = \"drop\")\n\n\n# Union geometries into states\nstates_shapes_2000 &lt;- cleaned_data |&gt;\n  select(STATENAME,geometry)|&gt;\n  group_by(STATENAME)|&gt;\n  summarize(geometry = st_union(geometry))|&gt;\n  filter(!is.na(geometry))\n\n# Cast geometries into a polygon\nus_states_sf &lt;- states_shapes_2000 |&gt;\n  filter(!is.na(geometry)) |&gt;\n  st_make_valid() |&gt; \n  st_cast(\"MULTIPOLYGON\") \n\n# Group by year and state and identify entry with most votes\npresidential_winners_by_state &lt;- ELECTION_DATA_PRESIDENT |&gt;\n  select(year, state, candidatevotes, candidate, party_simplified) |&gt;\n  group_by(year, state) |&gt;\n  slice_max(candidatevotes)\n\n# Join data\npresidentials_winners_combined_sf &lt;- presidential_winners_by_state |&gt;\n  select(year, state, party_simplified) |&gt;\n  left_join(us_states_sf|&gt;\n  select(STATENAME, geometry) |&gt;\n  mutate(STATENAME=toupper(STATENAME)),by=c(\"state\"=\"STATENAME\"))\n\n# Reduced Geometries\npresidentials_winners_combined_sf_t &lt;- presidentials_winners_combined_sf %&gt;%\n  mutate(geometry = st_simplify(geometry, dTolerance = 0.05))\n\n# Try without DC \npresidentials_winners_combined_sf_t &lt;- presidentials_winners_combined_sf_t |&gt;\n  filter(state != \"DISTRICT OF COLUMBIA\")\n\n# Plot Data (doesn't work)\nggplot(presidentials_winners_combined_sf_t |&gt; filter(year %in% c(1976, 1980))) +\n  geom_sf(aes(geometry = geometry, fill = party_simplified), color = \"white\") +\n  scale_fill_manual(values = c(\"DEMOCRAT\" = \"blue\", \"REPUBLICAN\" = \"red\")) +\n  coord_sf(xlim = c(-130, -60), ylim = c(24, 50)) +\n  labs(fill = \"Winning Party\") +\n  theme_minimal() +\n  theme(legend.position = \"bottom\") +\n  facet_wrap(~year)\nprint(\"ending\")"
  },
  {
    "objectID": "mp03.html#electoral-college-schemes",
    "href": "mp03.html#electoral-college-schemes",
    "title": "The Electoral College Dilemma: Tradition, Tension, and the Future of American Democracy",
    "section": "",
    "text": "The Electoral College has long been debated for its undemocratic nature, as it can allow a candidate to win the presidency without securing the popular vote, amplifying the influence of smaller or swing states over larger, non-competitive states. This occurs primarily due to the State-Wide Winner-Take-All method, where the candidate who wins the majority of votes in a state receives all of that state’s electoral votes, making individual votes in less competitive states less influential.\nThe United States Constitution does allow states to decide for themselves how they allocate their electoral votes. Here’s a brief overview of the different electoral vote allocation strategies and their political implications…\nState-Wide Winner-Take-All:\nCurrently used by most states, this approach awards all electoral votes to the candidate with the most votes in a state. While it simplifies outcomes, it can marginalize voters in states where one party has a strong majority, as votes for the minority party have no impact on the Electoral College outcome. This strategy focuses campaign efforts on swing states, leaving “safe” states largely ignored.\nDistrict-Wide Winner-Take-All + State-Wide “At Large” Votes:\nThis approach allocates one electoral vote per congressional district, awarded to the candidate who wins the district, with two additional votes (representing the Senate seats) awarded to the statewide winner. Adopted by Maine and Nebraska, it reflects more local preferences but may amplify the impact of gerrymandered districts, which can skew results within a state.\nState-Wide Proportional:\nIn this model, electoral votes are allocated proportionally based on the statewide vote. This approach provides a more representative outcome for each state, as candidates receive electoral votes in line with their actual support.\nNational Proportional:\nHere, electoral votes are allocated based on the candidates’ national popular vote percentages. This model best reflects the popular vote while maintaining the structure of the Electoral College."
  },
  {
    "objectID": "mp03.html#election-of-2000",
    "href": "mp03.html#election-of-2000",
    "title": "The Electoral College Dilemma: Tradition, Tension, and the Future of American Democracy",
    "section": "",
    "text": "electoral vote: 271\n\n\npopular vote: 50,456,002\n\n\npercentage: 47.9%\n\n\n\n\n\nelectoral vote: 266\n\n\npopular vote: 50,999,897\n\n\npercentage: 48.4%"
  },
  {
    "objectID": "mp03.html#election-of-2016",
    "href": "mp03.html#election-of-2016",
    "title": "The Electoral College Dilemma: Tradition, Tension, and the Future of American Democracy",
    "section": "",
    "text": "&gt; show the code\n\n#### STATE WIDE WINNER TAKE ALL ####\n\n# Create popular vote tabulations\npopular_vote_summary &lt;- ELECTION_DATA_PRESIDENT |&gt;\n  group_by(year, candidate) |&gt;\n  summarise(\n    popular_vote_count = sum(candidatevotes, na.rm = TRUE),           \n    total_votes_year = sum(totalvotes, na.rm = TRUE)                 \n  ) |&gt;\n  ungroup() |&gt;\n  mutate(\n    popular_vote_percentage = (popular_vote_count / total_votes_year) * 100   \n  ) |&gt;\n  select(year, candidate, popular_vote_count, popular_vote_percentage, total_votes_year) |&gt;\n  filter(popular_vote_percentage &gt; 4.9) |&gt;\n  arrange(year, desc(popular_vote_count))\n\n# Create electoral vote counts for each state in each presidential election\nelectoral_vote_counts &lt;- ELECTION_DATA_HOUSE |&gt;\n  filter(year %in% seq(1976, 2020, by = 4)) |&gt; \n  group_by(year, state) |&gt;\n  summarize(votes = n_distinct(district) + 2, .groups = \"drop\") \n\n# Create vector of years\nyears &lt;- unique(electoral_vote_counts$year)\n\n# Ensure Washington DC has 3 votes for each year\nelectoral_vote_counts &lt;- electoral_vote_counts |&gt;\n  bind_rows(\n    tibble(\n      year = years[!years %in% electoral_vote_counts$year[electoral_vote_counts$state == \"DISTRICT OF COLUMBIA\"]],\n      state = \"DISTRICT OF COLUMBIA\",\n      votes = 3\n    )\n  ) |&gt;\n  mutate(votes = ifelse(state == \"DISTRICT OF COLUMBIA\", 3, votes)) |&gt;\n  arrange(year, state)\n\n# Identify total votes, winning candidate and winning party\nstate_winner_take_all &lt;- ELECTION_DATA_PRESIDENT |&gt;  # \n  group_by(year, state) |&gt;             \n  filter(!is.na(candidate)) |&gt;        \n  summarise(\n    total_votes = sum(candidatevotes, na.rm = TRUE),\n    winner_candidate = candidate[which.max(candidatevotes)],\n    winner_party = party_detailed[which.max(candidatevotes)],\n    .groups = \"drop\"\n  )\n\n# Join the electoral vote counts to the state winner data\nstate_winner_with_votes &lt;- state_winner_take_all |&gt;\n  left_join(electoral_vote_counts, by = c(\"year\", \"state\"))\n\n# Handle Washington DC \nstate_winner_with_votes &lt;- state_winner_with_votes |&gt;\n  mutate(\n    state_abbr = ifelse(\n      state == \"District Of Columbia\", \"DC\",  \n      state.abb[match(state, state.name)]     \n    )\n  )\n\n# Function to Title Case and reformat names\nreformat_candidate_name &lt;- function(winner_candidate) {\n  name_parts &lt;- str_split(winner_candidate, \",\\\\s*\")[[1]]\n  formatted_name &lt;- str_to_title(paste(name_parts[2], name_parts[1]))\n  return(formatted_name)\n}\n\n# Reformat names\nstate_winner_with_votes &lt;- state_winner_with_votes |&gt;\n  mutate(\n    proper_name = sapply(winner_candidate, reformat_candidate_name), \n    winner_party = str_replace(winner_party, \"DEMOCRATIC\", \"DEMOCRAT\")\n    )\n\n# Re-do state abbreviations\nstate_winner_with_votes &lt;- state_winner_with_votes |&gt;\n  mutate(\n    state_cleaned = str_trim(str_to_title(state)), \n    state_abbr = ifelse(\n      state_cleaned == \"District Of Columbia\", \"DC\",  \n      state.abb[match(state_cleaned, state.name)]\n    )\n  ) |&gt;\n  select(-state_cleaned)  \n\n \n# Summarize electoral vote totals\ncalculate_ec_vote_totals &lt;- function(electoral_college_data, election_year) {\n  # Filter for the specific election year to avoid aggregating across years\n  df_year_requested &lt;- electoral_college_data |&gt;\n    filter(year == election_year)\n\n# Summarize total popular and electoral votes by candidate's proper name and party\nvote_summary &lt;- df_year_requested |&gt;\n  group_by(proper_name, winner_party) |&gt;\n  summarise(\n      ec_vote = sum(votes),\n      .groups = \"drop\"\n    )\n\n# Arrange by ec_vote in descending order to get the winners first\nvote_summary &lt;- vote_summary |&gt;\n  arrange(desc(ec_vote))\n\n  # Return the results as two named lists for first and second place candidates\n  list(\n    first_place = list(\n      candidate = vote_summary$proper_name[1],\n      party = vote_summary$winner_party[1],\n      ec_vote = vote_summary$ec_vote[1]\n    ),\n    second_place = list(\n      candidate = vote_summary$proper_name[2],\n      party = vote_summary$winner_party[2],\n      ec_vote = vote_summary$ec_vote[2]\n    )\n  )\n}\n\n# Summarize popular vote totals\ncalculate_popular_vote_totals &lt;- function(popular_vote_data, election_year) {\n  # Filter for the specified election year\n  df_year_requested &lt;- popular_vote_data |&gt;\n    filter(year == election_year)\n\n  # Summarize popular vote counts and percentages by candidate and party\n  vote_summary &lt;- df_year_requested |&gt;\n    group_by(candidate) |&gt;\n    summarise(\n      popular_vote_count = sum(popular_vote_count, na.rm = TRUE),\n      popular_vote_percentage = mean(popular_vote_percentage, na.rm = TRUE),\n      .groups = \"drop\"\n    ) |&gt;\n    arrange(desc(popular_vote_count))\n\n  # Return the results as a list with each candidate's information\n  list(\n    first_place = list(\n      candidate = vote_summary$candidate[1],\n      popular_vote_count = vote_summary$popular_vote_count[1],\n      popular_vote_percentage = vote_summary$popular_vote_percentage[1]\n    ),\n    second_place = list(\n      candidate = vote_summary$candidate[2],\n      popular_vote_count = vote_summary$popular_vote_count[2],\n      popular_vote_percentage = vote_summary$popular_vote_percentage[2]\n    )\n  )\n}\n\n# Function for winner take all report\nstate_winner_take_all &lt;- function(data_set, election_year, ec_summary_data) {\n  # Filter data for the requested election year\n  df_year_requested &lt;- data_set |&gt; \n    filter(year == election_year)\n  \n  # Extract information from the ec_summary_data\n  proper_name1 &lt;- ec_summary_data$first_place$candidate\n  party1 &lt;- ec_summary_data$first_place$party\n  ec_vote1 &lt;- ec_summary_data$first_place$ec_vote\n  \n  proper_name2 &lt;- ec_summary_data$second_place$candidate\n  party2 &lt;- ec_summary_data$second_place$party\n  ec_vote2 &lt;- ec_summary_data$second_place$ec_vote\n  \n  # Create custom legend text with candidate names, parties, popular votes, and electoral votes\n  legend_text &lt;- paste0(\n    toupper(proper_name1), \" (\", substr(party1, 1, 1), \")\\n\",\n    \"Electoral Votes: \", ec_vote1, \"\\n\",\n    toupper(proper_name2), \" (\", substr(party2, 1, 1), \")\\n\",\n    \"Electoral Votes: \", ec_vote2\n  )\n  \n  # Create the plot\n  ggplot(df_year_requested, aes(state = state_abbr, fill = winner_party)) +\n    statebins::geom_statebins(radius = grid::unit(0.1, \"cm\")) +\n    scale_fill_manual(values = c(\"DEMOCRAT\" = \"blue\", \"REPUBLICAN\" = \"red\"), name = \"Winner\") +\n    labs(\n      title = paste(\"US Electoral College Votes by State-Wide Winner-Take-All (\", election_year, \")\", sep = \"\"),\n      subtitle = legend_text\n    ) +\n    theme_minimal() +\n    theme(\n      legend.position = \"none\",\n      panel.background = element_blank(),\n      axis.text = element_blank(),\n      axis.ticks = element_blank(),\n      panel.grid = element_blank(),\n      plot.subtitle = element_text(color = \"black\")\n    )\n}\n\n# Call functions for plotting\nec_summary &lt;- calculate_ec_vote_totals(state_winner_with_votes, 2000)\npop_summary &lt;- calculate_popular_vote_totals(popular_vote_summary, 2000)\nstate_winner_take_all(state_winner_with_votes, 2000, ec_summary)\n\nec_summary &lt;- calculate_ec_vote_totals(state_winner_with_votes, 2000)\npop_summary &lt;- calculate_popular_vote_totals(popular_vote_summary, 2000)\nstate_winner_take_all(state_winner_with_votes, 2000, ec_summary)\n\n\n#### DISTRICT WIDE WINNTER TAKE ALL & STATE WIDE AT LARGE VOTES ####\n\n# Calculate district winners and add an at_large seat\ncalculate_district_winners_with_at_large &lt;- function(data) {\n  # Calculate district-level winners\n  district_winners &lt;- data |&gt;\n    group_by(year, state, state_po, district) |&gt;\n    filter(candidatevotes == max(candidatevotes)) |&gt;\n    summarise(\n      party = first(party),\n      candidate = first(candidate),\n      .groups = \"drop\"\n    ) |&gt;\n    mutate(district = as.character(district)) |&gt;\n    select(year, state, state_po, district, party)\n  \n  # Calculate at-large seats (2 votes) based on majority party in each state per year\n  at_large_winners &lt;- district_winners |&gt;\n    group_by(year, state, state_po) |&gt;\n    count(party, name = \"district_count\") |&gt;\n    slice_max(district_count, n = 1, with_ties = FALSE) |&gt;\n    mutate(\n      district = \"at_large\",\n      party = party\n    ) |&gt;\n    select(year, state, state_po, district, party)\n\n  # Combine district winners and at-large results\n  bind_rows(district_winners, at_large_winners)\n}\n\n# Sum all votes and percentages for each party for each year and each state\ncalculate_vote_totals_at_large &lt;- function(data) {\n  data |&gt;\n    mutate(votes = if_else(district == \"at_large\", 2, 1)) |&gt;\n    group_by(year, state, state_po, party) |&gt;\n    summarise(total_votes = sum(votes), .groups = \"drop\") |&gt;\n    group_by(year, state, state_po) |&gt;\n    mutate(total_state_votes = sum(total_votes)) |&gt;\n    mutate(win_percent = round((total_votes / total_state_votes), 4)) |&gt;\n    select(-total_state_votes) |&gt;\n    arrange(year, state, party) |&gt; \n    mutate(color = ifelse(party == \"DEMOCRAT\", alpha(\"blue\", win_percent), alpha(\"red\", win_percent)))\n}\n\n\n# First find winners for each district and the at large winner\ndistrict_winners_with_at_large &lt;- calculate_district_winners_with_at_large(ELECTION_DATA_HOUSE)\nec_total_at_large &lt;- calculate_vote_totals_at_large(district_winners_with_at_large) \n\n# Identify all the unique presidential winners\nunique_winners_al &lt;- state_winner_with_votes |&gt;\n  distinct(year, winner_party, proper_name) |&gt;\n  rename(\"party\" = \"winner_party\")\n\n# Add proper names to EC totals\nec_total_at_large &lt;- ec_total_at_large |&gt;\n  left_join(unique_winners_al, by = c(\"year\", \"party\")) \n\ntotal_votes_check &lt;- ec_total_at_large |&gt;\n  filter(year == 2016) |&gt; \n  summarise(total_electoral_votes = sum(total_votes))\n\n\nplot_electoral_votes &lt;- function(data, election_year) {\n  df_year_filtered &lt;- data |&gt;\n    filter(year == election_year) |&gt;\n    group_by(state, state_po) |&gt;\n    ungroup()\n  \n  total_votes_summary &lt;- df_year_filtered |&gt;\n    group_by(proper_name, party) |&gt;\n    summarise(total_votes = sum(total_votes), .groups = \"drop\") |&gt;\n    arrange(desc(total_votes))\n  print(total_votes_summary)\n  total_votes_list &lt;- split(total_votes_summary, seq(nrow(total_votes_summary)))\n  \n  # Manually referencing each element in total_votes_list\n  proper_name1 &lt;- total_votes_list[[1]]$proper_name\n  winner_party1 &lt;- total_votes_list[[1]]$party\n  total_votes1 &lt;- total_votes_list[[1]]$total_votes\n  \n  proper_name2 &lt;- total_votes_list[[2]]$proper_name\n  winner_party2 &lt;- total_votes_list[[2]]$party\n  total_votes2 &lt;- total_votes_list[[2]]$total_votes + 3\n  \n  # Format party abbreviations\n  party1 &lt;- ifelse(winner_party1 == \"DEMOCRAT\", \"(D)\", \"(R)\")\n  party2 &lt;- ifelse(winner_party2 == \"DEMOCRAT\", \"(D)\", \"(R)\")\n  \n  # Construct the formatted string using paste and the variables\n  output_string &lt;- paste(\n    toupper(proper_name1), party1, \"\\nElectoral Votes:\", total_votes1, \"\\n\",\n    toupper(proper_name2), party2, \"\\nElectoral Votes:\", total_votes2\n  )\n   output_string &lt;- sprintf(\n    \"%s %s\\nElectoral Votes: %d\\n%s %s\\nElectoral Votes: %d\",\n    toupper(proper_name1), party1, total_votes1,\n    toupper(proper_name2), party2, total_votes2\n    )\n    \n  # Create the plot\n  ggplot(df_year_filtered, aes(state = state_po, fill = color)) +\n    statebins::geom_statebins(radius = grid::unit(0.1, \"cm\")) +\n     scale_fill_identity() +\n    labs(\n      title = paste(\"US District-Wide Winner-Take-All + State-Wide “At Large” Votes (\", election_year, \")\", sep = \"\"),\n      subtitle = paste(\"Color intensity represents share of Electoral College Votes\\n\\n\",output_string, sep=\"\\n\")\n    ) +\n    theme_minimal() +\n    theme(\n      legend.position = \"right\",\n      panel.background = element_blank(),\n      axis.text = element_blank(),\n      axis.ticks = element_blank(),\n      panel.grid = element_blank(),\n      plot.subtitle = element_text(color = \"black\")\n    )\n}\n\n# Run plot\nplot_electoral_votes(ec_total_at_large, 2000)\n\n#### STATE WIDE PROPORTIONAL ####\n\nelecton_data_president_p &lt;- ELECTION_DATA_PRESIDENT |&gt; \n    mutate(party_detailed = if_else(party_detailed == \"DEMOCRATIC-FARMER-LABOR\", \"DEMOCRAT\", party_detailed)) |&gt;\n    filter(party_detailed == \"DEMOCRAT\" | party_detailed == \"REPUBLICAN\")\n\n# Get electoral votes for each state for each year\nelectoral_votes_by_state_p &lt;- ELECTION_DATA_HOUSE |&gt; \n  group_by(year, state, state_po) |&gt;\n  summarize(votes = n_distinct(district) + 2)\n\n# Calculate percentages \nstate_percentages_p &lt;- electon_data_president_p |&gt;\n  group_by(year, state, state_po, party_detailed) |&gt;\n  summarise(\n    candidate = first(candidate),\n    total_candidate_votes = sum(candidatevotes),\n    total_state_votes = first(totalvotes), \n    percentage = total_candidate_votes / total_state_votes\n  ) |&gt;\n  ungroup() |&gt;\n  select(year, state, state_po, candidate, party_detailed, percentage) |&gt;\n  group_by(year, state, state_po) |&gt;\n  mutate(winner = percentage == max(percentage)) |&gt;\n  ungroup()\n\n# Join percentages with votes\nstate_percentages_w_votes_p &lt;- state_percentages_p |&gt;\n  right_join(electoral_votes_by_state_p, by = c(\"year\", \"state\", \"state_po\")) |&gt;\n  rename(electoral_votes = votes)\n \n# Break up electoral votes won by percentages  \nstate_electoral_votes_p &lt;- state_percentages_w_votes_p |&gt;\n  group_by(year, state, state_po) |&gt;\n  mutate(\n    # Calculate electoral votes won by the winner (round up)\n    electoral_votes_won = ifelse(\n      winner,\n      ceiling(percentage * electoral_votes),\n      electoral_votes - ceiling(percentage[winner == TRUE] * electoral_votes)\n    )\n  ) |&gt;\n  mutate(percent_electoral_votes = round(electoral_votes_won / electoral_votes, 2)) |&gt;\n  mutate(color = ifelse(party_detailed == \"DEMOCRAT\", alpha(\"blue\", percent_electoral_votes), alpha(\"red\",             percent_electoral_votes))) |&gt;\n  ungroup()\n\n# Join proper names\nstate_electoral_votes_p &lt;- state_electoral_votes_p |&gt;\n  left_join(unique_winners_n, by = c(\"year\", \"party_detailed\")) \n  \nplot_electoral_votes &lt;- function(data, election_year) {\n  df_year_filtered &lt;- data |&gt;\n    filter(year == election_year) \n  \n  summary &lt;- df_year_filtered |&gt;\n    group_by(party_detailed, proper_name) |&gt;\n    summarise(total_electoral_votes_won = sum(electoral_votes_won, na.rm = TRUE)) |&gt;\n    ungroup()\n  print(summary)\n  total_votes_list &lt;- split(summary, seq(nrow(summary)))\n  print(total_votes_list)\n  proper_name1 &lt;- total_votes_list[[1]]$proper_name\n  winner_party1 &lt;- total_votes_list[[1]]$party_detailed\n  total_votes1 &lt;- total_votes_list[[1]]$total_electoral_votes_won + 3\n  \n  proper_name2 &lt;- total_votes_list[[2]]$proper_name\n  winner_party2 &lt;- total_votes_list[[2]]$party_detailed\n  total_votes2 &lt;- total_votes_list[[2]]$total_electoral_votes_won\n  \n  # Format party abbreviations\n  party1 &lt;- ifelse(winner_party1 == \"DEMOCRAT\", \"(D)\", \"(R)\")\n  party2 &lt;- ifelse(winner_party2 == \"DEMOCRAT\", \"(D)\", \"(R)\")\n  \n  # Construct the formatted string using paste and the variables\n  output_string &lt;- sprintf(\n  \"%s %s\\nElectoral Votes: %d\\n%s %s\\nElectoral Votes: %d\",\n  toupper(proper_name1), party1, total_votes1,\n  toupper(proper_name2), party2, total_votes2\n)\n  df_year_filtered &lt;- df_year_filtered |&gt; \n    filter(winner == TRUE)\n  # Create the plot\n  ggplot(df_year_filtered, aes(state = state_po, fill = color)) +\n    statebins::geom_statebins(radius = grid::unit(0.1, \"cm\")) +\n     scale_fill_identity() +\n    labs(\n      title = paste(\"United States Electoral College Votes by State-Wide Proportional (\", election_year, \")\", sep = \"\"),\n      subtitle = paste(\"Color intensity represents share of Electoral College Votes\\n\\n\", output_string, sep=\"\\n\")\n    ) +\n    theme_minimal() +\n    theme(\n      legend.position = \"right\",\n      panel.background = element_blank(),\n      axis.text = element_blank(),\n      axis.ticks = element_blank(),\n      panel.grid = element_blank(),\n      plot.subtitle = element_text(color = \"black\")\n    )\n}\n\n\nplot_electoral_votes(state_electoral_votes_p, 2000)\n\n#### NATIONAL VOTE PROPORTION ####\n\nelection_data_president_n &lt;- ELECTION_DATA_PRESIDENT |&gt; \n    mutate(party_detailed = if_else(party_detailed == \"DEMOCRATIC-FARMER-LABOR\", \"DEMOCRAT\", party_detailed)) |&gt;\n    filter(party_detailed == \"DEMOCRAT\" | party_detailed == \"REPUBLICAN\")\n\n# Get electoral votes for each state for each year\nelectoral_votes_by_state_n &lt;- ELECTION_DATA_HOUSE |&gt; \n  group_by(year, state, state_po) |&gt;\n  summarize(votes = n_distinct(district) + 2)\n\nstate_percentages_n &lt;- election_data_president_n |&gt;\n  group_by(year, party_detailed, candidate) |&gt;\n  summarise(\n    total_candidate_votes = sum(candidatevotes, na.rm = TRUE), # Total votes for the candidate across all states\n    total_year_votes = sum(totalvotes, na.rm = TRUE) # Total votes for the year across all states\n  ) |&gt;\n  ungroup() |&gt;\n  mutate(\n    percentage = total_candidate_votes / total_year_votes # Calculate percentage for the candidate across all states\n  ) |&gt;\n  select(year, candidate, party_detailed, total_candidate_votes, percentage) |&gt;\n  arrange(year, desc(percentage)) \n\n# Calculate the winner for each year\nstate_percentages_n &lt;- state_percentages_n |&gt;\n  group_by(year) |&gt;\n  mutate(winner = percentage == max(percentage)) |&gt;\n  ungroup()\n\nexpanded_data_n &lt;- state_percentages_n |&gt;\n  inner_join(\n    electoral_votes_by_state_n,\n    by = \"year\",\n    relationship = \"many-to-many\"\n  ) \n\nstate_electoral_votes_n &lt;- expanded_data_n |&gt;\n  group_by(year, state, state_po) |&gt;\n  mutate(\n  winner_votes = ceiling(percentage[winner == TRUE] * votes),\n  # Calculate electoral votes won by the winner (round up)\n  electoral_votes_won = ifelse(\n    winner,\n    winner_votes,\n    votes - winner_votes\n  )\n)\n \n# Identify all the unique presidential winners\nunique_winners_n &lt;- state_winner_with_votes |&gt;\n  distinct(year, winner_party, proper_name) |&gt; \n  rename(party_detailed = winner_party)\n\n# Add proper names\nstate_electoral_votes_n &lt;- state_electoral_votes_n |&gt;\n  left_join(unique_winners_n, by = c(\"year\", \"party_detailed\")) \n\n# Add colors\nstate_electoral_votes_n &lt;- state_electoral_votes_n |&gt;\n   mutate(color = ifelse(party_detailed == \"DEMOCRAT\", alpha(\"blue\", percentage), alpha(\"red\",             percentage)))\n\nplot_national_proportion &lt;- function(data, election_year) {\n  # Filter data for the specified election year\n  df_year_filtered &lt;- data |&gt;\n    filter(year == election_year)\n  print(df_year_filtered)\n  # Get summary for EC vote counts  \n  summary &lt;- df_year_filtered |&gt;\n    group_by(party_detailed, proper_name) |&gt;\n    summarise(total_electoral_votes_won = sum(electoral_votes_won, na.rm = TRUE)) |&gt;\n    ungroup()\n\n  # Break out into list for display\n  total_votes_list &lt;- split(summary, seq(nrow(summary)))\n\n  proper_name1 &lt;- total_votes_list[[1]]$proper_name\n  winner_party1 &lt;- total_votes_list[[1]]$party_detailed\n  total_votes1 &lt;- total_votes_list[[1]]$total_electoral_votes_won + 3\n  \n  proper_name2 &lt;- total_votes_list[[2]]$proper_name\n  winner_party2 &lt;- total_votes_list[[2]]$party_detailed\n  total_votes2 &lt;- total_votes_list[[2]]$total_electoral_votes_won\n  \n  # Format party abbreviations\n  party1 &lt;- ifelse(winner_party1 == \"DEMOCRAT\", \"(D)\", \"(R)\")\n  party2 &lt;- ifelse(winner_party2 == \"DEMOCRAT\", \"(D)\", \"(R)\")\n  \n  # Construct the formatted string using paste and the variables\n  output_string &lt;- sprintf(\n    \"%s %s\\nElectoral Votes: %d\\n%s %s\\nElectoral Votes: %d\",\n    toupper(proper_name1), party1, total_votes1,\n    toupper(proper_name2), party2, total_votes2\n    )\n  \n  # Create the plot\n  ggplot(df_year_filtered, aes(state = state_po, fill = color)) +\n    statebins::geom_statebins(radius = grid::unit(0.1, \"cm\")) +\n    scale_fill_identity() +\n    labs(\n      title = paste(\"United States Electoral College Votes by National Proportion (\", election_year, \")\", sep = \"\"),\n      subtitle = paste(\"Color intensity represents share of Electoral College Votes\\n\\n\", output_string,sep=\"\\n\")\n    ) +\n    theme_minimal() +\n    theme(\n      legend.position = \"right\",\n      panel.background = element_blank(),\n      axis.text = element_blank(),\n      axis.ticks = element_blank(),\n      panel.grid = element_blank(),\n      plot.subtitle = element_text(color = \"black\")\n    )\n}\n\n# Usage\nplot_national_proportion(state_electoral_votes_n, 2000)"
  },
  {
    "objectID": "mp03.html#high-positive-scores-for-democrats-1984-1980-1992",
    "href": "mp03.html#high-positive-scores-for-democrats-1984-1980-1992",
    "title": "The Electoral College Dilemma: Tradition, Tension, and the Future of American Democracy",
    "section": "",
    "text": "The Democratic Party shows substantial positive discrepancies in years like 1984, 1980, and 1992, suggesting that Democratic House candidates outperformed the Democratic Presidential candidate by a notable margin in these years. 1980 and 1984 reflect the transformative political strength of Ronald Reagan, arguably one of the most consequential Presidential figures of the last 50 years.11 In 1992, a strong third-party showing by Ross Perot may have influenced voting patterns, with many voters possibly splitting their votes between Perot and their local Democratic House Representatives."
  },
  {
    "objectID": "mp03.html#high-negative-scores-for-republicans-1988-1984-1976",
    "href": "mp03.html#high-negative-scores-for-republicans-1988-1984-1976",
    "title": "The Electoral College Dilemma: Tradition, Tension, and the Future of American Democracy",
    "section": "",
    "text": "In 1988, 1984, and 1976, Republicans have significant negative scores, suggesting that in these years, Republican House candidates underperformed relative to the Presidential candidate. This might indicate that the Presidential candidate was particularly appealing, drawing votes that House candidates could not capture as effectively.\nThis trend suggests that in certain election years, voters may have been inclined toward a Republican President but were more mixed in their support for Republicans in the House, as was the case in 1988 and 1984 years when the GOP ran strong candidates atop their tickets. The 1976 results are likely a reflection of broader voter disenchantment with the Republican Party post-Watergate in the ensuing years and the need to re-build their national stature among voters."
  },
  {
    "objectID": "mp03.html#low-discrepancy-years-near-zero-scores",
    "href": "mp03.html#low-discrepancy-years-near-zero-scores",
    "title": "The Electoral College Dilemma: Tradition, Tension, and the Future of American Democracy",
    "section": "",
    "text": "Years like 2004 (Democrat), 2000 (Republican), and 2012 (Republican) have scores close to zero, indicating minimal discrepancies between the public’s preference for President and the House within those years. In such years, voter alignment between Presidential and House races was more consistent, reflecting lower levels of split-ticket voting or greater alignment in perceived candidate appeal and party policies across both levels. These years most likely signaled the rise of growing polarization of the American electorate as seen in recent elections."
  },
  {
    "objectID": "mp03.html#recent-years-20082020",
    "href": "mp03.html#recent-years-20082020",
    "title": "The Electoral College Dilemma: Tradition, Tension, and the Future of American Democracy",
    "section": "",
    "text": "In recent years, such as 2008, 2016, and 2020, both parties show relatively low scores, suggesting less discrepancy in voter preferences between the House and Presidential candidates. This trend reflects growing political polarization, with fewer voters splitting their votes across parties. The increased partisan consistency among voters has led to a decline in split-ticket voting, a phenomenon that has been well-documented in studies on electoral polarization.12\n\n\n&gt; show the code\n\n\n# Remove 3rd party candidates from presidential data\nelection_president_r_d &lt;- ELECTION_DATA_PRESIDENT |&gt; \n  filter(party_detailed == \"REPUBLICAN\" | party_detailed == \"DEMOCRAT\" )\n  \n# Calculate total votes a presidential candidate received, total vote in race and create unique ID\nsum_president_votes_r_d &lt;- election_president_r_d |&gt;\n  group_by(year, state, state_po, party_detailed, candidate) |&gt;\n  summarize(\n    candidate_votes = sum(candidatevotes, na.rm = TRUE),\n    total_votes = max(totalvotes, na.rm = TRUE)  \n  ) |&gt;\n  ungroup() |&gt;\n  mutate(id = paste(year, state_po, party_detailed, sep = \"_\"), pres_percentage = candidate_votes / total_votes) |&gt;\n  rename(\n        pres_candidate_votes = candidate_votes, \n        pres_total_votes = total_votes\n        )\n\n# Vector for presidential election years\nPRESIDENTIAL_YEARS &lt;- seq(1976, 2020, by = 4)\n\n# Isolate house races that occured in presidential years and count votes for each state\ntotal_votes_per_state &lt;- ELECTION_DATA_HOUSE |&gt;\n  filter(year %in% PRESIDENTIAL_YEARS & (party == \"REPUBLICAN\" | party == \"DEMOCRAT\")) |&gt;\n  group_by(year, state, state_po) |&gt;\n  summarize(total_votes = unique(totalvotes, na.rm = TRUE) |&gt; sum()) |&gt;\n  ungroup()\n\n# Sum candidate votes, join total_votes_per_state and calculate percentage from total votes\nsum_house_votes_r_d &lt;- ELECTION_DATA_HOUSE |&gt;\n  filter(party %in% c(\"DEMOCRAT\", \"REPUBLICAN\") & year %in% PRESIDENTIAL_YEARS) |&gt;\n  group_by(year, state, state_po, party) |&gt;\n  summarize(candidate_votes = sum(candidatevotes, na.rm = TRUE)) |&gt;\n  ungroup() |&gt;\n  left_join(total_votes_per_state, by = c(\"year\", \"state\", \"state_po\")) |&gt;\n  mutate(\n    id = paste(year, state_po, party, sep = \"_\"), \n    house_percentage = candidate_votes / total_votes\n  ) |&gt;\n  rename(\n    house_candidate_votes = candidate_votes,\n    house_total_votes = total_votes\n  ) |&gt;\n  select(id, house_candidate_votes, house_total_votes, house_percentage)\n\n# Calculate differences from house races percentages and presidential races \nstate_vote_counts &lt;- sum_president_votes_r_d |&gt;\n  left_join(sum_house_votes_r_d, by = \"id\") |&gt;\n  mutate(dif = house_percentage - pres_percentage)\n\n# Group these differences by state\nstate_vote_diff_state_score &lt;- state_vote_counts |&gt; \n  group_by(state, party_detailed) |&gt; \n  summarize(state_dif = mean(dif, na.rm = TRUE))\n\n# Calculate differences by party\nstate_vote_diff_pres_house &lt;- state_vote_counts |&gt; \n  group_by(year, party_detailed) |&gt; \n  summarize(avg_dif = mean(dif, na.rm = TRUE))\n\n# Generate standardize numbers for comparisons\nSD &lt;- sd(state_vote_diff_pres_house$avg_dif)\nMEAN &lt;- mean(state_vote_diff_pres_house$avg_dif)\n\n# Create a score metric\nstate_vote_diff_total_score &lt;- state_vote_diff_pres_house |&gt; \n  mutate(score = (avg_dif - MEAN) / SD) |&gt; \n  arrange(desc(score))\n\n\n# Prepare data for plot\ndata &lt;- state_vote_diff_total_score |&gt;\n  select(Year = year, Party = party_detailed, Score = score) |&gt;\n  mutate(\n    Party = ifelse(Party == \"DEMOCRAT\", \"Democrat\", \"Republican\")\n  )\n\n# Chart differences in House vote vs. Presidental vote from 1976 - 2020\nggplot(data, aes(x = factor(Year), y = Score, fill = Party)) +\n  geom_bar(stat = \"identity\", position = \"dodge\", width = 0.7) +\n  scale_fill_manual(values = c(\"Democrat\" = \"blue\", \"Republican\" = \"red\")) +\n  labs(\n    title = \"Party Score by Year (1976 - 2020)\",\n    x = \"Year\",\n    y = \"Score\",\n    fill = \"Party\"\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    legend.position = \"top\"\n  )"
  },
  {
    "objectID": "mp03.html#footnotes",
    "href": "mp03.html#footnotes",
    "title": "The Electoral College Dilemma: Tradition, Tension, and the Future of American Democracy",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nMIT Election Data and Science Lab, 2017, “U.S. House 1976–2022”, https://doi.org/10.7910/DVN/IG0UN2, Harvard Dataverse, V13, UNF:6 /IVldA== [fileUNF]↩︎\nCD Maps, “The Database of Congressional Historical Shape Files,” https://cdmaps.polisci.ucla.edu/↩︎\nU.S. Census Bureau, “TIGER/Line Shapefiles,” https://www.census.gov/geographies/mapping-files/time-series/geo/tiger-line-file.html↩︎\nGlaeser, E. L., & Tobio, K. (2008). The rise of the sunbelt. Southern Economic Journal, 74(3), 609-643.↩︎\nNelson, P. B. (2005). Migration and the regional redistribution of nonearnings income in the United States: Metropolitan and nonmetropolitan perspectives from 1975 to 2000. Environment and Planning A, 37(9), 1613-1636.↩︎\nMooney, A. (n.d.). How states losing House seats decide which districts are cut. Mooney.house.gov. Retrieved November 13, 2024, from https://mooney.house.gov/how-states-losing-house-seats-decide-which-districts-are-cut/↩︎\nShapiro, B. [@benshapiro]. (2024, 11, 6). “Hey Democrats, I have some more unfortunate news for you. Here’s what the electoral map looks like..” Tweet. X. https://x.com/benshapiro/status/1854210993645297694↩︎\nHarvard Kennedy School Ash Center for Democratic Governance and Innovation. (n.d.). The Electoral College and our broken presidential election system. Harvard Kennedy School. Retrieved November 13, 2024, from https://ash.harvard.edu/articles/the-electoral-college-and-our-broken-presidential-election-system/↩︎\nProtect Democracy. (n.d.). Fusion voting explained. Protect Democracy. Retrieved November 12, 2024, from https://protectdemocracy.org/work/fusion-voting-explained/↩︎\nElectoral fusion in the United States. (n.d.). In Wikipedia. Retrieved November 11, 2024, from https://en.wikipedia.org/wiki/Electoral_fusion_in_the_United_States↩︎\nSmith, Robert C. “Ronald Reagan, Donald Trump, and the Future of the Republican Party and Conservatism in America.” American Political Thought 10.2 (2021): 283-289.↩︎\nAbramowitz, A. I. (2022). The Polarized American Electorate: The Rise of Partisan-Ideological Consistency and Its Consequences. Political Science Quarterly, 137(4), 645-674.↩︎\nPearson-Merkowitz, S., & Lang, C. (2016). The geographic polarization of American voters. The Geography Teacher, 13(3), 112-117.↩︎\nRodden, J. A. (2019). Why cities lose: The deep roots of the urban-rural political divide. Basic Books.↩︎\nEdwards, G. C. (2004). Why the electoral college is bad for America. Yale University Press.↩︎\nDahl, R. A. (2001). How democratic is the American Constitution? New Haven, Yale University Press.↩︎\nPew Research Center. (2024, September 25). Majority of Americans continue to favor moving away from Electoral College. Pew Research Center. Retrieved November 12, 2024, from https://www.pewresearch.org/short-reads/2024/09/25/majority-of-americans-continue-to-favor-moving-away-from-electoral-college/↩︎"
  },
  {
    "objectID": "mp03.html#how-has-the-electoral-college-changed-since-1976",
    "href": "mp03.html#how-has-the-electoral-college-changed-since-1976",
    "title": "The Electoral College Dilemma: Tradition, Tension, and the Future of American Democracy",
    "section": "",
    "text": "The past 40 years have seen dramatic demographic and economic shifts in the United States, with the “Sunbelt” region experiencing significant population growth. Factors such as warm climates, a lower cost of living and growing job opportunities have all contributed to this population transformation. Cities like Phoenix, Dallas, Houston, and Atlanta have expanded rapidly, becoming economic powerhouses that attract internal migration.4 This trend has boosted the political influence of the Sunbelt states, particularly in presidential elections, as their share of the Electoral College votes has grown in proportion to their population increases.\nIn contrast, the Northeast and Rust Belt states have faced steady population declines. The Rust Belt continues to grapple with the economic fallout from the decline in manufacturing5. The Northeast, once a densely populated region driving much of the nation’s political power, has also seen a slower growth rate due to higher costs of living and an unwelcome, cooler climate. States like New York, Ohio, Pennsylvania, and Michigan have all lost congressional seats6—and, by extension, Electoral College votes—in the face of a southward shift in national demographics.\nThe impact on the Electoral College reflects these changes, as the Sunbelt’s increasing population has translated into greater political clout. Every ten years, the U.S. Census triggers a reapportionment of congressional seats, redistributing the 435 seats in the House of Representatives—and thus Electoral College votes—based on population changes.\nThis dynamic remains topical as commentary last-week immediately following Donald Trump’s significant electoral victory led a popular Conservative commentator to remark on the conintued diminished influence of both the Rust Belt and the American North East, and its traditional bases of power among the Democratic Party7:\n\n\nWhat are the states to lose the most Electoral College votes since 1976?\n\nElectoral Vote Losses By State (1976 vs. 2022) \n\n\nState\n1976\n2022\nChange\n\n\n\n\nNew York\n41\n28\n-13\n\n\nOhio\n25\n17\n-8\n\n\nPennsylvania\n27\n19\n-8\n\n\nIllinois\n26\n19\n-7\n\n\nMichigan\n21\n15\n-6\n\n\n\n  What are the states to gain the most Electoral College votes since 1976?\n\nElectoral Vote Growth By State (1976 vs. 2022) \n\n\nState\n1976\n2022\nChange\n\n\n\n\nTexas\n26\n40\n14\n\n\nFlorida\n17\n30\n13\n\n\nCalifornia\n45\n54\n9\n\n\nArizona\n6\n11\n5\n\n\nGeorgia\n12\n16\n4\n\n\n\n  Despite the Sunbelt’s rising population and the corresponding increase in Electoral College votes, a paradox exists: many of these rapidly growing Sunbelt states lack the political clout associated with “swing states.”8\nIn the Electoral College, political influence often hinges not only on a state’s population, but on its competitiveness in presidential elections. States like Texas and Florida, though gaining in electoral votes, are often reliably partisan (both are heavily Republican), which can diminish the attention they receive compared to smaller yet more unpredictable states like Pennsylvania or Wisconsin.\nThis “swing state” phenomenon means that candidates prioritize states with narrower margins, where votes are likelier to tip the election, giving smaller, competitive states a unique power in the electoral process that even populous states in the Sunbelt do not always share.\n\n\n&gt;show the code\n\n\n# Get data for 1976 and 2022\nelectoral_votes_76_22 &lt;- ELECTION_DATA_HOUSE |&gt; \n  filter(year == 1976 | year == 2022 ) |&gt;\n  group_by(year, state) |&gt;\n  summarize(votes = n_distinct(district) + 2) |&gt; \n  pivot_wider(names_from = year, values_from = votes) |&gt;\n  mutate(change = `2022` - `1976`)\n\n# View states that have lost the most seats\nvote_data &lt;- electoral_votes_76_22 |&gt; \n  arrange(change)\n  \n# View states that have gained the most seats\nelectoral_votes_76_22 |&gt; \n  arrange(desc(change))\n  \n# Prepare map data and convert state names to match your data\nus_states &lt;- map_data(\"state\") |&gt;\n  mutate(region = toupper(region))\n\n# Join map data with your data on state names\nmap_data_combined &lt;- us_states |&gt;\n  left_join(vote_data, by = c(\"region\" = \"state\"))\n\n# Plot the heatmap\nggplot(map_data_combined, aes(long, lat, group = group, fill = change)) +\n  geom_polygon(color = \"white\") + \n  scale_fill_gradient2(low = \"blue\", mid = \"gray\", high = \"red\", midpoint = 0, \n                       name = \"Change in Seats\") +\n  coord_fixed(1.3) +\n  labs(title = \"Change in Congressional Seats (1976 to 2022)\", \n       subtitle = \"Positive values indicate gain in seats; negative values indicate loss\") +\n  theme_minimal() +\n  theme(\n    axis.text = element_blank(),\n    axis.title = element_blank(),   \n    axis.ticks = element_blank(),\n    panel.grid = element_blank(),\n    panel.background = element_blank()\n  )"
  },
  {
    "objectID": "mp03.html#the-fusion-phenomenon",
    "href": "mp03.html#the-fusion-phenomenon",
    "title": "The Electoral College Dilemma: Tradition, Tension, and the Future of American Democracy",
    "section": "",
    "text": "Fusion voting, also known as cross-endorsement, is an electoral practice that allows a candidate to appear on the ballot under multiple party lines, thereby consolidating votes from different political bases. This approach enables third parties to endorse a major-party candidate, allowing voters to support a candidate’s platform through the values or policies associated with a smaller, often more ideologically-focused party. In practice, fusion voting can increase a candidate’s visibility while empowering smaller parties to influence major-party agendas.9\nIn New York City, fusion voting originally began in the 1930’s as a strategy to challenge Tammany Hall. Since then, many fusion-enabled parties have become important fixtures in New York area politics. For one, The Working Families Party has frequently endorsed progressive Democratic candidates while giving voters an alternative way to support candidates who align with specific labor and social equity issues. Likewise, The Conservative Party line gives voters a direct voice to amplify their commitment to limited government and social conservatism. All told, the fusion approach has been unique in New York City’s local elections, shaping policy conversations and reinforcing the presence of alternative political values within a largely two-party system.10\n\nFusion Findings for NY Elections\n\n\n\n\n\n\n\n\n\n\n\n\nYear\nState\nDistrict\nWinner\nParty\nLoser\nParty\nHighest %\n\n\n\n\n1980\nNY\n3\nGregory W Carman\nConservative, Republican\nJerome A Ambro Jr\nDemocrat, Right To Life\n0.429\n\n\n1980\nNY\n6\nJohn LeBoutillier\nConservative, Republican, Right To Life\nLester L Wolff\nDemocrat, Liberal\n0.437\n\n\n1986\nNY\n27\nGeorge C Wortley\nConservative, Republican\nRosemary S Pooler\nDemocrat, Effective Congress\n0.483\n\n\n1994\nNY\n1\nMichael P Forbes\nConservative, Republican, Right To Life\nGeorge J Hochbrueckner\nDemocrat, Long Island First\n0.428\n\n\n1996\nNY\n1\nMichael P Forbes\nConservative, Independence, Republican, Right To Life\nNora L Bredes\nDemocrat, Save Medicare\n0.398\n\n\n1996\nNY\n30\nJack Quinn\nConservative, Freedom, Independence, Republican\nFrancis J Pordum\nDemocrat, Protect Seniors\n0.405\n\n\n2006\nNY\n25\nJames T Walsh\nConservative, Independence, Republican\nDan Maffei\nDemocrat, Working Families\n0.443\n\n\n2006\nNY\n29\nJohn R “Randy” Kuhl Jr\nConservative, Independence, Republican\nEric J Massa\nDemocrat, Working Families\n0.436\n\n\n2012\nNY\n27\nChris Collins\nConservative, Republican\nKathleen C Hochul\nDemocrat, Working Families\n0.425\n\n\n2018\nNY\n1\nLee M Zeldin\nConservative, Independence, Reform, Republican\nPerry Gershon\nDemocrat, Working Families\n0.460\n\n\n2018\nNY\n24\nJohn M Katko\nConservative, Independence, Reform, Republican\nDana Balter\nDemocrat, Women’s Equality, Working Families\n0.445\n\n\n2018\nNY\n27\nChris Collins\nConservative, Independence, Republican\nNathan D McMurray\nDemocrat, Women’s Equality, Working Families\n0.449\n\n\n2022\nNY\n4\nAnthony P D’Esposito\nRepublican, Conservative\nLaura A Gillen\nDemocrat\n0.470\n\n\n2022\nNY\n17\nMichael V Lawler\nRepublican, Conservative\nSean Patrick Maloney\nDemocrat, Working Families\n0.458\n\n\n2022\nNY\n22\nBrandon M Williams\nRepublican, Conservative\nFrancis Conole\nDemocrat\n0.485\n\n\n\n\n\n&gt; show the code\n\n\n# Filter House election data for fusion elections, calculate percentages and create unique ID\nfusion_elections &lt;- ELECTION_DATA_HOUSE |&gt; \n  filter(fusion_ticket == TRUE) |&gt; \n  mutate(percentage = candidatevotes / totalvotes, race_id = paste0(state_po, year, district))\n\n# Calculate total winnine percentage\nwinner_percentage &lt;- fusion_elections |&gt;\n  group_by(race_id, candidate) |&gt;\n  summarize(total_vote = sum(percentage)) |&gt;\n  ungroup()\n\n# Count races for a given ID and filter out only competitve races\nwinner_percentage &lt;- winner_percentage |&gt;\n  add_count(race_id, name = \"race_count\") |&gt;  \n  filter(race_count &gt; 1) |&gt;  \n  select(-race_count)\n  \n# Create boolean for variable name `winner`  \nwinners_added &lt;- winner_percentage |&gt; \n  group_by(race_id) |&gt; \n  mutate(winner = (total_vote == max(total_vote))) |&gt;\n  ungroup()\n\n# Join datasets\nfusion_elections &lt;- fusion_elections |&gt; \n  inner_join(winners_added, by=c(\"race_id\", \"candidate\")) |&gt;\n  select(year, state, state_po, district, candidate, party, percentage, race_id, total_vote, winner)\n\n# Identify individuals who recieved the highest single percentage, but lost race\nfusion_election_IDs &lt;- fusion_elections |&gt; \n  group_by(race_id) |&gt; \n  arrange(desc(percentage)) |&gt; \n  slice(1) |&gt;\n  filter(winner == FALSE) |&gt;\n  pull(race_id)\n\n# Recreate dataset with just unique elections with fusion winners (losers)\nfinal_data &lt;- fusion_elections |&gt; \n  filter(race_id %in% fusion_election_IDs & !is.na(party)) \n\n# Identify all the candidates and their parties in these unique fusion instances\nresult &lt;- final_data |&gt;\n  group_by(year, state, district) |&gt;\n  summarise(\n    winning_candidate = candidate[winner == TRUE],\n    winning_party = paste(unique(party[winner == TRUE]), collapse = \", \"),\n    losing_candidate = candidate[which.max((!winner) * percentage)],\n    losing_party = paste(unique(party[winner == FALSE]), collapse = \", \"),\n    highest_losing_percentage = max(percentage[winner == FALSE], na.rm = TRUE),\n    .groups = 'drop'\n  )\n\n# Print output for table formatting\nprint(result, n = 100)"
  },
  {
    "objectID": "mp03.html#house-vs.-presidential-candidate-support-in-u.s.-elections-examing-partisan-distinctions",
    "href": "mp03.html#house-vs.-presidential-candidate-support-in-u.s.-elections-examing-partisan-distinctions",
    "title": "The Electoral College Dilemma: Tradition, Tension, and the Future of American Democracy",
    "section": "",
    "text": "These scores represent the standardized differences in voter support between Democratic and Republican candidates in House versus Presidential elections for each election year. This examination represents whether in a given state and year, a party’s House candidates received a higher or lower percentage of votes than the party’s Presidential candidate, indicating voter preferences that may diverge between congressional and national races. The standardized score highlights years with especially strong or weak alignment between House and Presidential support. Positive scores indicate years when House candidates outperformed Presidential candidates, while negative scores suggest the opposite."
  },
  {
    "objectID": "mp03.html#house-vs.-presidential-candidate-support-in-recent-u.s.-elections-rising-partisanship",
    "href": "mp03.html#house-vs.-presidential-candidate-support-in-recent-u.s.-elections-rising-partisanship",
    "title": "The Electoral College Dilemma: Tradition, Tension, and the Future of American Democracy",
    "section": "",
    "text": "These scores represent the standardized differences in voter support between Democratic and Republican candidates in House versus Presidential elections for each election year. This examination represents whether in a given state and year, a party’s House candidates received a higher or lower percentage of votes than the party’s Presidential candidate, indicating voter preferences that may diverge between congressional and national races. The standardized score highlights years with especially strong or weak alignment between House and Presidential support. Positive scores indicate years when House candidates outperformed Presidential candidates, while negative scores suggest the opposite."
  },
  {
    "objectID": "mp03.html#house-vs.-presidential-candidate-support-in-recent-u.s",
    "href": "mp03.html#house-vs.-presidential-candidate-support-in-recent-u.s",
    "title": "The Electoral College Dilemma: Tradition, Tension, and the Future of American Democracy",
    "section": "",
    "text": "These scores represent the standardized differences in voter support between Democratic and Republican candidates in House versus Presidential elections for each election year. This examination represents whether in a given state and year a party’s House candidates received a higher or lower percentage of votes than the party’s Presidential candidate, indicating voter preferences that may diverge between congressional and national races. The standardized score highlights years with especially strong or weak alignment between House and Presidential support. Positive scores indicate years when House candidates outperformed Presidential candidates, while negative scores suggest the opposite."
  },
  {
    "objectID": "mp03.html#election-of-2000-george-w.-bush-v.-al-gore",
    "href": "mp03.html#election-of-2000-george-w.-bush-v.-al-gore",
    "title": "The Electoral College Dilemma: Tradition, Tension, and the Future of American Democracy",
    "section": "",
    "text": "The 2000 presidential election served as a stark reminder of the Electoral College’s pivotal role in determining the presidency, a mechanism many Americans were unfamiliar with until then. The race between George W. Bush and Al Gore hinged on a razor-thin vote margin in Florida, leading to a weeks-long recount and intense media scrutiny of obscure ballot-counting procedures introducing the country to the infamous “hanging chad.”\nUltimately the Supreme Court intervened in the recount, issuing a decision in Bush v. Gore that halted the Florida recount and awarded the state’s electoral votes to Bush. In a break from jurisprudence tradition, the Court explicitly declared that its ruling was intended solely for this case and was not meant to set legal precedent.\nWhile this contentious election spurred calls to reform or abolish the Electoral College no significant changes materialized, and the system remained unchanged.\n\n\n\n\nelectoral vote: 271\n\n\npopular vote: 50,456,002\n\n\npercentage: 47.9%\n\n\n\n\n\nelectoral vote: 266\n\n\npopular vote: 50,999,897\n\n\npercentage: 48.4%\n\n\n\n How would the election of 2000 played out under differing strategies of allocating electoral votes?"
  },
  {
    "objectID": "mp03.html#the-presidential-elections-of-2000-and-2016",
    "href": "mp03.html#the-presidential-elections-of-2000-and-2016",
    "title": "The Electoral College Dilemma: Tradition, Tension, and the Future of American Democracy",
    "section": "",
    "text": "The 2000 and 2016 elections offer compelling cases for examining competing methods of distributing electoral votes. In both instances, the Electoral College outcome diverged from the popular vote, with the presidential candidates who secured the majority of electoral votes not winning the national popular vote. These elections highlight the potential discrepancies within the Electoral College system and can shed light on whether alternative approaches might better align electoral outcomes with the popular will.\nAnalyzing these elections arguably offers the best insight into how different allocation methods could impact future presidential races and the broader democratic process."
  },
  {
    "objectID": "mp03.html#differing-means-of-allocating-electoral-college-votes",
    "href": "mp03.html#differing-means-of-allocating-electoral-college-votes",
    "title": "The Electoral College Dilemma: Tradition, Tension, and the Future of American Democracy",
    "section": "",
    "text": "The Electoral College has long been debated for its undemocratic nature as it can allow a candidate to win the presidency without securing the popular vote. In doing so, the Electoral College effectively amplifies the influence of smaller or swing states over larger, non-competitive states. This occurs due to the State-Wide Winner-Take-All method, where the candidate who wins the majority of votes in a state receives all of that state’s electoral votes, making individual votes in less competitive states less influential.\nBut states are not compelled to use the State-Wide Winner-Take-All method as the United States Constitution allows states to decide for themselves how they allocate their electoral votes.\nWhat follows is a brief overview of the different electoral vote allocation strategies and their political implications…\nState-Wide Winner-Take-All:\nCurrently used by most states, this approach awards all electoral votes to the candidate with the most votes in a state. While it simplifies outcomes, it can marginalize voters in states where one party has a strong majority, as votes for the minority party have no impact on the Electoral College outcome. This strategy focuses campaign efforts on swing states, leaving “safe” states largely ignored.\nDistrict-Wide Winner-Take-All + State-Wide “At Large” Votes:\nThis approach allocates one electoral vote per congressional district, awarded to the candidate who wins the district, with two additional votes (representing the Senate seats) awarded to the statewide winner. Adopted by Maine and Nebraska, it reflects more local preferences but may amplify the impact of gerrymandered districts, which can skew results within a state.\nState-Wide Proportional:\nIn this model, electoral votes are allocated proportionally based on the statewide vote. This approach provides a more representative outcome for each state, as candidates receive electoral votes in line with their actual support.\nNational Proportional:\nHere, electoral votes are allocated based on the candidates’ national popular vote percentages. This model reflects the popular vote while maintaining the structure of the Electoral College."
  },
  {
    "objectID": "mp03.html#the-election-of-2016-donald-j.-trump-v.-hillary-clinton",
    "href": "mp03.html#the-election-of-2016-donald-j.-trump-v.-hillary-clinton",
    "title": "The Electoral College Dilemma: Tradition, Tension, and the Future of American Democracy",
    "section": "",
    "text": "The 2016 election is regarded as one of the most consequential in recent memory. Its impact on American politics and society is still felt today. Widely expected to end in an easy victory for Hillary Clinton, the election shocked political experts and the nation at large when Donald Trump defied predictions and won.\nTrump’s unconventional, “gonzo” approach to politics upended traditional campaign norms and is seen as ushering in a new brand of political conservatism—one that marked a significant departure from the policies and style of traditional, staid Republican politics. This shift has shaped the direction of the Republican Party and redefined the political landscape, solidifying the 2016 election as an undeniably transformative moment in U.S. History.\nDonald Trump’s confrontational and unorthodox style as president only intensified public scrutiny of the Electoral College as he had won in 2016 despite losing the popular vote. His tumultuous administration brought scrutiny upon the U.S. Constitution and renewed calls for reform or even abolition of the Electoral College.\nHowever, despite this heightened debate surrounding the Trump Presidency, there was no meaningful progress toward changing the Electoral College. Consequently, the Electoral College remains unchanged even as public criticism reached new heights during the Trump Aministration.\n\n\n\n\nelectoral vote: 304\n\n\npopular vote: 62,984,828\n\n\npercentage: 46.1%\n\n\n\n\n\nelectoral vote: 227\n\n\npopular vote: 65,853,514\n\n\npercentage: 48.2%\n\n\n\n How would the election of 2016 played out under differing strategies of allocating electoral votes? \n   \n\n\n&gt; show the code\n\n#### STATE WIDE WINNER TAKE ALL ####\n\n# Create popular vote tabulations\npopular_vote_summary &lt;- ELECTION_DATA_PRESIDENT |&gt;\n  group_by(year, candidate) |&gt;\n  summarise(\n    popular_vote_count = sum(candidatevotes, na.rm = TRUE),           \n    total_votes_year = sum(totalvotes, na.rm = TRUE)                 \n  ) |&gt;\n  ungroup() |&gt;\n  mutate(\n    popular_vote_percentage = (popular_vote_count / total_votes_year) * 100   \n  ) |&gt;\n  select(year, candidate, popular_vote_count, popular_vote_percentage, total_votes_year) |&gt;\n  filter(popular_vote_percentage &gt; 4.9) |&gt;\n  arrange(year, desc(popular_vote_count))\n\n# Create electoral vote counts for each state in each presidential election\nelectoral_vote_counts &lt;- ELECTION_DATA_HOUSE |&gt;\n  filter(year %in% seq(1976, 2020, by = 4)) |&gt; \n  group_by(year, state) |&gt;\n  summarize(votes = n_distinct(district) + 2, .groups = \"drop\") \n\n# Create vector of years\nyears &lt;- unique(electoral_vote_counts$year)\n\n# Ensure Washington DC has 3 votes for each year\nelectoral_vote_counts &lt;- electoral_vote_counts |&gt;\n  bind_rows(\n    tibble(\n      year = years[!years %in% electoral_vote_counts$year[electoral_vote_counts$state == \"DISTRICT OF COLUMBIA\"]],\n      state = \"DISTRICT OF COLUMBIA\",\n      votes = 3\n    )\n  ) |&gt;\n  mutate(votes = ifelse(state == \"DISTRICT OF COLUMBIA\", 3, votes)) |&gt;\n  arrange(year, state)\n\n# Identify total votes, winning candidate and winning party\nstate_winner_take_all &lt;- ELECTION_DATA_PRESIDENT |&gt;  # \n  group_by(year, state) |&gt;             \n  filter(!is.na(candidate)) |&gt;        \n  summarise(\n    total_votes = sum(candidatevotes, na.rm = TRUE),\n    winner_candidate = candidate[which.max(candidatevotes)],\n    winner_party = party_detailed[which.max(candidatevotes)],\n    .groups = \"drop\"\n  )\n\n# Join the electoral vote counts to the state winner data\nstate_winner_with_votes &lt;- state_winner_take_all |&gt;\n  left_join(electoral_vote_counts, by = c(\"year\", \"state\"))\n\n# Handle Washington DC \nstate_winner_with_votes &lt;- state_winner_with_votes |&gt;\n  mutate(\n    state_abbr = ifelse(\n      state == \"District Of Columbia\", \"DC\",  \n      state.abb[match(state, state.name)]     \n    )\n  )\n\n# Function to Title Case and reformat names\nreformat_candidate_name &lt;- function(winner_candidate) {\n  name_parts &lt;- str_split(winner_candidate, \",\\\\s*\")[[1]]\n  formatted_name &lt;- str_to_title(paste(name_parts[2], name_parts[1]))\n  return(formatted_name)\n}\n\n# Reformat names\nstate_winner_with_votes &lt;- state_winner_with_votes |&gt;\n  mutate(\n    proper_name = sapply(winner_candidate, reformat_candidate_name), \n    winner_party = str_replace(winner_party, \"DEMOCRATIC\", \"DEMOCRAT\")\n    )\n\n# Re-do state abbreviations\nstate_winner_with_votes &lt;- state_winner_with_votes |&gt;\n  mutate(\n    state_cleaned = str_trim(str_to_title(state)), \n    state_abbr = ifelse(\n      state_cleaned == \"District Of Columbia\", \"DC\",  \n      state.abb[match(state_cleaned, state.name)]\n    )\n  ) |&gt;\n  select(-state_cleaned)  \n\n \n# Summarize electoral vote totals\ncalculate_ec_vote_totals &lt;- function(electoral_college_data, election_year) {\n  # Filter for the specific election year to avoid aggregating across years\n  df_year_requested &lt;- electoral_college_data |&gt;\n    filter(year == election_year)\n\n# Summarize total popular and electoral votes by candidate's proper name and party\nvote_summary &lt;- df_year_requested |&gt;\n  group_by(proper_name, winner_party) |&gt;\n  summarise(\n      ec_vote = sum(votes),\n      .groups = \"drop\"\n    )\n\n# Arrange by ec_vote in descending order to get the winners first\nvote_summary &lt;- vote_summary |&gt;\n  arrange(desc(ec_vote))\n\n  # Return the results as two named lists for first and second place candidates\n  list(\n    first_place = list(\n      candidate = vote_summary$proper_name[1],\n      party = vote_summary$winner_party[1],\n      ec_vote = vote_summary$ec_vote[1]\n    ),\n    second_place = list(\n      candidate = vote_summary$proper_name[2],\n      party = vote_summary$winner_party[2],\n      ec_vote = vote_summary$ec_vote[2]\n    )\n  )\n}\n\n# Summarize popular vote totals\ncalculate_popular_vote_totals &lt;- function(popular_vote_data, election_year) {\n  # Filter for the specified election year\n  df_year_requested &lt;- popular_vote_data |&gt;\n    filter(year == election_year)\n\n  # Summarize popular vote counts and percentages by candidate and party\n  vote_summary &lt;- df_year_requested |&gt;\n    group_by(candidate) |&gt;\n    summarise(\n      popular_vote_count = sum(popular_vote_count, na.rm = TRUE),\n      popular_vote_percentage = mean(popular_vote_percentage, na.rm = TRUE),\n      .groups = \"drop\"\n    ) |&gt;\n    arrange(desc(popular_vote_count))\n\n  # Return the results as a list with each candidate's information\n  list(\n    first_place = list(\n      candidate = vote_summary$candidate[1],\n      popular_vote_count = vote_summary$popular_vote_count[1],\n      popular_vote_percentage = vote_summary$popular_vote_percentage[1]\n    ),\n    second_place = list(\n      candidate = vote_summary$candidate[2],\n      popular_vote_count = vote_summary$popular_vote_count[2],\n      popular_vote_percentage = vote_summary$popular_vote_percentage[2]\n    )\n  )\n}\n\n# Function for winner take all report\nstate_winner_take_all &lt;- function(data_set, election_year, ec_summary_data) {\n  # Filter data for the requested election year\n  df_year_requested &lt;- data_set |&gt; \n    filter(year == election_year)\n  \n  # Extract information from the ec_summary_data\n  proper_name1 &lt;- ec_summary_data$first_place$candidate\n  party1 &lt;- ec_summary_data$first_place$party\n  ec_vote1 &lt;- ec_summary_data$first_place$ec_vote\n  \n  proper_name2 &lt;- ec_summary_data$second_place$candidate\n  party2 &lt;- ec_summary_data$second_place$party\n  ec_vote2 &lt;- ec_summary_data$second_place$ec_vote\n  \n  # Create custom legend text with candidate names, parties, popular votes, and electoral votes\n  legend_text &lt;- paste0(\n    toupper(proper_name1), \" (\", substr(party1, 1, 1), \")\\n\",\n    \"Electoral Votes: \", ec_vote1, \"\\n\",\n    toupper(proper_name2), \" (\", substr(party2, 1, 1), \")\\n\",\n    \"Electoral Votes: \", ec_vote2\n  )\n  \n  # Create the plot\n  ggplot(df_year_requested, aes(state = state_abbr, fill = winner_party)) +\n    statebins::geom_statebins(radius = grid::unit(0.1, \"cm\")) +\n    scale_fill_manual(values = c(\"DEMOCRAT\" = \"blue\", \"REPUBLICAN\" = \"red\"), name = \"Winner\") +\n    labs(\n      title = paste(\"US Electoral College Votes by State-Wide Winner-Take-All (\", election_year, \")\", sep = \"\"),\n      subtitle = legend_text\n    ) +\n    theme_minimal() +\n    theme(\n      legend.position = \"none\",\n      panel.background = element_blank(),\n      axis.text = element_blank(),\n      axis.ticks = element_blank(),\n      panel.grid = element_blank(),\n      plot.subtitle = element_text(color = \"black\")\n    )\n}\n\n# Call functions for plotting\nec_summary &lt;- calculate_ec_vote_totals(state_winner_with_votes, 2000)\npop_summary &lt;- calculate_popular_vote_totals(popular_vote_summary, 2000)\nstate_winner_take_all(state_winner_with_votes, 2000, ec_summary)\n\nec_summary &lt;- calculate_ec_vote_totals(state_winner_with_votes, 2000)\npop_summary &lt;- calculate_popular_vote_totals(popular_vote_summary, 2000)\nstate_winner_take_all(state_winner_with_votes, 2000, ec_summary)\n\n\n#### DISTRICT WIDE WINNTER TAKE ALL & STATE WIDE AT LARGE VOTES ####\n\n# Calculate district winners and add an at_large seat\ncalculate_district_winners_with_at_large &lt;- function(data) {\n  # Calculate district-level winners\n  district_winners &lt;- data |&gt;\n    group_by(year, state, state_po, district) |&gt;\n    filter(candidatevotes == max(candidatevotes)) |&gt;\n    summarise(\n      party = first(party),\n      candidate = first(candidate),\n      .groups = \"drop\"\n    ) |&gt;\n    mutate(district = as.character(district)) |&gt;\n    select(year, state, state_po, district, party)\n  \n  # Calculate at-large seats (2 votes) based on majority party in each state per year\n  at_large_winners &lt;- district_winners |&gt;\n    group_by(year, state, state_po) |&gt;\n    count(party, name = \"district_count\") |&gt;\n    slice_max(district_count, n = 1, with_ties = FALSE) |&gt;\n    mutate(\n      district = \"at_large\",\n      party = party\n    ) |&gt;\n    select(year, state, state_po, district, party)\n\n  # Combine district winners and at-large results\n  bind_rows(district_winners, at_large_winners)\n}\n\n# Sum all votes and percentages for each party for each year and each state\ncalculate_vote_totals_at_large &lt;- function(data) {\n  data |&gt;\n    mutate(votes = if_else(district == \"at_large\", 2, 1)) |&gt;\n    group_by(year, state, state_po, party) |&gt;\n    summarise(total_votes = sum(votes), .groups = \"drop\") |&gt;\n    group_by(year, state, state_po) |&gt;\n    mutate(total_state_votes = sum(total_votes)) |&gt;\n    mutate(win_percent = round((total_votes / total_state_votes), 4)) |&gt;\n    select(-total_state_votes) |&gt;\n    arrange(year, state, party) |&gt; \n    mutate(color = ifelse(party == \"DEMOCRAT\", alpha(\"blue\", win_percent), alpha(\"red\", win_percent)))\n}\n\n\n# First find winners for each district and the at large winner\ndistrict_winners_with_at_large &lt;- calculate_district_winners_with_at_large(ELECTION_DATA_HOUSE)\nec_total_at_large &lt;- calculate_vote_totals_at_large(district_winners_with_at_large) \n\n# Identify all the unique presidential winners\nunique_winners_al &lt;- state_winner_with_votes |&gt;\n  distinct(year, winner_party, proper_name) |&gt;\n  rename(\"party\" = \"winner_party\")\n\n# Add proper names to EC totals\nec_total_at_large &lt;- ec_total_at_large |&gt;\n  left_join(unique_winners_al, by = c(\"year\", \"party\")) \n\ntotal_votes_check &lt;- ec_total_at_large |&gt;\n  filter(year == 2016) |&gt; \n  summarise(total_electoral_votes = sum(total_votes))\n\n\nplot_electoral_votes &lt;- function(data, election_year) {\n  df_year_filtered &lt;- data |&gt;\n    filter(year == election_year) |&gt;\n    group_by(state, state_po) |&gt;\n    ungroup()\n  \n  total_votes_summary &lt;- df_year_filtered |&gt;\n    group_by(proper_name, party) |&gt;\n    summarise(total_votes = sum(total_votes), .groups = \"drop\") |&gt;\n    arrange(desc(total_votes))\n  print(total_votes_summary)\n  total_votes_list &lt;- split(total_votes_summary, seq(nrow(total_votes_summary)))\n  \n  # Manually referencing each element in total_votes_list\n  proper_name1 &lt;- total_votes_list[[1]]$proper_name\n  winner_party1 &lt;- total_votes_list[[1]]$party\n  total_votes1 &lt;- total_votes_list[[1]]$total_votes\n  \n  proper_name2 &lt;- total_votes_list[[2]]$proper_name\n  winner_party2 &lt;- total_votes_list[[2]]$party\n  total_votes2 &lt;- total_votes_list[[2]]$total_votes + 3\n  \n  # Format party abbreviations\n  party1 &lt;- ifelse(winner_party1 == \"DEMOCRAT\", \"(D)\", \"(R)\")\n  party2 &lt;- ifelse(winner_party2 == \"DEMOCRAT\", \"(D)\", \"(R)\")\n  \n  # Construct the formatted string using paste and the variables\n  output_string &lt;- paste(\n    toupper(proper_name1), party1, \"\\nElectoral Votes:\", total_votes1, \"\\n\",\n    toupper(proper_name2), party2, \"\\nElectoral Votes:\", total_votes2\n  )\n   output_string &lt;- sprintf(\n    \"%s %s\\nElectoral Votes: %d\\n%s %s\\nElectoral Votes: %d\",\n    toupper(proper_name1), party1, total_votes1,\n    toupper(proper_name2), party2, total_votes2\n    )\n    \n  # Create the plot\n  ggplot(df_year_filtered, aes(state = state_po, fill = color)) +\n    statebins::geom_statebins(radius = grid::unit(0.1, \"cm\")) +\n     scale_fill_identity() +\n    labs(\n      title = paste(\"US District-Wide Winner-Take-All + State-Wide “At Large” Votes (\", election_year, \")\", sep = \"\"),\n      subtitle = paste(\"Color intensity represents share of Electoral College Votes\\n\\n\",output_string, sep=\"\\n\")\n    ) +\n    theme_minimal() +\n    theme(\n      legend.position = \"right\",\n      panel.background = element_blank(),\n      axis.text = element_blank(),\n      axis.ticks = element_blank(),\n      panel.grid = element_blank(),\n      plot.subtitle = element_text(color = \"black\")\n    )\n}\n\n# Run plot\nplot_electoral_votes(ec_total_at_large, 2000)\n\n#### STATE WIDE PROPORTIONAL ####\n\nelecton_data_president_p &lt;- ELECTION_DATA_PRESIDENT |&gt; \n    mutate(party_detailed = if_else(party_detailed == \"DEMOCRATIC-FARMER-LABOR\", \"DEMOCRAT\", party_detailed)) |&gt;\n    filter(party_detailed == \"DEMOCRAT\" | party_detailed == \"REPUBLICAN\")\n\n# Get electoral votes for each state for each year\nelectoral_votes_by_state_p &lt;- ELECTION_DATA_HOUSE |&gt; \n  group_by(year, state, state_po) |&gt;\n  summarize(votes = n_distinct(district) + 2)\n\n# Calculate percentages \nstate_percentages_p &lt;- electon_data_president_p |&gt;\n  group_by(year, state, state_po, party_detailed) |&gt;\n  summarise(\n    candidate = first(candidate),\n    total_candidate_votes = sum(candidatevotes),\n    total_state_votes = first(totalvotes), \n    percentage = total_candidate_votes / total_state_votes\n  ) |&gt;\n  ungroup() |&gt;\n  select(year, state, state_po, candidate, party_detailed, percentage) |&gt;\n  group_by(year, state, state_po) |&gt;\n  mutate(winner = percentage == max(percentage)) |&gt;\n  ungroup()\n\n# Join percentages with votes\nstate_percentages_w_votes_p &lt;- state_percentages_p |&gt;\n  right_join(electoral_votes_by_state_p, by = c(\"year\", \"state\", \"state_po\")) |&gt;\n  rename(electoral_votes = votes)\n \n# Break up electoral votes won by percentages  \nstate_electoral_votes_p &lt;- state_percentages_w_votes_p |&gt;\n  group_by(year, state, state_po) |&gt;\n  mutate(\n    # Calculate electoral votes won by the winner (round up)\n    electoral_votes_won = ifelse(\n      winner,\n      ceiling(percentage * electoral_votes),\n      electoral_votes - ceiling(percentage[winner == TRUE] * electoral_votes)\n    )\n  ) |&gt;\n  mutate(percent_electoral_votes = round(electoral_votes_won / electoral_votes, 2)) |&gt;\n  mutate(color = ifelse(party_detailed == \"DEMOCRAT\", alpha(\"blue\", percent_electoral_votes), alpha(\"red\",             percent_electoral_votes))) |&gt;\n  ungroup()\n\n# Join proper names\nstate_electoral_votes_p &lt;- state_electoral_votes_p |&gt;\n  left_join(unique_winners_n, by = c(\"year\", \"party_detailed\")) \n  \nplot_electoral_votes &lt;- function(data, election_year) {\n  df_year_filtered &lt;- data |&gt;\n    filter(year == election_year) \n  \n  summary &lt;- df_year_filtered |&gt;\n    group_by(party_detailed, proper_name) |&gt;\n    summarise(total_electoral_votes_won = sum(electoral_votes_won, na.rm = TRUE)) |&gt;\n    ungroup()\n  print(summary)\n  total_votes_list &lt;- split(summary, seq(nrow(summary)))\n  print(total_votes_list)\n  proper_name1 &lt;- total_votes_list[[1]]$proper_name\n  winner_party1 &lt;- total_votes_list[[1]]$party_detailed\n  total_votes1 &lt;- total_votes_list[[1]]$total_electoral_votes_won + 3\n  \n  proper_name2 &lt;- total_votes_list[[2]]$proper_name\n  winner_party2 &lt;- total_votes_list[[2]]$party_detailed\n  total_votes2 &lt;- total_votes_list[[2]]$total_electoral_votes_won\n  \n  # Format party abbreviations\n  party1 &lt;- ifelse(winner_party1 == \"DEMOCRAT\", \"(D)\", \"(R)\")\n  party2 &lt;- ifelse(winner_party2 == \"DEMOCRAT\", \"(D)\", \"(R)\")\n  \n  # Construct the formatted string using paste and the variables\n  output_string &lt;- sprintf(\n  \"%s %s\\nElectoral Votes: %d\\n%s %s\\nElectoral Votes: %d\",\n  toupper(proper_name1), party1, total_votes1,\n  toupper(proper_name2), party2, total_votes2\n)\n  df_year_filtered &lt;- df_year_filtered |&gt; \n    filter(winner == TRUE)\n  # Create the plot\n  ggplot(df_year_filtered, aes(state = state_po, fill = color)) +\n    statebins::geom_statebins(radius = grid::unit(0.1, \"cm\")) +\n     scale_fill_identity() +\n    labs(\n      title = paste(\"United States Electoral College Votes by State-Wide Proportional (\", election_year, \")\", sep = \"\"),\n      subtitle = paste(\"Color intensity represents share of Electoral College Votes\\n\\n\", output_string, sep=\"\\n\")\n    ) +\n    theme_minimal() +\n    theme(\n      legend.position = \"right\",\n      panel.background = element_blank(),\n      axis.text = element_blank(),\n      axis.ticks = element_blank(),\n      panel.grid = element_blank(),\n      plot.subtitle = element_text(color = \"black\")\n    )\n}\n\n# Plot the data\nplot_electoral_votes(state_electoral_votes_p, 2000)\n\n#### NATIONAL VOTE PROPORTION ####\n\nelection_data_president_n &lt;- ELECTION_DATA_PRESIDENT |&gt; \n    mutate(party_detailed = if_else(party_detailed == \"DEMOCRATIC-FARMER-LABOR\", \"DEMOCRAT\", party_detailed)) |&gt;\n    filter(party_detailed == \"DEMOCRAT\" | party_detailed == \"REPUBLICAN\")\n\n# Get electoral votes for each state for each year\nelectoral_votes_by_state_n &lt;- ELECTION_DATA_HOUSE |&gt; \n  group_by(year, state, state_po) |&gt;\n  summarize(votes = n_distinct(district) + 2)\n\nstate_percentages_n &lt;- election_data_president_n |&gt;\n  group_by(year, party_detailed, candidate) |&gt;\n  summarise(\n    total_candidate_votes = sum(candidatevotes, na.rm = TRUE), # Total votes for the candidate across all states\n    total_year_votes = sum(totalvotes, na.rm = TRUE) # Total votes for the year across all states\n  ) |&gt;\n  ungroup() |&gt;\n  mutate(\n    percentage = total_candidate_votes / total_year_votes # Calculate percentage for the candidate across all states\n  ) |&gt;\n  select(year, candidate, party_detailed, total_candidate_votes, percentage) |&gt;\n  arrange(year, desc(percentage)) \n\n# Calculate the winner for each year\nstate_percentages_n &lt;- state_percentages_n |&gt;\n  group_by(year) |&gt;\n  mutate(winner = percentage == max(percentage)) |&gt;\n  ungroup()\n\nexpanded_data_n &lt;- state_percentages_n |&gt;\n  inner_join(\n    electoral_votes_by_state_n,\n    by = \"year\",\n    relationship = \"many-to-many\"\n  ) \n\nstate_electoral_votes_n &lt;- expanded_data_n |&gt;\n  group_by(year, state, state_po) |&gt;\n  mutate(\n  winner_votes = ceiling(percentage[winner == TRUE] * votes),\n  # Calculate electoral votes won by the winner (round up)\n  electoral_votes_won = ifelse(\n    winner,\n    winner_votes,\n    votes - winner_votes\n  )\n)\n \n# Identify all the unique presidential winners\nunique_winners_n &lt;- state_winner_with_votes |&gt;\n  distinct(year, winner_party, proper_name) |&gt; \n  rename(party_detailed = winner_party)\n\n# Add proper names\nstate_electoral_votes_n &lt;- state_electoral_votes_n |&gt;\n  left_join(unique_winners_n, by = c(\"year\", \"party_detailed\")) \n\n# Add colors\nstate_electoral_votes_n &lt;- state_electoral_votes_n |&gt;\n   mutate(color = ifelse(party_detailed == \"DEMOCRAT\", alpha(\"blue\", percentage), alpha(\"red\",             percentage)))\n\nplot_national_proportion &lt;- function(data, election_year) {\n  # Filter data for the specified election year\n  df_year_filtered &lt;- data |&gt;\n    filter(year == election_year)\n  print(df_year_filtered)\n  # Get summary for EC vote counts  \n  summary &lt;- df_year_filtered |&gt;\n    group_by(party_detailed, proper_name) |&gt;\n    summarise(total_electoral_votes_won = sum(electoral_votes_won, na.rm = TRUE)) |&gt;\n    ungroup()\n\n  # Break out into list for display\n  total_votes_list &lt;- split(summary, seq(nrow(summary)))\n\n  proper_name1 &lt;- total_votes_list[[1]]$proper_name\n  winner_party1 &lt;- total_votes_list[[1]]$party_detailed\n  total_votes1 &lt;- total_votes_list[[1]]$total_electoral_votes_won + 3\n  \n  proper_name2 &lt;- total_votes_list[[2]]$proper_name\n  winner_party2 &lt;- total_votes_list[[2]]$party_detailed\n  total_votes2 &lt;- total_votes_list[[2]]$total_electoral_votes_won\n  \n  # Format party abbreviations\n  party1 &lt;- ifelse(winner_party1 == \"DEMOCRAT\", \"(D)\", \"(R)\")\n  party2 &lt;- ifelse(winner_party2 == \"DEMOCRAT\", \"(D)\", \"(R)\")\n  \n  # Construct the formatted string using paste and the variables\n  output_string &lt;- sprintf(\n    \"%s %s\\nElectoral Votes: %d\\n%s %s\\nElectoral Votes: %d\",\n    toupper(proper_name1), party1, total_votes1,\n    toupper(proper_name2), party2, total_votes2\n    )\n  \n  # Create the plot\n  ggplot(df_year_filtered, aes(state = state_po, fill = color)) +\n    statebins::geom_statebins(radius = grid::unit(0.1, \"cm\")) +\n    scale_fill_identity() +\n    labs(\n      title = paste(\"United States Electoral College Votes by National Proportion (\", election_year, \")\", sep = \"\"),\n      subtitle = paste(\"Color intensity represents share of Electoral College Votes\\n\\n\", output_string,sep=\"\\n\")\n    ) +\n    theme_minimal() +\n    theme(\n      legend.position = \"right\",\n      panel.background = element_blank(),\n      axis.text = element_blank(),\n      axis.ticks = element_blank(),\n      panel.grid = element_blank(),\n      plot.subtitle = element_text(color = \"black\")\n    )\n}\n\n# Plot the data\nplot_national_proportion(state_electoral_votes_n, 2000)\n\n\ndata &lt;- data.frame(\n  system = c(\"State Winner Take All\", \"District Winner + At Large\", \"State Wide Proportional\", \"National Proportional\"),\n  percentage = c(0.4962, 0.4665, 0.4869, 0.52)\n)\n\n# Plot\nggplot(data, aes(x = system, y = percentage)) +\n  geom_point(shape = 21, color = \"black\", fill = \"dodgerblue\", size=8) +\n  geom_hline(yintercept = 0.5, linetype = \"dashed\", color = \"red\") +\n  scale_y_continuous(limits = c(0.42, 0.53), breaks = seq(0.42, 0.55, by = 0.01)) +\n  labs(\n    title = \"Do any Electoral Systems Exceed 50% for the 2000 Election?\",\n    x = \"Electoral System\",\n    y = \"Percentage\",\n    size = \"Distance from 50%\"\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    legend.position = \"right\"\n  )"
  },
  {
    "objectID": "mp03.html#conclusions",
    "href": "mp03.html#conclusions",
    "title": "The Electoral College Dilemma: Tradition, Tension, and the Future of American Democracy",
    "section": "",
    "text": "The Electoral College system inherently disadvantages densely concentrated urban populations due to geographic sorting, where large numbers of voters in cities are “wasted” under the current allocation methods. This effect is especially pronounced in the State-Wide Winner-Take-All and District-Wide Winner-Take-All + At-Large systems, where urban votes are overshadowed by more spread-out rural and suburban voters. Even with a State-Wide Proportional approach, the dispersed nature of electoral votes dilutes the power of high-population centers.6\nThis dynamic reflects the original pastoral leanings of certain Founding Fathers, who were wary of urban centers and their concentrated political influence. Many founders idealized a nation of independent, rural landowners and saw the Electoral College as a mechanism to balance the interests of these pastoral areas against growing urban centers.7 Consequently, modern calls for Electoral College reform often stem from this persistent tension between rural and urban representation.\nCritics of the Electoral College, such as historian George C. Edwards III, argue that the system introduces a significant “democratic deficit” by allowing a candidate to win the presidency without securing the popular vote. Edwards suggests that this mechanism distorts democratic representation, disproportionately empowering certain states and demographic groups at the expense of others, and thus subverting the principle of equal representation.8\nThese findings are in line with the thoughts of Robert A. Dahl, widely regarded as one of the United States’ preeminent authoritie on democratic theory and the American Constitution.\nIn How Democratic Is the American Constitution? Dahl critically examines the Electoral College and its democratic shortcomings. He too recounts the 2000 election, where a candidate with fewer popular votes won, and traces this anomaly to the original confusion and compromises of the Framers. They established the Electoral College out of desperation after rejecting other methods, prioritizing insulation from popular choice and concern over “cabal and corruption.”9\nThe Electoral College is deeply rooted in an anti-democratic framework. Built to balance regional influence rather than to represent the popular will, the Electoral College was crafted with significant limitations to prevent it from reflecting a true “one person, one vote” standard. Its structural barriers maken it impossible to align with the democratic values most champion today.\nIn contrast, modern American political culture is firmly grounded in the principle of equal representation, where each vote should carry equal weight. Most Americans believe strongly in “one person, one vote” and would find it jarring, even offensive, for any politician to openly assert that some votes should count more than others.\nYet by supporting the Electoral College, we tacitly accept this inequality, promoting the illusion that it’s anything other than an outdated system that distorts minority political power.\nGiven this context, the purple shading on the national proportion maps above best reflect the most equitable spirit of “one person, one vote,” highlighting how popular will could be represented more faithfully. If the Electoral College must be preserved, such a proportional approach would align more closely with our democratic values and national political culture, offering a way forward that respects the ideal of equal voter influence across the country.\nAs such, if were to keep the Electoral College, we should adopt the National Proportion method for allocating electoral votes and the delegates who chose our nation’s chief executive."
  },
  {
    "objectID": "mp03.html#electora-map-for-the-2000-election",
    "href": "mp03.html#electora-map-for-the-2000-election",
    "title": "The Electoral College Dilemma: Tradition, Tension, and the Future of American Democracy",
    "section": "",
    "text": "Here is the map for the fateful 2000 Presidential Election, the election that re-centered the Electoral College back into the national spotlight.\n\n\n\n&gt; show the code\n\n#### CHLOROPLETH FOR 2000 ELECTION ####\n\n# Calculate winner for each state for 2000 election and create winning_party field\npres_vote_2000 &lt;- ELECTION_DATA_PRESIDENT |&gt;\n  filter(year == 2000) |&gt;                             \n  group_by(state, candidate) |&gt;                       \n  summarise(total_votes = sum(candidatevotes, na.rm = TRUE)) |&gt;  \n  arrange(state, desc(total_votes)) |&gt;                 \n  slice_max(total_votes, n = 1, with_ties = FALSE) |&gt;\n  mutate(winning_party = ifelse(candidate == \"GORE, AL\", \"D\", \"R\"))\n\n# Load shapefile from 106th Congress - relevant for 2000 election\n&lt;!-- pres_shp_2000 &lt;- shp_from_zip(\"/mp03/congress_shapefiles/congress_106_shapefile.zip\") --&gt;\n\n\n# Load .shp file for congressional districts for 2000 \npres_shp_2000 &lt;- read_sf(\"data/mp03/congress_shapefiles/districtShapes/districts105.shp\")\n\n# Make sure STATENAME is clean and able to join\npres_shp_2000 &lt;- pres_shp_2000 |&gt;\n  mutate(STATENAME = str_to_upper(str_trim(STATENAME)))\n\n# Make sure state is clean and able to join\npres_vote_2000 &lt;- pres_vote_2000 |&gt;\n  mutate(state = str_to_upper(str_trim(state)))\n\n# Join data\npres_map_vote_2000_data &lt;- pres_shp_2000 |&gt;\n  left_join(pres_vote_2000, by = c(\"STATENAME\" = \"state\"))\n\n# Make geometries valid\npres_map_vote_2000_data_g &lt;- pres_map_vote_2000_data |&gt;\n  mutate(geometry = st_make_valid(geometry))\n\n# Create state boundaries\nstate_boundaries &lt;- pres_map_vote_2000_data_g |&gt;\n  group_by(STATENAME, winning_party) |&gt;\n  summarise(\n    geometry = st_union(geometry),\n    total_votes = sum(total_votes, na.rm = TRUE)\n  ) |&gt;\n  ungroup()\n\n# Find electoral college vote totals\nelectoral_votes_00 &lt;- ELECTION_DATA_HOUSE |&gt; \n  filter(year == 2000) |&gt;\n  group_by(year, state) |&gt;\n  summarize(votes = n_distinct(district) + 2) |&gt; \n  pivot_wider(names_from = year, values_from = votes)\n\n# Join electoral college votes\nstate_boundaries  &lt;-  state_boundaries |&gt;\n  left_join(electoral_votes_00, by = c(\"STATENAME\" = \"state\"))\n\n# Handle DC's NA\nstate_boundaries$`2000`[state_boundaries$STATENAME == \"DISTRICT OF COLUMBIA\" & is.na(state_boundaries$`2000`)] &lt;- 2\n \n# Remove NA values\ncleaned_data &lt;- state_boundaries |&gt;\n  filter(!is.na(geometry), !is.na(winning_party))\n\n# Define dc_location and assign geometry if needed\ndc_location &lt;- state_boundaries |&gt;\n  filter(STATENAME == \"DISTRICT OF COLUMBIA\")\n\n# Check if geometry exists and is not empty\nif (nrow(dc_location) == 0 || st_is_empty(dc_location$geometry)) {\n  # Manually assign coordinates if geometry is missing or empty\n  dc_location &lt;- st_sf(\n    STATENAME = \"DISTRICT OF COLUMBIA\",\n    winning_party = \"D\",\n    geometry = st_sfc(st_point(c(-77.0369, 38.9072)), crs = st_crs(state_boundaries))\n  )\n} else {\n  # Calculate centroid if geometry is available\n  dc_location &lt;- st_centroid(dc_location)\n}\n\n# Calculate centroids using st_point_on_surface to ensure within geometry\nstate_centroids &lt;- state_boundaries |&gt;\n  st_point_on_surface()\n\n# Ensure all layers have the same CRS\nstate_boundaries &lt;- st_transform(state_boundaries, crs = st_crs(pres_shp_2000))\nstate_centroids &lt;- st_transform(state_centroids, crs = st_crs(state_boundaries))\ndc_location &lt;- st_transform(dc_location, crs = st_crs(state_boundaries))\n\n# Plot the data\nggplot() +\n  geom_sf(data = cleaned_data, aes(fill = winning_party), color = NA) +\n  geom_sf_text(data = state_centroids, aes(label = `2000`), size = 3, color = \"black\") +\n  geom_sf(data = dc_location, shape = 8, size = 5, color = \"gold\") +  # Overlay star for DC\n  scale_fill_manual(values = c(\"D\" =  alpha(\"blue\", .7), \"R\" =  alpha(\"red\", .7))) + \n  coord_sf(xlim = c(-130, -60), ylim = c(24, 50)) +\n  labs(fill = \"Winning Party\") +\n  theme_minimal() +\n  theme(\n    legend.position = \"bottom\",\n    panel.background = element_blank(),    \n    axis.text = element_blank(),           \n    axis.ticks = element_blank(),\n    axis.title = element_blank(), \n    panel.grid.major = element_blank(),    \n    panel.grid.minor = element_blank()     \n  )\n\n#### FACETED HISTORY OF RECENT ELECTORAL COLLEGE COUNTS ####\n\n#### DOES NOT RENDER. CRASHES COMPUTER. ITS NOT IN PROJECT :-( ####\n\n# Clean up all gemoetries\ncleaned_data &lt;- pres_shp_2000 |&gt;\n  mutate(geometry = st_make_valid(geometry)) |&gt;\n  group_by(STATENAME) |&gt;\n  summarize(geometry = st_union(geometry), .groups = \"drop\")\n\n# Union geometries into states\nstates_shapes_2000 &lt;- cleaned_data |&gt;\n  select(STATENAME,geometry)|&gt;\n  group_by(STATENAME)|&gt;\n  summarize(geometry = st_union(geometry))|&gt;\n  filter(!is.na(geometry))\n\n# Cast geometries into a polygon\nus_states_sf &lt;- states_shapes_2000 |&gt;\n  filter(!is.na(geometry)) |&gt;\n  st_make_valid() |&gt; \n  st_cast(\"MULTIPOLYGON\") \n\n# Group by year and state and identify entry with most votes\npresidential_winners_by_state &lt;- ELECTION_DATA_PRESIDENT |&gt;\n  select(year, state, candidatevotes, candidate, party_simplified) |&gt;\n  group_by(year, state) |&gt;\n  slice_max(candidatevotes)\n\n# Join data\npresidentials_winners_combined_sf &lt;- presidential_winners_by_state |&gt;\n  select(year, state, party_simplified) |&gt;\n  left_join(us_states_sf|&gt;\n  select(STATENAME, geometry) |&gt;\n  mutate(STATENAME=toupper(STATENAME)),by=c(\"state\"=\"STATENAME\"))\n\n# Reduced Geometries\npresidentials_winners_combined_sf_t &lt;- presidentials_winners_combined_sf %&gt;%\n  mutate(geometry = st_simplify(geometry, dTolerance = 0.05))\n\n# Try without DC \npresidentials_winners_combined_sf_t &lt;- presidentials_winners_combined_sf_t |&gt;\n  filter(state != \"DISTRICT OF COLUMBIA\")\n\n# Plot Data (doesn't work)\nggplot(presidentials_winners_combined_sf_t |&gt; filter(year %in% c(1976, 1980))) +\n  geom_sf(aes(geometry = geometry, fill = party_simplified), color = \"white\") +\n  scale_fill_manual(values = c(\"DEMOCRAT\" = \"blue\", \"REPUBLICAN\" = \"red\")) +\n  coord_sf(xlim = c(-130, -60), ylim = c(24, 50)) +\n  labs(fill = \"Winning Party\") +\n  theme_minimal() +\n  theme(legend.position = \"bottom\") +\n  facet_wrap(~year)\nprint(\"ending\")"
  },
  {
    "objectID": "mp03.html#adjusting-data-in-anticipation-for-maping-our-findings",
    "href": "mp03.html#adjusting-data-in-anticipation-for-maping-our-findings",
    "title": "The Electoral College Dilemma: Tradition, Tension, and the Future of American Democracy",
    "section": "",
    "text": "What follows are the re-adjustment of our data and inclusion of shapefiles to map out conclusions about our electoral data.\n\n\n&gt; show code for .shp files\n\n# Identify main directory\nDIRECTORY &lt;- paste(getwd(),\"data\", sep=\"/\")\n\n# Create function for extracting files from .zip files\nshp_from_zip &lt;- function(file_name, directory = DIRECTORY){\n  dir &lt;- paste(directory, file_name, sep=\"/\")\n  td &lt;- tempdir(); \n  zip_contents &lt;- unzip(dir, \n                        exdir = td)\n  fname_shp &lt;- zip_contents[grepl(\"shp$\", zip_contents)]\n  return(read_sf(fname_shp))\n}\n\n# Test function\nfile &lt;- shp_from_zip(\"/mp03/congress_shapefiles/congress_095_shapefile.zip\")"
  },
  {
    "objectID": "mp03.html#finndings",
    "href": "mp03.html#finndings",
    "title": "The Electoral College Dilemma: Tradition, Tension, and the Future of American Democracy",
    "section": "",
    "text": "The Electoral College system inherently disadvantages densely concentrated urban populations due to geographic sorting, where large numbers of voters in cities are “wasted” under the current allocation methods. This effect is especially pronounced in the State-Wide Winner-Take-All and District-Wide Winner-Take-All + At-Large systems, where urban votes are overshadowed by more spread-out rural and suburban voters. Even with a State-Wide Proportional approach, the dispersed nature of electoral votes dilutes the power of high-population centers.13\nThis dynamic reflects the original pastoral leanings of certain Founding Fathers, who were wary of urban centers and their concentrated political influence. Many founders idealized a nation of independent, rural landowners and saw the Electoral College as a mechanism to balance the interests of these pastoral areas against growing urban centers.14 Consequently, modern calls for Electoral College reform often stem from this persistent tension between rural and urban representation.\nCritics of the Electoral College, such as historian George C. Edwards III, argue that this system inevitably introduces a significant “democratic deficit” by allowing a candidate to win the presidency without securing the popular vote. Edwards suggests that this mechanism distorts democratic representation, disproportionately empowering certain states and demographic groups at the expense of others, and thus subverting the principle of equal representation.15\nThese findings are in line with the thoughts of Robert A. Dahl, widely regarded as one of the United States’ preeminent authoritie on democratic theory and the American Constitution.\nIn How Democratic Is the American Constitution? Dahl critically examines the Electoral College and its democratic shortcomings. He too recounts the 2000 election, where a candidate with fewer popular votes won, and traces this anomaly to the original confusion and compromises of the Framers. They established the Electoral College out of desperation after rejecting other methods, prioritizing insulation from popular choice and concern over “cabal and corruption.”16\nAs such, the Electoral College is deeply rooted in an anti-democratic framework. Built to balance regional influence rather than to represent the popular will, the Electoral College was again, crafted with significant limitations to prevent it from reflecting a true “one person, one vote” standard. Its mission makes it impossible to align with the democratic values most champion today.\nIn contrast, modern American political culture is firmly grounded in the principle of equal representation, where each vote should carry equal weight. Most Americans believe strongly in “one person, one vote” and would find it jarring, even offensive, for any politician to openly assert that some votes should count more than others.\nYet by supporting the Electoral College, we tacitly accept this inequality, promoting the illusion that it’s anything other than an outdated system that distorts minority political power.\nThere exists a deep disatisfaction with the Electoral College among the American public17: \nAs such, strong public support exists for centering “one person, one vote” into the U.S. Political System and its methods for selecting the President.\nIf we summarize our findings, there’s one system that consistly rewards the Popular Vote Winner the 50% electoral college vote threshold needed to win the presidency:\n\n Given these findings, the it’s the purple shading on the National Proportional maps above that best reflect the most equitable spirit of “one person, one vote,” highlighting how popular will could be represented more faithfully. If the Electoral College must be preserved, such a proportional approach would align more closely with our democratic values and national political culture, offering a way forward that respects the ideal of equal voter influence.\nAs such, if were to keep the Electoral College, we should adopt the National Proportion method for allocating electoral votes and the delegates who chose our nation’s chief executive, The President of the United States."
  }
]